{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c73133af-7360-4762-9048-3aa0b3bb71b4",
   "metadata": {},
   "source": [
    "# Transformers for Multivariate Energy Price Forecasting - Seminar Paper\n",
    "## Applied Predictive Analytics\n",
    "## Humboldt University Berlin (SS24)\n",
    "##\n",
    "## Authors: Ekaterina Basova, Emircan Ince , Yash Chougule\n",
    "## Supervisor: Georg Velev\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9feb2f0-f08e-4042-b246-2f7b22fae3ff",
   "metadata": {},
   "source": [
    "### Agenda:\n",
    "1. Data Loading & Preprocessing\n",
    "2. Experimental Design\n",
    "    - Benchmark Models\n",
    "      - Linear Regression\n",
    "      - LSTM\n",
    "    - Pre trained Chronos\n",
    "    - Transformers\n",
    "      - Unification\n",
    "      - Non-Stationary Autoformer\n",
    "      - BasisFormer\n",
    "      - iTransformer\n",
    "      - Increased prediction length (96)\n",
    "3. Results\n",
    "4. Outlook\n",
    "   - Chronos Simulation Framework\n",
    "   - DYNOTEARS Causal Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370ef93a-0cd3-471b-a6d1-1b3ed3da369c",
   "metadata": {},
   "source": [
    "# 1. Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0639d4ff-3f38-4acd-9bca-b125b15bd7f0",
   "metadata": {},
   "source": [
    "The first step is to load all the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f4de819",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 11:19:32.603550: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-18 11:19:32.608425: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-18 11:19:32.618473: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-18 11:19:32.635014: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-18 11:19:32.639891: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-18 11:19:32.652591: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-18 11:19:33.951495: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/RDC/inceemir/apa_group4_transformers_for_multivar_energy_forecasting/.venv/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.weight_norm as wn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import chronos\n",
    "from chronos import ChronosPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b023c8b7-32a6-427a-8f12-4178c843adad",
   "metadata": {},
   "source": [
    "Calling the all_countries.csv file from the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "iGtogtkxzGiT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "iGtogtkxzGiT",
    "outputId": "d63b1548-a355-4ac8-89ed-fc0029c44b31"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>ISO3 Code</th>\n",
       "      <th>Datetime (UTC)</th>\n",
       "      <th>Datetime (Local)</th>\n",
       "      <th>Price (EUR/MWhe)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>2015-01-01 01:00:00</td>\n",
       "      <td>17.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>2015-01-01 01:00:00</td>\n",
       "      <td>2015-01-01 02:00:00</td>\n",
       "      <td>15.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>2015-01-01 02:00:00</td>\n",
       "      <td>2015-01-01 03:00:00</td>\n",
       "      <td>16.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>2015-01-01 03:00:00</td>\n",
       "      <td>2015-01-01 04:00:00</td>\n",
       "      <td>17.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>2015-01-01 04:00:00</td>\n",
       "      <td>2015-01-01 05:00:00</td>\n",
       "      <td>16.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country ISO3 Code       Datetime (UTC)     Datetime (Local)  \\\n",
       "0  Austria       AUT  2015-01-01 00:00:00  2015-01-01 01:00:00   \n",
       "1  Austria       AUT  2015-01-01 01:00:00  2015-01-01 02:00:00   \n",
       "2  Austria       AUT  2015-01-01 02:00:00  2015-01-01 03:00:00   \n",
       "3  Austria       AUT  2015-01-01 03:00:00  2015-01-01 04:00:00   \n",
       "4  Austria       AUT  2015-01-01 04:00:00  2015-01-01 05:00:00   \n",
       "\n",
       "   Price (EUR/MWhe)  \n",
       "0             17.93  \n",
       "1             15.17  \n",
       "2             16.38  \n",
       "3             17.38  \n",
       "4             16.38  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##file_path = '/content/all_countries.csv' ## colab path\n",
    "file_path = 'data/all_countries.csv' ## jupyter path\n",
    "df = pd.read_csv(file_path)\n",
    "df = pd.DataFrame(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d5f883",
   "metadata": {},
   "source": [
    "The data is pivoted, setting the timestamp as the index and the country names as columns, with the corresponding electricity prices as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vQW9jbwq4lFG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "vQW9jbwq4lFG",
    "outputId": "e9aa57ef-18a2-4243-cd79-51b284512116"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Country</th>\n",
       "      <th>Austria</th>\n",
       "      <th>Belgium</th>\n",
       "      <th>Bulgaria</th>\n",
       "      <th>Croatia</th>\n",
       "      <th>Czechia</th>\n",
       "      <th>Denmark</th>\n",
       "      <th>Estonia</th>\n",
       "      <th>Finland</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>...</th>\n",
       "      <th>Norway</th>\n",
       "      <th>Poland</th>\n",
       "      <th>Portugal</th>\n",
       "      <th>Romania</th>\n",
       "      <th>Serbia</th>\n",
       "      <th>Slovakia</th>\n",
       "      <th>Slovenia</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Sweden</th>\n",
       "      <th>Switzerland</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime (UTC)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00</th>\n",
       "      <td>17.93</td>\n",
       "      <td>34.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.20</td>\n",
       "      <td>18.29</td>\n",
       "      <td>23.37</td>\n",
       "      <td>23.37</td>\n",
       "      <td>34.94</td>\n",
       "      <td>17.93</td>\n",
       "      <td>...</td>\n",
       "      <td>27.36</td>\n",
       "      <td>17.18</td>\n",
       "      <td>48.10</td>\n",
       "      <td>44.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.20</td>\n",
       "      <td>23.25</td>\n",
       "      <td>48.10</td>\n",
       "      <td>23.37</td>\n",
       "      <td>43.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 01:00:00</th>\n",
       "      <td>15.17</td>\n",
       "      <td>32.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.06</td>\n",
       "      <td>16.04</td>\n",
       "      <td>19.33</td>\n",
       "      <td>19.33</td>\n",
       "      <td>32.19</td>\n",
       "      <td>15.17</td>\n",
       "      <td>...</td>\n",
       "      <td>27.24</td>\n",
       "      <td>17.38</td>\n",
       "      <td>47.33</td>\n",
       "      <td>39.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.06</td>\n",
       "      <td>22.20</td>\n",
       "      <td>47.33</td>\n",
       "      <td>19.33</td>\n",
       "      <td>38.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 02:00:00</th>\n",
       "      <td>16.38</td>\n",
       "      <td>28.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.27</td>\n",
       "      <td>14.60</td>\n",
       "      <td>17.66</td>\n",
       "      <td>17.66</td>\n",
       "      <td>23.53</td>\n",
       "      <td>16.38</td>\n",
       "      <td>...</td>\n",
       "      <td>27.16</td>\n",
       "      <td>17.40</td>\n",
       "      <td>42.27</td>\n",
       "      <td>26.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.27</td>\n",
       "      <td>19.56</td>\n",
       "      <td>42.27</td>\n",
       "      <td>17.66</td>\n",
       "      <td>35.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 03:00:00</th>\n",
       "      <td>17.38</td>\n",
       "      <td>28.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.17</td>\n",
       "      <td>14.95</td>\n",
       "      <td>17.53</td>\n",
       "      <td>17.53</td>\n",
       "      <td>22.92</td>\n",
       "      <td>17.38</td>\n",
       "      <td>...</td>\n",
       "      <td>27.15</td>\n",
       "      <td>18.60</td>\n",
       "      <td>38.41</td>\n",
       "      <td>20.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.17</td>\n",
       "      <td>18.88</td>\n",
       "      <td>38.41</td>\n",
       "      <td>17.53</td>\n",
       "      <td>30.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 04:00:00</th>\n",
       "      <td>16.38</td>\n",
       "      <td>34.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.90</td>\n",
       "      <td>14.50</td>\n",
       "      <td>18.07</td>\n",
       "      <td>18.07</td>\n",
       "      <td>34.26</td>\n",
       "      <td>16.38</td>\n",
       "      <td>...</td>\n",
       "      <td>27.30</td>\n",
       "      <td>19.30</td>\n",
       "      <td>35.72</td>\n",
       "      <td>18.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.90</td>\n",
       "      <td>18.39</td>\n",
       "      <td>35.72</td>\n",
       "      <td>18.07</td>\n",
       "      <td>28.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Country              Austria  Belgium  Bulgaria  Croatia  Czechia  Denmark  \\\n",
       "Datetime (UTC)                                                               \n",
       "2015-01-01 00:00:00    17.93    34.94       NaN      NaN    24.20    18.29   \n",
       "2015-01-01 01:00:00    15.17    32.19       NaN      NaN    22.06    16.04   \n",
       "2015-01-01 02:00:00    16.38    28.05       NaN      NaN    20.27    14.60   \n",
       "2015-01-01 03:00:00    17.38    28.04       NaN      NaN    19.17    14.95   \n",
       "2015-01-01 04:00:00    16.38    34.26       NaN      NaN    17.90    14.50   \n",
       "\n",
       "Country              Estonia  Finland  France  Germany  ...  Norway  Poland  \\\n",
       "Datetime (UTC)                                          ...                   \n",
       "2015-01-01 00:00:00    23.37    23.37   34.94    17.93  ...   27.36   17.18   \n",
       "2015-01-01 01:00:00    19.33    19.33   32.19    15.17  ...   27.24   17.38   \n",
       "2015-01-01 02:00:00    17.66    17.66   23.53    16.38  ...   27.16   17.40   \n",
       "2015-01-01 03:00:00    17.53    17.53   22.92    17.38  ...   27.15   18.60   \n",
       "2015-01-01 04:00:00    18.07    18.07   34.26    16.38  ...   27.30   19.30   \n",
       "\n",
       "Country              Portugal  Romania  Serbia  Slovakia  Slovenia  Spain  \\\n",
       "Datetime (UTC)                                                              \n",
       "2015-01-01 00:00:00     48.10    44.17     NaN     24.20     23.25  48.10   \n",
       "2015-01-01 01:00:00     47.33    39.17     NaN     22.06     22.20  47.33   \n",
       "2015-01-01 02:00:00     42.27    26.93     NaN     20.27     19.56  42.27   \n",
       "2015-01-01 03:00:00     38.41    20.94     NaN     19.17     18.88  38.41   \n",
       "2015-01-01 04:00:00     35.72    18.52     NaN     17.90     18.39  35.72   \n",
       "\n",
       "Country              Sweden  Switzerland  \n",
       "Datetime (UTC)                            \n",
       "2015-01-01 00:00:00   23.37        43.43  \n",
       "2015-01-01 01:00:00   19.33        38.08  \n",
       "2015-01-01 02:00:00   17.66        35.47  \n",
       "2015-01-01 03:00:00   17.53        30.83  \n",
       "2015-01-01 04:00:00   18.07        28.26  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df [['Country','Datetime (UTC)',  'Price (EUR/MWhe)']]\n",
    "df = df.pivot(index='Datetime (UTC)', columns='Country', values='Price (EUR/MWhe)')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mfQvgSnM3_1v",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mfQvgSnM3_1v",
    "outputId": "9cd1c2f9-c7f7-46d1-df8b-df5c13df26d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country\n",
      "Austria                0\n",
      "Belgium                0\n",
      "Bulgaria           15336\n",
      "Croatia            24096\n",
      "Czechia                0\n",
      "Denmark                0\n",
      "Estonia                0\n",
      "Finland                0\n",
      "France                 0\n",
      "Germany                0\n",
      "Greece                 0\n",
      "Hungary                0\n",
      "Ireland            12480\n",
      "Italy                  0\n",
      "Latvia                 0\n",
      "Lithuania              0\n",
      "Luxembourg             0\n",
      "Netherlands            0\n",
      "North Macedonia    73008\n",
      "Norway                 0\n",
      "Poland                 0\n",
      "Portugal               0\n",
      "Romania                0\n",
      "Serbia             16800\n",
      "Slovakia               0\n",
      "Slovenia               0\n",
      "Spain                  0\n",
      "Sweden                 0\n",
      "Switzerland            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5644b079",
   "metadata": {},
   "source": [
    "Missing values are handled by dropping the samples that contained any NaNs to ensure a clean dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "WObloVqL4aH3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WObloVqL4aH3",
    "outputId": "c1a5702e-1761-4cca-d65c-14966b09d8dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country\n",
      "Austria        0\n",
      "Belgium        0\n",
      "Czechia        0\n",
      "Denmark        0\n",
      "Estonia        0\n",
      "Finland        0\n",
      "France         0\n",
      "Germany        0\n",
      "Greece         0\n",
      "Hungary        0\n",
      "Italy          0\n",
      "Latvia         0\n",
      "Lithuania      0\n",
      "Luxembourg     0\n",
      "Netherlands    0\n",
      "Norway         0\n",
      "Poland         0\n",
      "Portugal       0\n",
      "Romania        0\n",
      "Slovakia       0\n",
      "Slovenia       0\n",
      "Spain          0\n",
      "Sweden         0\n",
      "Switzerland    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(axis=1)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "AB6vyJX-C6h3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AB6vyJX-C6h3",
    "outputId": "aa9990f8-cb44-4367-b4ff-e2a1bf1732d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datetime (UTC)  Austria  Belgium  Czechia  Denmark  Estonia  Finland  \\\n",
      "0  2015-01-01 00:00:00    17.93    34.94    24.20    18.29    23.37    23.37   \n",
      "1  2015-01-01 01:00:00    15.17    32.19    22.06    16.04    19.33    19.33   \n",
      "2  2015-01-01 02:00:00    16.38    28.05    20.27    14.60    17.66    17.66   \n",
      "3  2015-01-01 03:00:00    17.38    28.04    19.17    14.95    17.53    17.53   \n",
      "4  2015-01-01 04:00:00    16.38    34.26    17.90    14.50    18.07    18.07   \n",
      "\n",
      "   France  Germany  Greece  ...  Netherlands  Norway  Poland  Portugal  \\\n",
      "0   34.94    17.93   48.78  ...        34.94   27.36   17.18     48.10   \n",
      "1   32.19    15.17   31.10  ...        32.19   27.24   17.38     47.33   \n",
      "2   23.53    16.38   20.78  ...        28.05   27.16   17.40     42.27   \n",
      "3   22.92    17.38   25.40  ...        28.04   27.15   18.60     38.41   \n",
      "4   34.26    16.38   26.00  ...        34.26   27.30   19.30     35.72   \n",
      "\n",
      "   Romania  Slovakia  Slovenia  Spain  Sweden  Switzerland  \n",
      "0    44.17     24.20     23.25  48.10   23.37        43.43  \n",
      "1    39.17     22.06     22.20  47.33   19.33        38.08  \n",
      "2    26.93     20.27     19.56  42.27   17.66        35.47  \n",
      "3    20.94     19.17     18.88  38.41   17.53        30.83  \n",
      "4    18.52     17.90     18.39  35.72   18.07        28.26  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.columns.name = None\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99211c4c-9b8f-4d60-9bb6-add80102ca5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last time point available: 2024-03-31 23:00:00\n"
     ]
    }
   ],
   "source": [
    "df['Datetime (UTC)'] = pd.to_datetime(df['Datetime (UTC)'])\n",
    "last_time_point = df['Datetime (UTC)'].max()\n",
    "print(\"Last time point available:\", last_time_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222566ac",
   "metadata": {},
   "source": [
    "Selected only latest 2500 samples for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9365312-6296-4b97-ace6-9dd9191fccea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Datetime (UTC)  Austria  Belgium  Czechia  Denmark  Estonia  \\\n",
      "78571 2023-12-18 19:00:00    89.00    81.68    91.54    37.53    85.79   \n",
      "78572 2023-12-18 20:00:00    84.92    79.97    76.34    33.87    76.89   \n",
      "78573 2023-12-18 21:00:00    72.05    73.79    63.56    27.91    12.66   \n",
      "78574 2023-12-18 22:00:00    59.58    68.67    53.21    31.94    10.08   \n",
      "78575 2023-12-18 23:00:00    64.79    65.61    63.10    24.84    10.04   \n",
      "...                   ...      ...      ...      ...      ...      ...   \n",
      "81067 2024-03-31 19:00:00    66.17    47.01    68.37    70.00    50.09   \n",
      "81068 2024-03-31 20:00:00    61.25    43.70    63.26    64.51    46.28   \n",
      "81069 2024-03-31 21:00:00    44.99    50.29    51.29    54.90    43.98   \n",
      "81070 2024-03-31 22:00:00    40.70    50.32    46.39    49.95    40.41   \n",
      "81071 2024-03-31 23:00:00    32.10    44.39    42.60    48.98    40.39   \n",
      "\n",
      "       Finland  France  Germany  Greece  ...  Netherlands  Norway  Poland  \\\n",
      "78571    17.20   82.07    77.98  121.73  ...        83.09   44.87   85.79   \n",
      "78572    15.21   77.93    71.09  101.76  ...        74.89   44.18   79.32   \n",
      "78573    12.66   83.20    62.98  108.33  ...        63.79   42.67   77.35   \n",
      "78574    10.08   79.46    55.12  102.52  ...        57.94   38.09   52.63   \n",
      "78575     8.06   78.51    47.29   91.55  ...        52.24   37.27   50.70   \n",
      "...        ...     ...      ...     ...  ...          ...     ...     ...   \n",
      "81067    50.09   26.12    70.00   65.81  ...        65.20   57.09   69.99   \n",
      "81068    46.28   24.53    64.51   60.90  ...        60.55   55.85   72.43   \n",
      "81069    43.98   32.35    54.90   48.07  ...        54.90   53.50   75.27   \n",
      "81070    40.41   40.70    49.95   43.45  ...        51.03   51.08   68.70   \n",
      "81071    40.39   32.10    48.98   37.15  ...        48.98   48.13   68.69   \n",
      "\n",
      "       Portugal  Romania  Slovakia  Slovenia   Spain  Sweden  Switzerland  \n",
      "78571    174.00   121.73     79.23     97.78  174.00   17.20        90.48  \n",
      "78572    129.47   101.76    105.45     89.42  129.47   15.21        85.21  \n",
      "78573    110.00    93.64     66.12     79.61  110.00   12.66        80.07  \n",
      "78574    105.71    57.20     55.42     61.41  105.71   10.08        76.25  \n",
      "78575     94.28    72.64     55.56     69.50   94.28    8.06        73.17  \n",
      "...         ...      ...       ...       ...     ...     ...          ...  \n",
      "81067      3.20    65.81     67.09     63.43    3.20   50.09        74.52  \n",
      "81068      3.20    60.90     62.10     58.74    3.20   46.28        67.31  \n",
      "81069      1.63    48.07     49.03     46.61    1.63   43.98        62.86  \n",
      "81070      0.70    43.45     44.32     42.13    0.70   40.41        44.23  \n",
      "81071      0.02    37.15     38.77     34.75    0.02   40.39        40.01  \n",
      "\n",
      "[2501 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find the latest timestamp in the DataFrame\n",
    "latest_timestamp = df['Datetime (UTC)'].max()\n",
    "\n",
    "# Calculate the timestamp for 2500 hours before the latest timestamp\n",
    "start_timestamp = latest_timestamp - pd.Timedelta(hours=2500)\n",
    "\n",
    "# Filter the DataFrame for the last 2500 hours\n",
    "df = df[df['Datetime (UTC)'] >= start_timestamp]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfda0759",
   "metadata": {},
   "source": [
    "Additional time-based features are extracted from the timestamp, including month, day, weekday, and hour, to provide temporal context for indexing expected by the model architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "_Jtyfje24Pdq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Jtyfje24Pdq",
    "outputId": "507d28c6-0347-4446-9078-c6fda9ffa9a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Datetime (UTC)  Austria  Belgium  Czechia  Denmark  Estonia  \\\n",
      "78571 2023-12-18 19:00:00    89.00    81.68    91.54    37.53    85.79   \n",
      "78572 2023-12-18 20:00:00    84.92    79.97    76.34    33.87    76.89   \n",
      "78573 2023-12-18 21:00:00    72.05    73.79    63.56    27.91    12.66   \n",
      "78574 2023-12-18 22:00:00    59.58    68.67    53.21    31.94    10.08   \n",
      "78575 2023-12-18 23:00:00    64.79    65.61    63.10    24.84    10.04   \n",
      "\n",
      "       Finland  France  Germany  Greece  ...  Romania  Slovakia  Slovenia  \\\n",
      "78571    17.20   82.07    77.98  121.73  ...   121.73     79.23     97.78   \n",
      "78572    15.21   77.93    71.09  101.76  ...   101.76    105.45     89.42   \n",
      "78573    12.66   83.20    62.98  108.33  ...    93.64     66.12     79.61   \n",
      "78574    10.08   79.46    55.12  102.52  ...    57.20     55.42     61.41   \n",
      "78575     8.06   78.51    47.29   91.55  ...    72.64     55.56     69.50   \n",
      "\n",
      "        Spain  Sweden  Switzerland  month  day  weekday  hour  \n",
      "78571  174.00   17.20        90.48     12   18        0    19  \n",
      "78572  129.47   15.21        85.21     12   18        0    20  \n",
      "78573  110.00   12.66        80.07     12   18        0    21  \n",
      "78574  105.71   10.08        76.25     12   18        0    22  \n",
      "78575   94.28    8.06        73.17     12   18        0    23  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "df['month'] = df['Datetime (UTC)'].apply(lambda row: row.month)\n",
    "df['day'] = df['Datetime (UTC)'].apply(lambda row: row.day)\n",
    "df['weekday'] = df['Datetime (UTC)'].apply(lambda row: row.weekday())\n",
    "df['hour'] = df['Datetime (UTC)'].apply(lambda row: row.hour)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a33c29",
   "metadata": {},
   "source": [
    "The data is split into training and testing sets using an 80-20 ratio. Separate splits are made for electricity prices and the newly created timestamp features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80mxqDAh5Mwd",
   "metadata": {
    "id": "80mxqDAh5Mwd"
   },
   "outputs": [],
   "source": [
    "# separating the electricity prices and timestamp features\n",
    "electricity_prices_df = df[['Datetime (UTC)', 'Austria', 'Belgium', 'Czechia', 'Denmark', 'Estonia', 'Finland', 'France',\n",
    "              'Germany', 'Greece', 'Hungary', 'Italy', 'Latvia', 'Lithuania', 'Luxembourg',\n",
    "             'Netherlands', 'Norway', 'Poland', 'Portugal', 'Romania', 'Slovakia',\n",
    "             'Slovenia', 'Spain', 'Sweden', 'Switzerland']]\n",
    "timestamp_features_df = df[['Datetime (UTC)', 'month', 'day', 'weekday', 'hour']]\n",
    "\n",
    "# defining the split ratio\n",
    "train_size = 0.8\n",
    "train_size_electricity = int(len(electricity_prices_df) * train_size)\n",
    "train_size_timestamp = int(len(timestamp_features_df) * train_size)\n",
    "\n",
    "# spliting the data into train and test sets\n",
    "electricity_prices_train = electricity_prices_df[:train_size_electricity]\n",
    "electricity_prices_test = electricity_prices_df[train_size_electricity:]\n",
    "timestamp_features_train = timestamp_features_df[:train_size_timestamp]\n",
    "timestamp_features_test = timestamp_features_df[train_size_timestamp:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d602f2d",
   "metadata": {},
   "source": [
    "The electricity prices are normalized using StandardScaler, ensuring the model could train effectively without being affected by different ranges in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4oRyT6un5WWm",
   "metadata": {
    "id": "4oRyT6un5WWm"
   },
   "outputs": [],
   "source": [
    "# rescaling the electricity prices\n",
    "scaler = StandardScaler()\n",
    "\n",
    "electricity_prices_train_scaled = scaler.fit_transform(electricity_prices_train.drop(columns=['Datetime (UTC)']))\n",
    "electricity_prices_test_scaled = scaler.transform(electricity_prices_test.drop(columns=['Datetime (UTC)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40587696",
   "metadata": {},
   "source": [
    "Sequences are created for model input and output based on a given sequence length, label length and prediction horizon. The sequences are similar for 'basis_former', 'itransformer' and 'ns_autoformer' whereas changes slightly for 'chronos'. This is because since chronos is a pretrained model, it need not be trained, hence, no need of label length for validation. We only predict using chronos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "407a011b-3187-4e94-9c3a-e36c17253639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length, pred_length, label_length, curr_model):\n",
    "    seq_x = [] # storing for input seqiences\n",
    "    seq_y = [] # storing for output seqiences\n",
    "    for i in range(len(data) - seq_length - pred_length):\n",
    "        seq_x.append(data[i:i+seq_length])\n",
    "        if curr_model in [\"basis_former\", \"itransformer\", \"ns_autoformer\"]:\n",
    "          seq_y.append(data[i+seq_length-label_length:i+seq_length+pred_length])\n",
    "        else: ## only chronos\n",
    "          seq_y.append(data[i+seq_length:i+seq_length+pred_length])\n",
    "    return np.array(seq_x), np.array(seq_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210f6f18",
   "metadata": {},
   "source": [
    "The sequences are converted into PyTorch tensors and wrapped into a DataLoader for efficient batching during model training. For the \"basis_former\" model, additional indexing was performed to normalize indices within the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c17fd64-77c4-42ab-9e63-bf919d801d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(seq_x, seq_y, seq_x_mark, seq_y_mark, batch_size, curr_model):\n",
    "    seq_x = torch.tensor(seq_x, dtype=torch.float32)\n",
    "    seq_y = torch.tensor(seq_y, dtype=torch.float32)\n",
    "    seq_x_mark = torch.tensor(seq_x_mark, dtype=torch.float32)\n",
    "    seq_y_mark = torch.tensor(seq_y_mark, dtype=torch.float32)\n",
    "    \n",
    "    if curr_model == \"basis_former\":\n",
    "        indices = []\n",
    "        total_len = len(seq_x)\n",
    "        for i in range(total_len):\n",
    "            index_list = np.arange(i, i + len(seq_x[0]) + len(seq_y[0]), 1)\n",
    "            norm_index = index_list / total_len\n",
    "            indices.append(norm_index)\n",
    "        indices = torch.tensor(indices, dtype=torch.float32)\n",
    "        dataset = TensorDataset(seq_x, seq_y, seq_x_mark, seq_y_mark, indices)\n",
    "    else:\n",
    "        dataset = TensorDataset(seq_x, seq_y, seq_x_mark, seq_y_mark)\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=2, shuffle=True, drop_last=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21225b3d-5c69-425f-9f8e-17ebcc39cd8b",
   "metadata": {},
   "source": [
    "# 2. Experimental Design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584d834d",
   "metadata": {},
   "source": [
    "# Benchmark Models\n",
    "\n",
    "To evaluate the performance of our advanced Transformer models in forecasting multivariate energy prices, we first establish baseline results using two benchmark models: Linear Regression and Long Short-Term Memory (LSTM) networks. \n",
    "  \n",
    "By comparing these benchmarks, we can better understand the strengths and weaknesses of the Transformer models in this specific forecasting task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1627bd8d-ab8f-4f35-81c8-25b91760b230",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "**Linear Regression** provides a simple, interpretable model that assumes linear relationships between the input features and the target variables. It serves as a baseline to compare against more complex models.\n",
    "\n",
    "\n",
    "### Linear Model Preprocessing\n",
    "\n",
    "In this step, we prepare the data for the Linear Regression model:\n",
    "\n",
    "- **Lag Features**: We create lagged features to capture the relationship between the current and previous values of the target variable. This allows the model to consider temporal dependencies.\n",
    "- **Data Splitting**: The dataset is split into training and testing sets, ensuring that we evaluate the model on unseen data.\n",
    "- **Scaling**: Features and target variables are standardized to have a mean of 0 and a standard deviation of 1, but only after splitting the data to avoid information leakage.\n",
    "\n",
    "This preprocessing ensures that the Linear Regression model can effectively learn from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ad38e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the main dataframe for linear model preprocessing\n",
    "df_linear = df.copy()\n",
    "\n",
    "# Define the number of lagged features\n",
    "lag_steps = 3\n",
    "\n",
    "# List of all columns (already defined in the main preprocessing)\n",
    "all_columns = df_linear.columns.tolist()\n",
    "\n",
    "# List of columns to exclude (non-country columns)\n",
    "exclude_columns = ['Datetime (UTC)', 'month', 'day', 'weekday', 'hour']\n",
    "\n",
    "# Define the country columns by excluding non-country columns\n",
    "countries = [col for col in all_columns if col not in exclude_columns]\n",
    "\n",
    "# Create lagged features for each country\n",
    "for country in countries:\n",
    "    for lag in range(1, lag_steps + 1):\n",
    "        df_linear[f'{country}_lag_{lag}'] = df_linear[country].shift(lag)\n",
    "\n",
    "# Drop rows with NaN values due to lagging\n",
    "df_linear.dropna(inplace=True)\n",
    "\n",
    "# Define features (X) and targets (Y)\n",
    "X_numerical = df_linear.drop(columns=countries + ['Datetime (UTC)'])\n",
    "Y = df_linear[countries]  # Target: current prices of all countries\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_size = 0.8\n",
    "train_size_idx = int(len(X_numerical) * train_size)\n",
    "X_train, X_test = X_numerical[:train_size_idx], X_numerical[train_size_idx:]\n",
    "Y_train, Y_test = Y[:train_size_idx], Y[train_size_idx:]\n",
    "\n",
    "# Standardize the features and targets using only the training data\n",
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "scaler_Y = StandardScaler()\n",
    "Y_train_scaled = scaler_Y.fit_transform(Y_train)\n",
    "Y_test_scaled = scaler_Y.transform(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c39d0c",
   "metadata": {},
   "source": [
    "### Linear Regression Model\n",
    "\n",
    "Here, we train and evaluate the Linear Regression model:\n",
    "\n",
    "- **Training**: The model is trained on the preprocessed training data.\n",
    "- **Prediction**: After training, the model makes predictions on the test set.\n",
    "- **Evaluation**: We use Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE) to assess the model's performance, providing insight into its accuracy.\n",
    "\n",
    "These metrics help us understand how well the Linear Regression model fits the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "575df258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Mean Absolute Error: 7.121460465848673\n",
      "Linear Regression Root Mean Squared Error: 12.298510526240198\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the linear regression model\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train_scaled, Y_train_scaled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "Y_pred_lr = model_lr.predict(X_test_scaled)\n",
    "\n",
    "# Inverse transform the predictions and the actual values back to the original scale\n",
    "Y_pred_lr_original = scaler_Y.inverse_transform(Y_pred_lr)\n",
    "Y_test_original = scaler_Y.inverse_transform(Y_test_scaled)\n",
    "\n",
    "# Evaluate the model using MAE\n",
    "mae_lr = mean_absolute_error(Y_test_original, Y_pred_lr_original)\n",
    "print(f\"Linear Regression Mean Absolute Error: {mae_lr}\")\n",
    "\n",
    "# Evaluate the model using RMSE\n",
    "rmse_lr = np.sqrt(mean_squared_error(Y_test_original, Y_pred_lr_original))\n",
    "print(f\"Linear Regression Root Mean Squared Error: {rmse_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb17613-c608-4a1b-b8dd-7773464d72b1",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "\n",
    "**LSTM** is a more sophisticated neural network designed to capture temporal dependencies in sequential data. It is particularly useful for time series forecasting, allowing us to assess how well it handles the complexities in the dataset compared to the Transformer models.\n",
    "\n",
    "\n",
    "### LSTM Preprocessing\n",
    "\n",
    "In this section, we preprocess the data for the LSTM model:\n",
    "\n",
    "- **Data Splitting**: The dataset is split into training and testing sets before any scaling is applied to avoid information leakage.\n",
    "- **Scaling**: Both training and testing data are standardized using `StandardScaler` to ensure the LSTM model can effectively learn.\n",
    "- **Sequence Creation**: We create sequences of a specified length to capture temporal dependencies, which are crucial for the LSTM model's learning process.\n",
    "\n",
    "This preprocessing is tailored to the LSTM model's need to understand sequential data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "740f3adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the main dataframe for LSTM model preprocessing\n",
    "df_lstm = df.copy()\n",
    "\n",
    "# Split data into training and testing sets before scaling\n",
    "train_size = int(len(df_lstm) * 0.8)\n",
    "train_df = df_lstm.iloc[:train_size]\n",
    "test_df = df_lstm.iloc[train_size:]\n",
    "\n",
    "# Rescale the data using StandardScaler for LSTM\n",
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(train_df.drop(columns=['Datetime (UTC)', 'month', 'day', 'weekday', 'hour']))\n",
    "test_scaled = scaler.transform(test_df.drop(columns=['Datetime (UTC)', 'month', 'day', 'weekday', 'hour']))\n",
    "\n",
    "# Convert to a supervised learning problem by creating sequences\n",
    "def create_sequences_lstm(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Define sequence length (number of time steps)\n",
    "seq_length = 96\n",
    "\n",
    "# Create sequences\n",
    "X_train, y_train = create_sequences_lstm(train_scaled, seq_length)\n",
    "X_test, y_test = create_sequences_lstm(test_scaled, seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b871c7e",
   "metadata": {},
   "source": [
    "### LSTM Model\n",
    "\n",
    "Here, we train and evaluate the LSTM model:\n",
    "\n",
    "- **Model Architecture**: The LSTM model is built with two LSTM layers followed by a Dense layer, allowing it to capture complex temporal patterns.\n",
    "- **Training**: The model is trained using the preprocessed data, with Early Stopping to prevent overfitting.\n",
    "- **Evaluation**: After making predictions on the test set, we evaluate the model using MAE and RMSE, giving us a measure of its forecasting accuracy.\n",
    "\n",
    "These steps ensure that the LSTM model is well-prepared to handle the complexities of time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd87f6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-17 21:49:41.422320: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/RDC/inceemir/apa_group4_transformers_for_multivar_energy_forecasting/.venv/lib64/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - loss: 0.7113 - val_loss: 0.6439\n",
      "Epoch 2/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.4890 - val_loss: 0.4834\n",
      "Epoch 3/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.3603 - val_loss: 0.3544\n",
      "Epoch 4/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - loss: 0.2156 - val_loss: 0.2748\n",
      "Epoch 5/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.1786 - val_loss: 0.2429\n",
      "Epoch 6/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.1493 - val_loss: 0.2280\n",
      "Epoch 7/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.1296 - val_loss: 0.2095\n",
      "Epoch 8/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.1296 - val_loss: 0.2004\n",
      "Epoch 9/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0988 - val_loss: 0.1996\n",
      "Epoch 10/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.1044 - val_loss: 0.1966\n",
      "Epoch 11/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0977 - val_loss: 0.1892\n",
      "Epoch 12/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0993 - val_loss: 0.1846\n",
      "Epoch 13/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0934 - val_loss: 0.1820\n",
      "Epoch 14/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - loss: 0.0780 - val_loss: 0.1781\n",
      "Epoch 15/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0885 - val_loss: 0.1745\n",
      "Epoch 16/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0833 - val_loss: 0.1805\n",
      "Epoch 17/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0716 - val_loss: 0.1750\n",
      "Epoch 18/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0741 - val_loss: 0.1666\n",
      "Epoch 19/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - loss: 0.0662 - val_loss: 0.1683\n",
      "Epoch 20/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - loss: 0.0762 - val_loss: 0.1716\n",
      "Epoch 21/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0651 - val_loss: 0.1705\n",
      "Epoch 22/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - loss: 0.0646 - val_loss: 0.1668\n",
      "Epoch 23/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - loss: 0.0625 - val_loss: 0.1631\n",
      "Epoch 24/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - loss: 0.0712 - val_loss: 0.1625\n",
      "Epoch 25/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0653 - val_loss: 0.1643\n",
      "Epoch 26/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0620 - val_loss: 0.1665\n",
      "Epoch 27/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - loss: 0.0636 - val_loss: 0.1588\n",
      "Epoch 28/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0644 - val_loss: 0.1579\n",
      "Epoch 29/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0600 - val_loss: 0.1623\n",
      "Epoch 30/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 0.0646 - val_loss: 0.1576\n",
      "Epoch 31/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - loss: 0.0576 - val_loss: 0.1669\n",
      "Epoch 32/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0619 - val_loss: 0.1621\n",
      "Epoch 33/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0606 - val_loss: 0.1589\n",
      "Epoch 34/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0535 - val_loss: 0.1614\n",
      "Epoch 35/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - loss: 0.0503 - val_loss: 0.1628\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "LSTM Mean Absolute Error: 9.709397783011797\n",
      "LSTM Root Mean Squared Error: 15.6083472731543\n"
     ]
    }
   ],
   "source": [
    "# Define the LSTM model\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(units=50, return_sequences=True, input_shape=(seq_length, X_train.shape[2])))\n",
    "model_lstm.add(LSTM(units=50, return_sequences=False))\n",
    "model_lstm.add(Dense(units=y_train.shape[1]))\n",
    "\n",
    "# Compile the model\n",
    "model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Set up EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Fit the model with EarlyStopping\n",
    "model_lstm.fit(X_train, y_train, epochs=50, batch_size=24, \n",
    "               validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lstm = model_lstm.predict(X_test)\n",
    "\n",
    "# Inverse transform the scaled data to original values\n",
    "y_test_inverse = scaler.inverse_transform(y_test)\n",
    "y_pred_inverse = scaler.inverse_transform(y_pred_lstm)\n",
    "\n",
    "# Evaluate the model using MAE\n",
    "mae_lstm = mean_absolute_error(y_test_inverse, y_pred_inverse)\n",
    "print(f\"LSTM Mean Absolute Error: {mae_lstm}\")\n",
    "\n",
    "# Evaluate the model using RMSE\n",
    "rmse_lstm = np.sqrt(mean_squared_error(y_test_inverse, y_pred_inverse))\n",
    "print(f\"LSTM Root Mean Squared Error: {rmse_lstm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524dced6-ac13-4939-9362-ab95493547d0",
   "metadata": {},
   "source": [
    "# Pre trained model Chronos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133a20c4-aa7e-4fd7-95e7-8e60275dc839",
   "metadata": {},
   "source": [
    "The first transformer-based model we tested was the Chronos. Published in March 2024, it is the most recent model used in this notebook. The authors use the small (46M parameters) and basic (200M parameters) pre-trained model variants. \n",
    "\n",
    "As Chronos requires data in a different format from other transformer-based models, data pre-processing is performed first. The Chronos architecture treats time series as a simple sequence without considering temporal frequencies. This removes date features and performs a train & test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1c0a8cf-52f1-402f-bfd3-16d4b7a204c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 96\n",
    "pred_length = 48\n",
    "\n",
    "## seleting countries because while testing not all countries were used, for the final version all are added\n",
    "selected_countries = ['Austria', 'Belgium', 'Czechia', 'Denmark', 'Estonia', 'Finland', 'France',\n",
    "              'Germany', 'Greece', 'Hungary', 'Italy', 'Latvia', 'Lithuania', 'Luxembourg',\n",
    "             'Netherlands', 'Norway', 'Poland', 'Portugal', 'Romania', 'Slovakia',\n",
    "             'Slovenia', 'Spain', 'Sweden', 'Switzerland']\n",
    "\n",
    "## extracting data for selected countries\n",
    "data = df[selected_countries]\n",
    "\n",
    "## train & test ratios\n",
    "split_point = int(len(df) * 0.8)  \n",
    "\n",
    "## data split\n",
    "train_data = data.iloc[:split_point]\n",
    "test_data = data.iloc[split_point:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1a55a7-2336-43a8-a547-252eeea9222d",
   "metadata": {},
   "source": [
    "### Small Version\n",
    "A small version of the model with 46 million parameters is loaded from the Chronos package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2730ed31-8b2d-4584-9c7a-e7963bba7415",
   "metadata": {},
   "outputs": [],
   "source": [
    "## initializing Chronos pipeline (framework from original GitHub repo)\n",
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-small\",\n",
    "    device_map=\"cpu\", \n",
    "    torch_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e060e4f8-c378-4049-9e9f-0e9dd0ee98e7",
   "metadata": {},
   "source": [
    "Chronos is designed to process univariate data. As the data for this analysis is multivariate, it is split by country and processed separately. In addition, the model accepts 1D tensors, so a function is written to create torch tensors for each country column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdcb210d-3d09-48fb-bede-ff65b2e3de8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Austria\n",
      "Data range for Austria: -12.5 to 147.04\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Belgium\n",
      "Data range for Belgium: -11.8 to 144.11\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Czechia\n",
      "Data range for Czechia: -17.09 to 158.44\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Denmark\n",
      "Data range for Denmark: -4.97 to 275.85\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Estonia\n",
      "Data range for Estonia: -2.02 to 1896.0\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Finland\n",
      "Data range for Finland: -2.5 to 1896.0\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing France\n",
      "Data range for France: -11.93 to 144.11\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Germany\n",
      "Data range for Germany: -13.37 to 150.09\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Greece\n",
      "Data range for Greece: 0.04 to 190.96\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Hungary\n",
      "Data range for Hungary: -13.01 to 183.11\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Italy\n",
      "Data range for Italy: 27.92 to 165.0\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Latvia\n",
      "Data range for Latvia: -2.02 to 1478.91\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Lithuania\n",
      "Data range for Lithuania: -2.02 to 1478.91\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Luxembourg\n",
      "Data range for Luxembourg: -13.37 to 150.09\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Netherlands\n",
      "Data range for Netherlands: -39.79 to 147.06\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Norway\n",
      "Data range for Norway: 10.95 to 355.82\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Poland\n",
      "Data range for Poland: -13.81 to 160.15\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Portugal\n",
      "Data range for Portugal: 0.0 to 181.26\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Romania\n",
      "Data range for Romania: -0.01 to 231.37\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Slovakia\n",
      "Data range for Slovakia: -14.06 to 147.93\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Slovenia\n",
      "Data range for Slovenia: -11.53 to 147.12\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Spain\n",
      "Data range for Spain: 0.0 to 181.26\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Sweden\n",
      "Data range for Sweden: -2.5 to 526.25\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Switzerland\n",
      "Data range for Switzerland: -10.36 to 143.05\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n"
     ]
    }
   ],
   "source": [
    "## function for creating tensors (format that chronos needs)\n",
    "def prepare_chronos_data(data, seq_length):\n",
    "    return torch.tensor(data[-seq_length:].values, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "### forecast loop for each country since Chronos can only process univariate data\n",
    "results = {}\n",
    "\n",
    "for country in selected_countries:\n",
    "    ## printings for logging and checking if data is processed correctly\n",
    "    print(f\"\\nProcessing {country}\")\n",
    "    print(f\"Data range for {country}: {train_data[country].min()} to {train_data[country].max()}\")\n",
    "    ## tensors\n",
    "    chronos_input = prepare_chronos_data(train_data[country], seq_length)\n",
    "    print(f\"Chronos input shape: {chronos_input.shape}\")\n",
    "    \n",
    "    ## forecasting as showed in the repo\n",
    "    forecast = pipeline.predict(\n",
    "        context=chronos_input,\n",
    "        prediction_length=pred_length,\n",
    "        num_samples=20,\n",
    "    )\n",
    "    \n",
    "    ## storing results\n",
    "    results[country] = forecast\n",
    "    print(f\"Forecast shape: {forecast.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf0f50c-e216-4245-b0f1-61532bf6f3c9",
   "metadata": {},
   "source": [
    "The following evaluation metrics are now defined and calculated for each country. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d4e2e76-e80a-45da-aba7-c82e5dae03b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE for Austria: 1377.1959211825235\n",
      "MAE for Austria: 33.97182075738907\n",
      "\n",
      "RMSE for Austria: 37.11059041813433\n",
      "MAPE for Austria: 0.42718874009340096\n",
      "\n",
      "MSE for Belgium: 246.35925053619886\n",
      "MAE for Belgium: 12.915189402898156\n",
      "\n",
      "RMSE for Belgium: 15.69583545199805\n",
      "MAPE for Belgium: 0.16125279587377492\n",
      "\n",
      "MSE for Czechia: 1068.4946820076534\n",
      "MAE for Czechia: 29.521004292170204\n",
      "\n",
      "RMSE for Czechia: 32.68783691233872\n",
      "MAPE for Czechia: 0.359955355545563\n",
      "\n",
      "MSE for Denmark: 1726.6649134184088\n",
      "MAE for Denmark: 34.86134136150281\n",
      "\n",
      "RMSE for Denmark: 41.55315768288144\n",
      "MAPE for Denmark: 0.4527950009699202\n",
      "\n",
      "MSE for Estonia: 2144.8586789976985\n",
      "MAE for Estonia: 41.87909220178922\n",
      "\n",
      "RMSE for Estonia: 46.31261900387084\n",
      "MAPE for Estonia: 0.5435857851755701\n",
      "\n",
      "MSE for Finland: 709.5732684982034\n",
      "MAE for Finland: 24.307278334299724\n",
      "\n",
      "RMSE for Finland: 26.637816511459857\n",
      "MAPE for Finland: 0.329354823164105\n",
      "\n",
      "MSE for France: 164.02438319637128\n",
      "MAE for France: 11.039518947601318\n",
      "\n",
      "RMSE for France: 12.807200443358855\n",
      "MAPE for France: 0.15346062437693633\n",
      "\n",
      "MSE for Germany: 1728.143726293929\n",
      "MAE for Germany: 36.02746922058363\n",
      "\n",
      "RMSE for Germany: 41.5709481043424\n",
      "MAPE for Germany: 0.44375691952302426\n",
      "\n",
      "MSE for Greece: 386.8713800258801\n",
      "MAE for Greece: 15.745281937917076\n",
      "\n",
      "RMSE for Greece: 19.669046240880114\n",
      "MAPE for Greece: 0.3999037908126796\n",
      "\n",
      "MSE for Hungary: 1763.281952206641\n",
      "MAE for Hungary: 37.97018885453542\n",
      "\n",
      "RMSE for Hungary: 41.9914509419077\n",
      "MAPE for Hungary: 0.4705761071355084\n",
      "\n",
      "MSE for Italy: 66.6525181848338\n",
      "MAE for Italy: 6.62220780690511\n",
      "\n",
      "RMSE for Italy: 8.16409934927508\n",
      "MAPE for Italy: 0.07590606216963665\n",
      "\n",
      "MSE for Latvia: 2194.738356405784\n",
      "MAE for Latvia: 42.4631769212087\n",
      "\n",
      "RMSE for Latvia: 46.848034712309804\n",
      "MAPE for Latvia: 0.5521157813541657\n",
      "\n",
      "MSE for Lithuania: 2062.6974767759343\n",
      "MAE for Lithuania: 40.77195035437743\n",
      "\n",
      "RMSE for Lithuania: 45.416929407170784\n",
      "MAPE for Lithuania: 0.5293360171440297\n",
      "\n",
      "MSE for Luxembourg: 1920.604287860696\n",
      "MAE for Luxembourg: 38.39839107885957\n",
      "\n",
      "RMSE for Luxembourg: 43.82469951820202\n",
      "MAPE for Luxembourg: 0.47129853487055806\n",
      "\n",
      "MSE for Netherlands: 509.7088087682144\n",
      "MAE for Netherlands: 16.551613783836363\n",
      "\n",
      "RMSE for Netherlands: 22.576731578512742\n",
      "MAPE for Netherlands: 0.21562682672441827\n",
      "\n",
      "MSE for Norway: 302.518735862402\n",
      "MAE for Norway: 15.11150557200114\n",
      "\n",
      "RMSE for Norway: 17.393065740760083\n",
      "MAPE for Norway: 0.2107081047415061\n",
      "\n",
      "MSE for Poland: 2713.1402413651836\n",
      "MAE for Poland: 49.03884528755027\n",
      "\n",
      "RMSE for Poland: 52.08781279114322\n",
      "MAPE for Poland: 0.5992140668190542\n",
      "\n",
      "MSE for Portugal: 2073.868719002915\n",
      "MAE for Portugal: 27.553354055539273\n",
      "\n",
      "RMSE for Portugal: 45.539748780630255\n",
      "MAPE for Portugal: inf\n",
      "\n",
      "MSE for Romania: 809.7847632293332\n",
      "MAE for Romania: 24.787941895325975\n",
      "\n",
      "RMSE for Romania: 28.45671736566488\n",
      "MAPE for Romania: 0.4057348497092879\n",
      "\n",
      "MSE for Slovakia: 2110.4069039641818\n",
      "MAE for Slovakia: 41.949572020769125\n",
      "\n",
      "RMSE for Slovakia: 45.93916525105982\n",
      "MAPE for Slovakia: 0.5202338150336488\n",
      "\n",
      "MSE for Slovenia: 859.0176829849339\n",
      "MAE for Slovenia: 26.482560224533085\n",
      "\n",
      "RMSE for Slovenia: 29.30900344578324\n",
      "MAPE for Slovenia: 0.3307249736369035\n",
      "\n",
      "MSE for Spain: 2453.798112198822\n",
      "MAE for Spain: 31.171701009559428\n",
      "\n",
      "RMSE for Spain: 49.53582655209078\n",
      "MAPE for Spain: inf\n",
      "\n",
      "MSE for Sweden: 726.5240525917394\n",
      "MAE for Sweden: 25.223302189509074\n",
      "\n",
      "RMSE for Sweden: 26.954110124278625\n",
      "MAPE for Sweden: 0.3610503298276164\n",
      "\n",
      "MSE for Switzerland: 287.3614526040763\n",
      "MAE for Switzerland: 11.159589500427245\n",
      "\n",
      "RMSE for Switzerland: 16.951738925670025\n",
      "MAPE for Switzerland: 0.11462552820914583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3526970/590783650.py:12: RuntimeWarning: divide by zero encountered in divide\n",
      "  return np.mean(np.abs((forecast - actual) / actual + 1e-5)) ## adding epsilon\n"
     ]
    }
   ],
   "source": [
    "## evaluation metrics as in other transformers\n",
    "def calculate_mse(actual, forecast):\n",
    "    return np.mean((actual - forecast) ** 2)\n",
    "    \n",
    "def calculate_mae(actual, forecast):\n",
    "    return np.mean(np.abs(actual - forecast))\n",
    "    \n",
    "def calculate_rmse(actual, forecast):\n",
    "    return np.sqrt(calculate_mse(forecast, actual))\n",
    "    \n",
    "def calculate_mape(actual, forecast):\n",
    "    return np.mean(np.abs((forecast - actual) / actual + 1e-5)) ## adding epsilon\n",
    "\n",
    "mse_results = {}\n",
    "mae_results = {}\n",
    "mape_results = {}\n",
    "rmse_results = {}\n",
    "\n",
    "## evaluation for each country\n",
    "for country in selected_countries:\n",
    "    actual_values = test_data[country].values[:pred_length]\n",
    "    ## since chronos produced 20 forecasts for each country, finding median within them\n",
    "    forecasted_values = np.median(results[country], axis=1).flatten()\n",
    "    ## matching test and forecast lenght to make sure  evaluation is consistent\n",
    "    min_length = min(len(actual_values), len(forecasted_values))\n",
    "    actual_values = actual_values[:min_length]\n",
    "    forecasted_values = forecasted_values[:min_length]\n",
    "    \n",
    "    mse = calculate_mse(actual_values, forecasted_values)\n",
    "    mae = calculate_mae(actual_values, forecasted_values)\n",
    "    rmse = calculate_rmse(actual_values, forecasted_values)\n",
    "    mape = calculate_mape(actual_values, forecasted_values)\n",
    "    mse_results[country] = mse\n",
    "    mae_results[country] = mae\n",
    "    rmse_results[country] = rmse\n",
    "    mape_results[country] = mape\n",
    "    print(f\"\\nMSE for {country}: {mse}\")\n",
    "    print(f\"MAE for {country}: {mae}\")\n",
    "    print(f\"\\nRMSE for {country}: {rmse}\")\n",
    "    print(f\"MAPE for {country}: {mape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462bc8c5-db0a-4790-bdc3-aa9c03584cdf",
   "metadata": {},
   "source": [
    "To obtain an average performance for all univariate results, an average is calculated over them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8a27c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average MSE across selected countries: 1266.92876117344\n",
      "\n",
      "Average MAE across selected countries: 28.146829042128683\n",
      "\n",
      "Average RMSE across selected countries: 33.126424385571816\n",
      "\n",
      "Average MAPE across selected countries: inf\n"
     ]
    }
   ],
   "source": [
    "## avg of the whole model\n",
    "average_mse = np.mean(list(mse_results.values()))\n",
    "print(f\"\\nAverage MSE across selected countries: {average_mse}\")\n",
    "average_mae = np.mean(list(mae_results.values()))\n",
    "print(f\"\\nAverage MAE across selected countries: {average_mae}\")\n",
    "average_rmse = np.mean(list(rmse_results.values()))\n",
    "print(f\"\\nAverage RMSE across selected countries: {average_rmse}\")\n",
    "average_mape = np.mean(list(mape_results.values()))\n",
    "print(f\"\\nAverage MAPE across selected countries: {average_mape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c62e92-6237-4056-9215-fe349054f5b4",
   "metadata": {},
   "source": [
    "### Base Version\n",
    "Same procedure for base model version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e529b04-12c5-4d52-82eb-0160c6e8626a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Austria\n",
      "Data range for Austria: -12.5 to 147.04\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "\n",
      "Processing Belgium\n",
      "Data range for Belgium: -11.8 to 144.11\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "\n",
      "Processing Czechia\n",
      "Data range for Czechia: -17.09 to 158.44\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "\n",
      "Processing Denmark\n",
      "Data range for Denmark: -4.97 to 275.85\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "\n",
      "Processing Estonia\n",
      "Data range for Estonia: -2.02 to 1896.0\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "\n",
      "Processing Finland\n",
      "Data range for Finland: -2.5 to 1896.0\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "\n",
      "Processing France\n",
      "Data range for France: -11.93 to 144.11\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "\n",
      "Processing Germany\n",
      "Data range for Germany: -13.37 to 150.09\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "\n",
      "Processing Greece\n",
      "Data range for Greece: 0.04 to 190.96\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "\n",
      "Processing Hungary\n",
      "Data range for Hungary: -13.01 to 183.11\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "\n",
      "Processing Italy\n",
      "Data range for Italy: 27.92 to 165.0\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "\n",
      "Processing Latvia\n",
      "Data range for Latvia: -2.02 to 1478.91\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "\n",
      "Processing Lithuania\n",
      "Data range for Lithuania: -2.02 to 1478.91\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "\n",
      "Processing Luxembourg\n",
      "Data range for Luxembourg: -13.37 to 150.09\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "\n",
      "Processing Netherlands\n",
      "Data range for Netherlands: -39.79 to 147.06\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "\n",
      "Processing Norway\n",
      "Data range for Norway: 10.95 to 355.82\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "\n",
      "Processing Poland\n",
      "Data range for Poland: -13.81 to 160.15\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "\n",
      "Processing Portugal\n",
      "Data range for Portugal: 0.0 to 181.26\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "\n",
      "Processing Romania\n",
      "Data range for Romania: -0.01 to 231.37\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "\n",
      "Processing Slovakia\n",
      "Data range for Slovakia: -14.06 to 147.93\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "\n",
      "Processing Slovenia\n",
      "Data range for Slovenia: -11.53 to 147.12\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "\n",
      "Processing Spain\n",
      "Data range for Spain: 0.0 to 181.26\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "\n",
      "Processing Sweden\n",
      "Data range for Sweden: -2.5 to 526.25\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "\n",
      "Processing Switzerland\n",
      "Data range for Switzerland: -10.36 to 143.05\n",
      "Chronos input shape: torch.Size([1, 96])\n"
     ]
    }
   ],
   "source": [
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-base\",\n",
    "    device_map=\"cpu\", \n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "results_2 = {}\n",
    "\n",
    "for country in selected_countries:\n",
    "    print(f\"\\nProcessing {country}\")\n",
    "    print(f\"Data range for {country}: {train_data[country].min()} to {train_data[country].max()}\")\n",
    "    chronos_input = prepare_chronos_data(train_data[country], seq_length)\n",
    "    print(f\"Chronos input shape: {chronos_input.shape}\")  \n",
    "    forecast_2 = pipeline.predict(\n",
    "        context=chronos_input,\n",
    "        prediction_length=pred_length,\n",
    "        num_samples=20,\n",
    "    )\n",
    "    \n",
    "    results_2[country] = forecast_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1ee5091-e558-4cbc-8dfe-56779c74197b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE for Austria: 773.4936684231992\n",
      "MAE for Austria: 24.143480763435363\n",
      "\n",
      "RMSE for Austria: 27.81175414142731\n",
      "MAPE for Austria: 0.29619716157361714\n",
      "\n",
      "MSE for Belgium: 127.9165796535528\n",
      "MAE for Belgium: 8.577646487553915\n",
      "\n",
      "RMSE for Belgium: 11.310021204823306\n",
      "MAPE for Belgium: 0.11065585873889562\n",
      "\n",
      "MSE for Czechia: 931.3943890948616\n",
      "MAE for Czechia: 26.81776564598083\n",
      "\n",
      "RMSE for Czechia: 30.518754710748954\n",
      "MAPE for Czechia: 0.3293356203518319\n",
      "\n",
      "MSE for Denmark: 1412.8281537525897\n",
      "MAE for Denmark: 32.59973978678386\n",
      "\n",
      "RMSE for Denmark: 37.58760638498533\n",
      "MAPE for Denmark: 0.4155747502847836\n",
      "\n",
      "MSE for Estonia: 1316.52801790989\n",
      "MAE for Estonia: 32.845781043370565\n",
      "\n",
      "RMSE for Estonia: 36.28399120700326\n",
      "MAPE for Estonia: 0.4211230317205239\n",
      "\n",
      "MSE for Finland: 334.5750945408876\n",
      "MAE for Finland: 14.347600123087565\n",
      "\n",
      "RMSE for Finland: 18.291394002122626\n",
      "MAPE for Finland: 0.19601914184711577\n",
      "\n",
      "MSE for France: 269.0242063930303\n",
      "MAE for France: 13.661555274327597\n",
      "\n",
      "RMSE for France: 16.40195739517178\n",
      "MAPE for France: 0.18465954837630197\n",
      "\n",
      "MSE for Germany: 1222.9129247691194\n",
      "MAE for Germany: 31.57112998485565\n",
      "\n",
      "RMSE for Germany: 34.97017192936173\n",
      "MAPE for Germany: 0.3871557993430117\n",
      "\n",
      "MSE for Greece: 386.61694681688203\n",
      "MAE for Greece: 14.24513864517212\n",
      "\n",
      "RMSE for Greece: 19.662577318776957\n",
      "MAPE for Greece: 0.47774085665119953\n",
      "\n",
      "MSE for Hungary: 1083.4706346103194\n",
      "MAE for Hungary: 29.355267562866214\n",
      "\n",
      "RMSE for Hungary: 32.91611512026168\n",
      "MAPE for Hungary: 0.36302049825991506\n",
      "\n",
      "MSE for Italy: 81.81512903824164\n",
      "MAE for Italy: 8.13279172261556\n",
      "\n",
      "RMSE for Italy: 9.045171586998316\n",
      "MAPE for Italy: 0.09256486371702473\n",
      "\n",
      "MSE for Latvia: 1381.4296874432628\n",
      "MAE for Latvia: 33.01958735307058\n",
      "\n",
      "RMSE for Latvia: 37.167589206770764\n",
      "MAPE for Latvia: 0.42520913180468883\n",
      "\n",
      "MSE for Lithuania: 1802.3110975949412\n",
      "MAE for Lithuania: 38.404233937660855\n",
      "\n",
      "RMSE for Lithuania: 42.453634680612936\n",
      "MAPE for Lithuania: 0.4962511283894096\n",
      "\n",
      "MSE for Luxembourg: 1382.6525582654638\n",
      "MAE for Luxembourg: 32.2828204703331\n",
      "\n",
      "RMSE for Luxembourg: 37.184036336383166\n",
      "MAPE for Luxembourg: 0.3964306839541016\n",
      "\n",
      "MSE for Netherlands: 126.07634912227581\n",
      "MAE for Netherlands: 8.95107455889384\n",
      "\n",
      "RMSE for Netherlands: 11.228372505500333\n",
      "MAPE for Netherlands: 0.11773599771090319\n",
      "\n",
      "MSE for Norway: 232.12664796333124\n",
      "MAE for Norway: 12.845075511932373\n",
      "\n",
      "RMSE for Norway: 15.235703067575557\n",
      "MAPE for Norway: 0.17884090985541035\n",
      "\n",
      "MSE for Poland: 1720.2452709407487\n",
      "MAE for Poland: 38.46623805085818\n",
      "\n",
      "RMSE for Poland: 41.4758396050128\n",
      "MAPE for Poland: 0.47285251302578485\n",
      "\n",
      "MSE for Portugal: 2001.8317989121176\n",
      "MAE for Portugal: 27.20204125970095\n",
      "\n",
      "RMSE for Portugal: 44.74183499714912\n",
      "MAPE for Portugal: inf\n",
      "\n",
      "MSE for Romania: 568.8833544605349\n",
      "MAE for Romania: 20.147497137387592\n",
      "\n",
      "RMSE for Romania: 23.85127574073418\n",
      "MAPE for Romania: 0.44204328446227326\n",
      "\n",
      "MSE for Slovakia: 1400.109336147817\n",
      "MAE for Slovakia: 34.1196249961853\n",
      "\n",
      "RMSE for Slovakia: 37.4180349049468\n",
      "MAPE for Slovakia: 0.41722465257105484\n",
      "\n",
      "MSE for Slovenia: 933.2363474407836\n",
      "MAE for Slovenia: 27.72908948580424\n",
      "\n",
      "RMSE for Slovenia: 30.548917287537108\n",
      "MAPE for Slovenia: 0.34744463223603334\n",
      "\n",
      "MSE for Spain: 2383.9602804994406\n",
      "MAE for Spain: 30.839074711739034\n",
      "\n",
      "RMSE for Spain: 48.825815717706554\n",
      "MAPE for Spain: inf\n",
      "\n",
      "MSE for Sweden: 857.0603297118138\n",
      "MAE for Sweden: 27.44333452383677\n",
      "\n",
      "RMSE for Sweden: 29.275592730324245\n",
      "MAPE for Sweden: 0.3928236002724601\n",
      "\n",
      "MSE for Switzerland: 301.71709861611185\n",
      "MAE for Switzerland: 11.092042140960693\n",
      "\n",
      "RMSE for Switzerland: 17.370005717215864\n",
      "MAPE for Switzerland: 0.11304370591077602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3526970/590783650.py:12: RuntimeWarning: divide by zero encountered in divide\n",
      "  return np.mean(np.abs((forecast - actual) / actual + 1e-5)) ## adding epsilon\n"
     ]
    }
   ],
   "source": [
    "mse_results_2 = {}\n",
    "mae_results_2 = {}\n",
    "mape_results_2 = {}\n",
    "rmse_results_2 = {}\n",
    "\n",
    "for country in selected_countries:\n",
    "    actual_values = test_data[country].values[:pred_length]\n",
    "    forecasted_values_2 = np.median(results_2[country], axis=1).flatten()\n",
    "    min_length = min(len(actual_values), len(forecasted_values_2))\n",
    "    actual_values = actual_values[:min_length]\n",
    "    forecasted_values_2 = forecasted_values_2[:min_length]\n",
    "    \n",
    "    mse_2 = calculate_mse(actual_values, forecasted_values_2)\n",
    "    mae_2 = calculate_mae(actual_values, forecasted_values_2)\n",
    "    rmse_2 = calculate_rmse(actual_values, forecasted_values_2)\n",
    "    mape_2 = calculate_mape(actual_values, forecasted_values_2)\n",
    "    mse_results_2[country] = mse_2\n",
    "    mae_results_2[country] = mae_2\n",
    "    rmse_results_2[country] = rmse_2\n",
    "    mape_results_2[country] = mape_2\n",
    "    print(f\"\\nMSE for {country}: {mse_2}\")\n",
    "    print(f\"MAE for {country}: {mae_2}\")\n",
    "    print(f\"\\nRMSE for {country}: {rmse_2}\")\n",
    "    print(f\"MAPE for {country}: {mape_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5985b5e9-3ca3-4c56-a51e-e241f1b6824e",
   "metadata": {},
   "source": [
    "Results for base Chronos model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b3f8aa6-0310-429e-af3b-19d7e9ac71a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average MSE across selected countries: 959.6756625883841\n",
      "\n",
      "Average MAE across selected countries: 24.1183179657672\n",
      "\n",
      "Average RMSE across selected countries: 28.815673645797943\n",
      "\n",
      "Average MAPE across selected countries: inf\n"
     ]
    }
   ],
   "source": [
    "average_mse_2 = np.mean(list(mse_results_2.values()))\n",
    "print(f\"\\nAverage MSE across selected countries: {average_mse_2}\")\n",
    "average_mae_2 = np.mean(list(mae_results_2.values()))\n",
    "print(f\"\\nAverage MAE across selected countries: {average_mae_2}\")\n",
    "average_rmse_2 = np.mean(list(rmse_results_2.values()))\n",
    "print(f\"\\nAverage RMSE across selected countries: {average_rmse_2}\")\n",
    "average_mape_2 = np.mean(list(mape_results_2.values()))\n",
    "print(f\"\\nAverage MAPE across selected countries: {average_mape_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5a7ac4-ef50-4568-aeb2-ed1cec9d015f",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02c458b-65b0-4808-a620-24831f9482c8",
   "metadata": {},
   "source": [
    "## Unification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba8d633",
   "metadata": {},
   "source": [
    "Given the train_loader and test_loader, the function 'fit' trains and/or tests the transformer model on that dataset.\n",
    "1. **Model selection:** the argument 'model' loads the corresponding model and the associated configurations.\n",
    "2. **Training and testing flags:** train_flag determins if the model must be trained, test_flag determines if the model must be tested. Also a pretrained model can be passed in which case only test_flag will be True.\n",
    "3. **Arguments:** every model has its specific set of parameters in class 'Args' that define the configuration for training and testing.\n",
    "4. **Return:** the function returns trained and/or tested model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10670e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit (model, train_flag, test_flag, train_loader=None, test_loader=None, pretrained_model=None):\n",
    "    '''Fits a transformer model to the train and/or test loaders\n",
    "    \n",
    "    model - \"basis_former\", \"itransformer\", \"ns_autoformer\"\n",
    "    \n",
    "    train_flag: typ(bool) - True: to train the model on train_loader, False: if pretrained_model is passed\n",
    "    \n",
    "    test_flag: typ(bool) - True: to test on test_loader, False: if only training\n",
    "    \n",
    "    pretrained_model - pass a pretrained model if available to be fitted on a test_loader. \n",
    "    eg. fit(basis_former, train_flag=False, test_flag=True, test_loader=test_loader, pretrained_model=model)\n",
    "    '''\n",
    "    \n",
    "    if curr_model == 'basis_former':\n",
    "        # Code for Basisforme\n",
    "\n",
    "        import Basisformer.model\n",
    "        importlib.reload(Basisformer.model)\n",
    "        from Basisformer.model import Basisformer\n",
    "\n",
    "        import Basisformer.main\n",
    "        importlib.reload(Basisformer.main)\n",
    "        from Basisformer.main import parse_args, model_setup, log_and_print\n",
    "        importlib.reload(Basisformer.pyplot)\n",
    "\n",
    "        class Args:\n",
    "            is_training = True\n",
    "            data_path = 'data'\n",
    "            device = 0\n",
    "            num_workers = 10\n",
    "            features = 'M'\n",
    "            freq = 'h'\n",
    "            seq_len = 96\n",
    "            pred_len = 48\n",
    "            heads = 16\n",
    "            d_model = 512\n",
    "            N = 10\n",
    "            block_nums = 2\n",
    "            bottleneck = 2\n",
    "            map_bottleneck = 20\n",
    "            train_epochs = 50\n",
    "            batch_size = 24\n",
    "            learning_rate = 0.0001\n",
    "            tau = 0.07\n",
    "            loss_weight_prediction = 1.0\n",
    "            loss_weight_infonce = 1.0\n",
    "            loss_weight_smooth = 1.0\n",
    "            check_point = 'checkpoint'\n",
    "            patience = 3\n",
    "\n",
    "        args = Args()\n",
    "\n",
    "        # Set up device\n",
    "        device = torch.device(f\"cuda:{args.device}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Set up model\n",
    "        model = model_setup(args, device)\n",
    "        \n",
    "        if pretrained_model == None:\n",
    "            # Set up model\n",
    "            model = model_setup(args, device)\n",
    "\n",
    "        else:\n",
    "            model = pretrained_model\n",
    "\n",
    "        \n",
    "        if train_flag:\n",
    "            import Basisformer.model\n",
    "            importlib.reload(Basisformer.model)\n",
    "            from Basisformer.model import Basisformer\n",
    "\n",
    "            import Basisformer.main\n",
    "            importlib.reload(Basisformer.main)\n",
    "            from Basisformer.main import train\n",
    "\n",
    "\n",
    "            record_dir = os.path.join('records', args.data_path.split('.')[0], 'features_' + args.features,\n",
    "                                    'seq_len' + str(args.seq_len) + ',' + 'pred_len' + str(args.pred_len))\n",
    "            \n",
    "            if train_loader == None:\n",
    "                return 'train_loader not found'\n",
    "\n",
    "            # Call the train function\n",
    "            train(model, train_loader, args, device, record_dir)\n",
    "            \n",
    "        else:\n",
    "            if pretrained_model == None:\n",
    "                return 'model not found which is required for testing'\n",
    "            \n",
    "        if test_flag :\n",
    "            import Basisformer.main\n",
    "            importlib.reload(Basisformer.main)\n",
    "            from Basisformer.main import test\n",
    "            \n",
    "            if test_loader == None:\n",
    "                return 'test_loader not found'\n",
    "\n",
    "            test(model, test_loader, args, device, record_dir)\n",
    "        return model\n",
    "            \n",
    "    \n",
    "    elif curr_model == 'itransformer':\n",
    "        # code for itransformer\n",
    "        \n",
    "        import iTransformer.experiment\n",
    "        importlib.reload(iTransformer.experiment)\n",
    "        from iTransformer.experiment import Exp_Long_Term_Forecast\n",
    "        \n",
    "        class Args:\n",
    "            is_training = 1\n",
    "            model_id = 'iTransformer_train'\n",
    "            model = 'iTransformer'\n",
    "            data = 'all_countries'\n",
    "            features = 'M'\n",
    "            target = 'OT'\n",
    "            freq = 'h'\n",
    "            checkpoints = './checkpoints/'\n",
    "            seq_len = 96\n",
    "            label_len = 48\n",
    "            pred_len = 48\n",
    "            enc_in = 24\n",
    "            dec_in = 24\n",
    "            c_out = 24\n",
    "            d_model = 512\n",
    "            n_heads = 8\n",
    "            e_layers = 2\n",
    "            d_layers = 1\n",
    "            d_ff = 2048\n",
    "            moving_avg = 25\n",
    "            factor = 1\n",
    "            distil = True\n",
    "            dropout = 0.05\n",
    "            embed = 'timeF'\n",
    "            activation = 'gelu'\n",
    "            output_attention = False\n",
    "            do_predict = True\n",
    "            num_workers = 10\n",
    "            itr = 2\n",
    "            train_epochs = 50\n",
    "            batch_size = 24\n",
    "            patience = 3\n",
    "            learning_rate = 0.0001\n",
    "            des = 'test'\n",
    "            loss = 'mse'\n",
    "            lradj = 'type1'\n",
    "            use_amp = False\n",
    "            use_gpu = True if torch.cuda.is_available() else False\n",
    "            gpu = 0\n",
    "            use_multi_gpu = False\n",
    "            devices = '0,1,2,3'\n",
    "            exp_name = 'MTSF'\n",
    "            channel_independence = False\n",
    "            inverse = False\n",
    "            class_strategy = 'projection'\n",
    "            target_root_path = './data'\n",
    "            target_data_path = 'all_countries'\n",
    "            efficient_training = False\n",
    "            use_norm = True\n",
    "            partial_start_index = 0\n",
    "            seed = 2021\n",
    "            p_hidden_dims = [128, 128]\n",
    "            p_hidden_layers = 2\n",
    "\n",
    "        args = Args()\n",
    "        \n",
    "        if pretrained_model == None:\n",
    "            # Initialize the experiment\n",
    "            exp = Exp_Long_Term_Forecast(args)\n",
    "\n",
    "        else:\n",
    "            return 'pretrained not valid for iTransformer and ns_autoformer'\n",
    "\n",
    "        # Define the settings\n",
    "        setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}'.format(\n",
    "            args.model_id, args.model, args.data, args.features, args.seq_len, args.label_len,\n",
    "            args.pred_len, args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff,\n",
    "            args.factor, args.embed, args.distil, args.des, 0)\n",
    "        \n",
    "        if train_flag:\n",
    "            Exp_Long_Term_Forecast.train(self=exp, train_loader=train_loader, setting=setting)\n",
    "        \n",
    "        if test_flag:\n",
    "            Exp_Long_Term_Forecast.test(self=exp, test_loader=test_loader, setting=setting, test=0)\n",
    "        return exp.model\n",
    "    \n",
    "    elif curr_model == 'ns_autoformer':\n",
    "        # code for itransformer\n",
    "        \n",
    "        import ns_Autoformer.ns_Autoformer\n",
    "        importlib.reload(ns_Autoformer.ns_Autoformer)\n",
    "        from ns_Autoformer.ns_Autoformer import Model\n",
    "        \n",
    "        from ns_Autoformer.main import Exp_Main\n",
    "\n",
    "        class Args:\n",
    "            is_training = 1\n",
    "            model_id = 'ns_autoformer_train'\n",
    "            model = 'ns_Autoformer'\n",
    "            features = 'M'\n",
    "            target = 'OT'\n",
    "            freq = 'h'\n",
    "            checkpoints = './checkpoints/'\n",
    "            seq_len = 96\n",
    "            label_len = 48\n",
    "            pred_len = 48\n",
    "            enc_in = 24\n",
    "            dec_in = 24\n",
    "            c_out = 24\n",
    "            d_model = 512\n",
    "            n_heads = 8\n",
    "            e_layers = 2\n",
    "            d_layers = 1\n",
    "            d_ff = 2048\n",
    "            moving_avg = 25\n",
    "            factor = 1\n",
    "            distil = True\n",
    "            dropout = 0.05\n",
    "            embed = 'timeF'\n",
    "            activation = 'gelu'\n",
    "            output_attention = False\n",
    "            do_predict = True\n",
    "            num_workers = 10\n",
    "            itr = 2\n",
    "            train_epochs = 50\n",
    "            batch_size = 24\n",
    "            patience = 3\n",
    "            learning_rate = 0.0001\n",
    "            des = 'test'\n",
    "            loss = 'mse'\n",
    "            lradj = 'type1'\n",
    "            use_amp = False\n",
    "            use_gpu = True if torch.cuda.is_available() else False\n",
    "            gpu = 0\n",
    "            use_multi_gpu = False\n",
    "            devices = '0,1,2,3'\n",
    "            seed = 2021\n",
    "            p_hidden_dims = [128, 128]\n",
    "            p_hidden_layers = 2\n",
    "\n",
    "        args = Args()\n",
    "        \n",
    "        if pretrained_model == None:\n",
    "            # Initialize the experiment\n",
    "            exp = Exp_Main(args)\n",
    "\n",
    "        # Define the setting string\n",
    "        setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}'.format(\n",
    "            args.model_id, args.model, args.features, args.seq_len, args.label_len,\n",
    "            args.pred_len, args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff,\n",
    "            args.factor, args.embed, args.distil, args.des, 0)\n",
    "        \n",
    "        if train_flag:\n",
    "            Exp_Main.train(self=exp, train_loader=train_loader, setting=setting)\n",
    "        \n",
    "        if test_flag:\n",
    "            Exp_Main.test(self=exp, test_loader=test_loader, setting=setting, test=0)\n",
    "        return exp.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa62ae11-381d-4aaf-9e32-ade675824eeb",
   "metadata": {},
   "source": [
    "## Nonstationary Autoformer\n",
    "\n",
    "The Nonstationary Autoformer is a specialized Transformer model designed to handle nonstationary time series data effectively. This section outlines the preparation and training process of the Nonstationary Autoformer model.\n",
    "\n",
    "### Data Preparation\n",
    "\n",
    "We first prepare the data sequences required for training and testing the Nonstationary Autoformer model:\n",
    "\n",
    "- **Sequence Creation**: We generate sequences for both the electricity prices and corresponding timestamp features for the training and testing datasets.\n",
    "- **PyTorch DataLoader**: These sequences are then converted into PyTorch `DataLoader` objects, which will be fed into the model for training and evaluation.\n",
    "\n",
    "This preparation step ensures that the model receives data in the correct format for learning and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f380f29-2948-4a18-8fa7-36533717c383",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 96\n",
    "pred_length = 48\n",
    "label_length = 48\n",
    "batch_size = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80a8451f-0280-4b1d-83f4-645080a0ebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_model = \"ns_autoformer\"\n",
    "\n",
    "train_seq_x, train_seq_y = create_sequences(electricity_prices_train_scaled, seq_length, pred_length, label_length, curr_model)\n",
    "train_seq_x_mark, train_seq_y_mark = create_sequences(timestamp_features_train.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "\n",
    "test_seq_x, test_seq_y = create_sequences(electricity_prices_test_scaled, seq_length, pred_length,label_length, curr_model)\n",
    "test_seq_x_mark, test_seq_y_mark = create_sequences(timestamp_features_test.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "\n",
    "train_loader = create_dataloader(train_seq_x, train_seq_y, train_seq_x_mark, train_seq_y_mark, batch_size, curr_model)\n",
    "test_loader = create_dataloader(test_seq_x, test_seq_y, test_seq_x_mark, test_seq_y_mark, batch_size, curr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8affed",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation\n",
    "\n",
    "The model is trained and tested using the prepared `DataLoader` objects:\n",
    "\n",
    "- **Training and Testing**: The `fit` function is called with the model type, training flag, and testing flag set to `True`. This function trains the model on the training data and then evaluates its performance on the test data.\n",
    "\n",
    "By training and testing the Nonstationary Autoformer, we can assess its ability to forecast multivariate energy prices under nonstationary conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55134ef6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "Epoch: 1 cost time: 9.170212507247925\n",
      "Epoch: 1, Steps: 77 | Train Loss: 1.3706557\n",
      "Validation loss decreased (inf --> 1.370656).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 7.460994720458984\n",
      "Epoch: 2, Steps: 77 | Train Loss: 0.7722959\n",
      "Validation loss decreased (1.370656 --> 0.772296).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 7.602068185806274\n",
      "Epoch: 3, Steps: 77 | Train Loss: 0.6973021\n",
      "Validation loss decreased (0.772296 --> 0.697302).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 7.4225404262542725\n",
      "Epoch: 4, Steps: 77 | Train Loss: 0.6553520\n",
      "Validation loss decreased (0.697302 --> 0.655352).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 7.446813344955444\n",
      "Epoch: 5, Steps: 77 | Train Loss: 0.6268754\n",
      "Validation loss decreased (0.655352 --> 0.626875).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 7.51957368850708\n",
      "Epoch: 6, Steps: 77 | Train Loss: 0.6100929\n",
      "Validation loss decreased (0.626875 --> 0.610093).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 7.563289403915405\n",
      "Epoch: 7, Steps: 77 | Train Loss: 0.6051365\n",
      "Validation loss decreased (0.610093 --> 0.605137).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 7.558748483657837\n",
      "Epoch: 8, Steps: 77 | Train Loss: 0.6008775\n",
      "Validation loss decreased (0.605137 --> 0.600878).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 7.567034721374512\n",
      "Epoch: 9, Steps: 77 | Train Loss: 0.5968353\n",
      "Validation loss decreased (0.600878 --> 0.596835).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 7.469096899032593\n",
      "Epoch: 10, Steps: 77 | Train Loss: 0.5970811\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 7.516429901123047\n",
      "Epoch: 11, Steps: 77 | Train Loss: 0.5959736\n",
      "Validation loss decreased (0.596835 --> 0.595974).  Saving model ...\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 7.545827627182007\n",
      "Epoch: 12, Steps: 77 | Train Loss: 0.5958178\n",
      "Validation loss decreased (0.595974 --> 0.595818).  Saving model ...\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 7.633572816848755\n",
      "Epoch: 13, Steps: 77 | Train Loss: 0.5882948\n",
      "Validation loss decreased (0.595818 --> 0.588295).  Saving model ...\n",
      "Updating learning rate to 2.44140625e-08\n",
      "Epoch: 14 cost time: 7.510655879974365\n",
      "Epoch: 14, Steps: 77 | Train Loss: 0.5931980\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.220703125e-08\n",
      "Epoch: 15 cost time: 7.612364768981934\n",
      "Epoch: 15, Steps: 77 | Train Loss: 0.5948149\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.103515625e-09\n",
      "Epoch: 16 cost time: 7.578675270080566\n",
      "Epoch: 16, Steps: 77 | Train Loss: 0.5913246\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test shape: (14, 24, 48, 24) (14, 24, 48, 24)\n",
      "test shape: (336, 48, 24) (336, 48, 24)\n",
      "mse:0.5997434854507446, mae:0.5859289169311523, mape:5.601837158203125, rmse:0.774431049823761\n"
     ]
    }
   ],
   "source": [
    "ns_autoformer_train_test_48_pred = fit(model=curr_model, train_flag=True, test_flag=True, train_loader=train_loader, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ee0fbc-fd5f-4b8e-99f0-e0d05ff0826d",
   "metadata": {},
   "source": [
    "## Basisformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbb6bf7-4105-4037-9976-530a87c770ef",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ILk9LX4k5Yuu",
   "metadata": {
    "id": "ILk9LX4k5Yuu"
   },
   "outputs": [],
   "source": [
    "curr_model = \"basis_former\"\n",
    "\n",
    "train_seq_x, train_seq_y = create_sequences(electricity_prices_train_scaled, seq_length, pred_length, label_length, curr_model)\n",
    "train_seq_x_mark, train_seq_y_mark = create_sequences(timestamp_features_train.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "\n",
    "test_seq_x, test_seq_y = create_sequences(electricity_prices_test_scaled, seq_length, pred_length,label_length, curr_model)\n",
    "test_seq_x_mark, test_seq_y_mark = create_sequences(timestamp_features_test.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "train_loader = create_dataloader(train_seq_x, train_seq_y, train_seq_x_mark, train_seq_y_mark, batch_size, curr_model)\n",
    "test_loader = create_dataloader(test_seq_x, test_seq_y, test_seq_x_mark, test_seq_y_mark, batch_size, curr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25388088-0a01-4a53-9327-36baeb5ec317",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33d34df7-21cb-4303-87f9-d5ec8c03ec8e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33d34df7-21cb-4303-87f9-d5ec8c03ec8e",
    "outputId": "3c5fe222-fb0a-4abc-d84a-489ef41b44b1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "\titers: 15, epoch: 1 | loss: 3.2205608\n",
      "\titers: 30, epoch: 1 | loss: 1.8433468\n",
      "\titers: 45, epoch: 1 | loss: 1.3125908\n",
      "\titers: 60, epoch: 1 | loss: 0.8543798\n",
      "\titers: 75, epoch: 1 | loss: 0.7683564\n",
      "Epoch: 1 cost time: 3.953132152557373\n",
      "loss_pred:0.8524745485999368\n",
      "loss entropy:1.1382287019172415\n",
      "loss smooth:0.13352408434276458\n",
      "Epoch: 1 | Train Loss: 2.1242273\n",
      "\titers: 15, epoch: 2 | loss: 1.8100058\n",
      "\titers: 30, epoch: 2 | loss: 1.0088799\n",
      "\titers: 45, epoch: 2 | loss: 0.7898964\n",
      "\titers: 60, epoch: 2 | loss: 1.0458199\n",
      "\titers: 75, epoch: 2 | loss: 0.9705649\n",
      "Epoch: 2 cost time: 3.9880404472351074\n",
      "loss_pred:0.8438585412192654\n",
      "loss entropy:0.049672288018602156\n",
      "loss smooth:0.11198921104917278\n",
      "Epoch: 2 | Train Loss: 1.0055200\n",
      "\titers: 15, epoch: 3 | loss: 0.7384611\n",
      "\titers: 30, epoch: 3 | loss: 0.8869678\n",
      "\titers: 45, epoch: 3 | loss: 1.4037942\n",
      "\titers: 60, epoch: 3 | loss: 0.7371203\n",
      "\titers: 75, epoch: 3 | loss: 0.8020715\n",
      "Epoch: 3 cost time: 3.9961256980895996\n",
      "loss_pred:0.8419001675271368\n",
      "loss entropy:0.022095771918862302\n",
      "loss smooth:0.09618353495350132\n",
      "Epoch: 3 | Train Loss: 0.9601795\n",
      "\titers: 15, epoch: 4 | loss: 0.8312268\n",
      "\titers: 30, epoch: 4 | loss: 0.6337777\n",
      "\titers: 45, epoch: 4 | loss: 0.9558143\n",
      "\titers: 60, epoch: 4 | loss: 1.1184993\n",
      "\titers: 75, epoch: 4 | loss: 0.7809139\n",
      "Epoch: 4 cost time: 3.8805465698242188\n",
      "loss_pred:0.8181532482048134\n",
      "loss entropy:0.0006776041648418367\n",
      "loss smooth:0.07709745936966561\n",
      "Epoch: 4 | Train Loss: 0.8959283\n",
      "\titers: 15, epoch: 5 | loss: 0.7435282\n",
      "\titers: 30, epoch: 5 | loss: 1.0463336\n",
      "\titers: 45, epoch: 5 | loss: 0.9022618\n",
      "\titers: 60, epoch: 5 | loss: 0.7099116\n",
      "\titers: 75, epoch: 5 | loss: 0.5730528\n",
      "Epoch: 5 cost time: 3.987643241882324\n",
      "loss_pred:0.7760076933092885\n",
      "loss entropy:0.004151576646348336\n",
      "loss smooth:0.06331969637955938\n",
      "Epoch: 5 | Train Loss: 0.8434790\n",
      "\titers: 15, epoch: 6 | loss: 1.2816601\n",
      "\titers: 30, epoch: 6 | loss: 0.7749825\n",
      "\titers: 45, epoch: 6 | loss: 0.5763744\n",
      "\titers: 60, epoch: 6 | loss: 0.6538262\n",
      "\titers: 75, epoch: 6 | loss: 0.6271905\n",
      "Epoch: 6 cost time: 3.9578750133514404\n",
      "loss_pred:0.7264880116109724\n",
      "loss entropy:0.021475277617323475\n",
      "loss smooth:0.05765608572340631\n",
      "Epoch: 6 | Train Loss: 0.8056194\n",
      "\titers: 15, epoch: 7 | loss: 0.8613074\n",
      "\titers: 30, epoch: 7 | loss: 0.6979578\n",
      "\titers: 45, epoch: 7 | loss: 0.6712750\n",
      "\titers: 60, epoch: 7 | loss: 0.7320991\n",
      "\titers: 75, epoch: 7 | loss: 0.8037471\n",
      "Epoch: 7 cost time: 4.195734024047852\n",
      "loss_pred:0.71298060208172\n",
      "loss entropy:0.1412658561786313\n",
      "loss smooth:0.07841606215610132\n",
      "Epoch: 7 | Train Loss: 0.9326625\n",
      "\titers: 15, epoch: 8 | loss: 0.7226916\n",
      "\titers: 30, epoch: 8 | loss: 0.5925656\n",
      "\titers: 45, epoch: 8 | loss: 0.6962438\n",
      "\titers: 60, epoch: 8 | loss: 0.9002775\n",
      "\titers: 75, epoch: 8 | loss: 1.0117480\n",
      "Epoch: 8 cost time: 3.9565553665161133\n",
      "loss_pred:0.6758659780025482\n",
      "loss entropy:0.07551835388973739\n",
      "loss smooth:0.08077105115373413\n",
      "Epoch: 8 | Train Loss: 0.8321554\n",
      "\titers: 15, epoch: 9 | loss: 0.6485558\n",
      "\titers: 30, epoch: 9 | loss: 0.7465032\n",
      "\titers: 45, epoch: 9 | loss: 0.8201982\n",
      "\titers: 60, epoch: 9 | loss: 1.6195345\n",
      "\titers: 75, epoch: 9 | loss: 1.1732864\n",
      "Epoch: 9 cost time: 3.9755148887634277\n",
      "loss_pred:0.671786684494514\n",
      "loss entropy:0.26170086241030727\n",
      "loss smooth:0.08133978125723926\n",
      "Epoch: 9 | Train Loss: 1.0148273\n",
      "loading model\n",
      "total_time:2.1598470211029053\n",
      "avg_time:0.1542747872216361\n",
      "mse:0.7973358035087585, mae:0.6438835859298706, mape:455.187463760376, rmse:0.892936646938324\n"
     ]
    }
   ],
   "source": [
    "basisformer_train_test_48_pred = fit(model=curr_model, train_flag=True, test_flag=True, train_loader=train_loader, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ffc309-339b-43e4-ab87-1e1ece074e45",
   "metadata": {},
   "source": [
    "## iTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfe65f7",
   "metadata": {},
   "source": [
    "iTransformer in its architecture applies attention and feed-forward network on the inverted dimsenions. Inverted means creating the tokens along the variates, instead of creating along the timestamp. By inverting, the embedded token aggregates the global representations of series that can be more\n",
    "variate-centric and better leveraged by applying attention mechanisms for multivariate correlating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9e57e6",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "train_loader and test_loader are created and then passed to the fit function to train and test using itransformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adf6cf6e-e6dc-41fd-a14e-db5a55912360",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_model = \"itransformer\"\n",
    "\n",
    "train_seq_x, train_seq_y = create_sequences(electricity_prices_train_scaled, seq_length, pred_length, label_length, curr_model)\n",
    "train_seq_x_mark, train_seq_y_mark = create_sequences(timestamp_features_train.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "\n",
    "test_seq_x, test_seq_y = create_sequences(electricity_prices_test_scaled, seq_length, pred_length,label_length, curr_model)\n",
    "test_seq_x_mark, test_seq_y_mark = create_sequences(timestamp_features_test.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "\n",
    "train_loader = create_dataloader(train_seq_x, train_seq_y, train_seq_x_mark, train_seq_y_mark, batch_size, curr_model)\n",
    "test_loader = create_dataloader(test_seq_x, test_seq_y, test_seq_x_mark, test_seq_y_mark, batch_size, curr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca24c83-5c85-41d7-adfb-4b679d9bb9cf",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5207bb8-dd92-41b0-9f62-eb436fb7e4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost time: 1.582637071609497\n",
      "Epoch: 1, Steps: 77 | Train Loss: 0.6365194\n",
      "Validation loss decreased (inf --> 0.636519).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 1.6112422943115234\n",
      "Epoch: 2, Steps: 77 | Train Loss: 0.5127320\n",
      "Validation loss decreased (0.636519 --> 0.512732).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 1.5666236877441406\n",
      "Epoch: 3, Steps: 77 | Train Loss: 0.4534520\n",
      "Validation loss decreased (0.512732 --> 0.453452).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 1.5693845748901367\n",
      "Epoch: 4, Steps: 77 | Train Loss: 0.4236801\n",
      "Validation loss decreased (0.453452 --> 0.423680).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 1.5648770332336426\n",
      "Epoch: 5, Steps: 77 | Train Loss: 0.4066485\n",
      "Validation loss decreased (0.423680 --> 0.406649).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 1.598283290863037\n",
      "Epoch: 6, Steps: 77 | Train Loss: 0.3975171\n",
      "Validation loss decreased (0.406649 --> 0.397517).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 1.5721781253814697\n",
      "Epoch: 7, Steps: 77 | Train Loss: 0.3934848\n",
      "Validation loss decreased (0.397517 --> 0.393485).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 1.5744471549987793\n",
      "Epoch: 8, Steps: 77 | Train Loss: 0.3900960\n",
      "Validation loss decreased (0.393485 --> 0.390096).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 1.5774586200714111\n",
      "Epoch: 9, Steps: 77 | Train Loss: 0.3857381\n",
      "Validation loss decreased (0.390096 --> 0.385738).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 1.5851922035217285\n",
      "Epoch: 10, Steps: 77 | Train Loss: 0.3897303\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 1.57468843460083\n",
      "Epoch: 11, Steps: 77 | Train Loss: 0.3900299\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 1.61077880859375\n",
      "Epoch: 12, Steps: 77 | Train Loss: 0.3876725\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test shape: (14, 24, 48, 24) (14, 24, 48, 24)\n",
      "test shape: (336, 48, 24) (336, 48, 24)\n",
      "mse:0.5714368224143982, mae:0.5443888902664185, mape:5.017033100128174, rmse0.7559344172477722:\n"
     ]
    }
   ],
   "source": [
    "itransformer_train_test_48_pred = fit(model=curr_model, train_flag=True, test_flag=True, train_loader=train_loader, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df342f0-dd41-4272-b6fb-7dc794457fd8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Increasing predinction length\n",
    "In order to get more comprehensive results transformer models are going to be tested "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0af080ea-863d-4d4d-a215-2502751e2cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit (model, train_flag, test_flag, train_loader=None, test_loader=None, pretrained_model=None):\n",
    "    '''Fits a transformer model to the train and/or test loaders\n",
    "    \n",
    "    model - \"basis_former\", \"itransformer\", \"ns_autoformer\"\n",
    "    \n",
    "    train_flag: typ(bool) - True: to train the model on train_loader, False: if pretrained_model is passed\n",
    "    \n",
    "    test_flag: typ(bool) - True: to test on test_loader, False: if only training\n",
    "    \n",
    "    pretrained_model - pass a pretrained model if available to be fitted on a test_loader. \n",
    "    eg. fit(basis_former, train_flag=False, test_flag=True, test_loader=test_loader, pretrained_model=model)\n",
    "    '''\n",
    "    \n",
    "    if curr_model == 'basis_former':\n",
    "        # Code for Basisforme\n",
    "\n",
    "        import Basisformer.model\n",
    "        importlib.reload(Basisformer.model)\n",
    "        from Basisformer.model import Basisformer\n",
    "\n",
    "        import Basisformer.main\n",
    "        importlib.reload(Basisformer.main)\n",
    "        from Basisformer.main import parse_args, model_setup, log_and_print\n",
    "        importlib.reload(Basisformer.pyplot)\n",
    "\n",
    "        class Args:\n",
    "            is_training = True\n",
    "            data_path = 'data'\n",
    "            device = 0\n",
    "            num_workers = 10\n",
    "            features = 'M'\n",
    "            freq = 'h'\n",
    "            seq_len = 96\n",
    "            pred_len = 96\n",
    "            heads = 16\n",
    "            d_model = 512\n",
    "            N = 10\n",
    "            block_nums = 2\n",
    "            bottleneck = 2\n",
    "            map_bottleneck = 20\n",
    "            train_epochs = 50\n",
    "            batch_size = 24\n",
    "            learning_rate = 0.0001\n",
    "            tau = 0.07\n",
    "            loss_weight_prediction = 1.0\n",
    "            loss_weight_infonce = 1.0\n",
    "            loss_weight_smooth = 1.0\n",
    "            check_point = 'checkpoint'\n",
    "            patience = 3\n",
    "\n",
    "        args = Args()\n",
    "\n",
    "        # Set up device\n",
    "        device = torch.device(f\"cuda:{args.device}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Set up model\n",
    "        model = model_setup(args, device)\n",
    "        \n",
    "        if pretrained_model == None:\n",
    "            # Set up model\n",
    "            model = model_setup(args, device)\n",
    "\n",
    "        else:\n",
    "            model = pretrained_model\n",
    "\n",
    "        \n",
    "        if train_flag:\n",
    "            import Basisformer.model\n",
    "            importlib.reload(Basisformer.model)\n",
    "            from Basisformer.model import Basisformer\n",
    "\n",
    "            import Basisformer.main\n",
    "            importlib.reload(Basisformer.main)\n",
    "            from Basisformer.main import train\n",
    "\n",
    "\n",
    "            record_dir = os.path.join('records', args.data_path.split('.')[0], 'features_' + args.features,\n",
    "                                    'seq_len' + str(args.seq_len) + ',' + 'pred_len' + str(args.pred_len))\n",
    "            \n",
    "            if train_loader == None:\n",
    "                return 'train_loader not found'\n",
    "\n",
    "            # Call the train function\n",
    "            train(model, train_loader, args, device, record_dir)\n",
    "            \n",
    "        else:\n",
    "            if pretrained_model == None:\n",
    "                return 'model not found which is required for testing'\n",
    "            \n",
    "        if test_flag :\n",
    "            import Basisformer.main\n",
    "            importlib.reload(Basisformer.main)\n",
    "            from Basisformer.main import test\n",
    "            \n",
    "            if test_loader == None:\n",
    "                return 'test_loader not found'\n",
    "\n",
    "            test(model, test_loader, args, device, record_dir)\n",
    "        return model\n",
    "            \n",
    "    \n",
    "    elif curr_model == 'itransformer':\n",
    "        # code for itransformer\n",
    "        \n",
    "        import iTransformer.experiment\n",
    "        importlib.reload(iTransformer.experiment)\n",
    "        from iTransformer.experiment import Exp_Long_Term_Forecast\n",
    "        \n",
    "        class Args:\n",
    "            is_training = 1\n",
    "            model_id = 'iTransformer_train'\n",
    "            model = 'iTransformer'\n",
    "            data = 'all_countries'\n",
    "            features = 'M'\n",
    "            target = 'OT'\n",
    "            freq = 'h'\n",
    "            checkpoints = './checkpoints/'\n",
    "            seq_len = 96\n",
    "            label_len = 48\n",
    "            pred_len = 96\n",
    "            enc_in = 24\n",
    "            dec_in = 24\n",
    "            c_out = 24\n",
    "            d_model = 512\n",
    "            n_heads = 8\n",
    "            e_layers = 2\n",
    "            d_layers = 1\n",
    "            d_ff = 2048\n",
    "            moving_avg = 25\n",
    "            factor = 1\n",
    "            distil = True\n",
    "            dropout = 0.05\n",
    "            embed = 'timeF'\n",
    "            activation = 'gelu'\n",
    "            output_attention = False\n",
    "            do_predict = True\n",
    "            num_workers = 10\n",
    "            itr = 2\n",
    "            train_epochs = 50\n",
    "            batch_size = 24\n",
    "            patience = 3\n",
    "            learning_rate = 0.0001\n",
    "            des = 'test'\n",
    "            loss = 'mse'\n",
    "            lradj = 'type1'\n",
    "            use_amp = False\n",
    "            use_gpu = True if torch.cuda.is_available() else False\n",
    "            gpu = 0\n",
    "            use_multi_gpu = False\n",
    "            devices = '0,1,2,3'\n",
    "            exp_name = 'MTSF'\n",
    "            channel_independence = False\n",
    "            inverse = False\n",
    "            class_strategy = 'projection'\n",
    "            target_root_path = './data'\n",
    "            target_data_path = 'all_countries'\n",
    "            efficient_training = False\n",
    "            use_norm = True\n",
    "            partial_start_index = 0\n",
    "            seed = 2021\n",
    "            p_hidden_dims = [128, 128]\n",
    "            p_hidden_layers = 2\n",
    "\n",
    "        args = Args()\n",
    "        \n",
    "        if pretrained_model == None:\n",
    "            # Initialize the experiment\n",
    "            exp = Exp_Long_Term_Forecast(args)\n",
    "\n",
    "        else:\n",
    "            return 'pretrained not valid for iTransformer and ns_autoformer'\n",
    "\n",
    "        # Define the settings\n",
    "        setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}'.format(\n",
    "            args.model_id, args.model, args.data, args.features, args.seq_len, args.label_len,\n",
    "            args.pred_len, args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff,\n",
    "            args.factor, args.embed, args.distil, args.des, 0)\n",
    "        \n",
    "        if train_flag:\n",
    "            Exp_Long_Term_Forecast.train(self=exp, train_loader=train_loader, setting=setting)\n",
    "        \n",
    "        if test_flag:\n",
    "            Exp_Long_Term_Forecast.test(self=exp, test_loader=test_loader, setting=setting, test=0)\n",
    "        return exp.model\n",
    "    \n",
    "    elif curr_model == 'ns_autoformer':\n",
    "        # code for itransformer\n",
    "        import ns_Autoformer.ns_Autoformer\n",
    "        importlib.reload(ns_Autoformer.ns_Autoformer)\n",
    "        from ns_Autoformer.ns_Autoformer import Model\n",
    "        \n",
    "        from ns_Autoformer.main import Exp_Main\n",
    "\n",
    "        class Args:\n",
    "            is_training = 1\n",
    "            model_id = 'ns_autoformer_train'\n",
    "            model = 'ns_Autoformer'\n",
    "            features = 'M'\n",
    "            target = 'OT'\n",
    "            freq = 'h'\n",
    "            checkpoints = './checkpoints/'\n",
    "            seq_len = 96\n",
    "            label_len = 48\n",
    "            pred_len = 96\n",
    "            enc_in = 24\n",
    "            dec_in = 24\n",
    "            c_out = 24\n",
    "            d_model = 512\n",
    "            n_heads = 8\n",
    "            e_layers = 2\n",
    "            d_layers = 1\n",
    "            d_ff = 2048\n",
    "            moving_avg = 25\n",
    "            factor = 1\n",
    "            distil = True\n",
    "            dropout = 0.05\n",
    "            embed = 'timeF'\n",
    "            activation = 'gelu'\n",
    "            output_attention = False\n",
    "            do_predict = True\n",
    "            num_workers = 10\n",
    "            itr = 2\n",
    "            train_epochs = 50\n",
    "            batch_size = 24\n",
    "            patience = 3\n",
    "            learning_rate = 0.0001\n",
    "            des = 'test'\n",
    "            loss = 'mse'\n",
    "            lradj = 'type1'\n",
    "            use_amp = False\n",
    "            use_gpu = True if torch.cuda.is_available() else False\n",
    "            gpu = 0\n",
    "            use_multi_gpu = False\n",
    "            devices = '0,1,2,3'\n",
    "            seed = 2021\n",
    "            p_hidden_dims = [128, 128]\n",
    "            p_hidden_layers = 2\n",
    "\n",
    "        args = Args()\n",
    "        \n",
    "        if pretrained_model == None:\n",
    "            # Initialize the experiment\n",
    "            exp = Exp_Main(args)\n",
    "\n",
    "        # Define the setting string\n",
    "        setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}'.format(\n",
    "            args.model_id, args.model, args.features, args.seq_len, args.label_len,\n",
    "            args.pred_len, args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff,\n",
    "            args.factor, args.embed, args.distil, args.des, 0)\n",
    "        \n",
    "        if train_flag:\n",
    "            Exp_Main.train(self=exp, train_loader=train_loader, setting=setting)\n",
    "        \n",
    "        if test_flag:\n",
    "            Exp_Main.test(self=exp, test_loader=test_loader, setting=setting, test=0)\n",
    "        return exp.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14fd0252-f4f1-4390-a1f0-0d4d0eed4c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 96\n",
    "pred_length = 96 ## new\n",
    "label_length = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f91c4eab-750e-4648-a953-43717db0424b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "Epoch: 1 cost time: 8.146090269088745\n",
      "Epoch: 1, Steps: 75 | Train Loss: 1.3117549\n",
      "Validation loss decreased (inf --> 1.311755).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 8.107336282730103\n",
      "Epoch: 2, Steps: 75 | Train Loss: 0.8179602\n",
      "Validation loss decreased (1.311755 --> 0.817960).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 8.109177589416504\n",
      "Epoch: 3, Steps: 75 | Train Loss: 0.7076564\n",
      "Validation loss decreased (0.817960 --> 0.707656).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 8.145787954330444\n",
      "Epoch: 4, Steps: 75 | Train Loss: 0.6070210\n",
      "Validation loss decreased (0.707656 --> 0.607021).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 8.135039329528809\n",
      "Epoch: 5, Steps: 75 | Train Loss: 0.5709493\n",
      "Validation loss decreased (0.607021 --> 0.570949).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 8.174699544906616\n",
      "Epoch: 6, Steps: 75 | Train Loss: 0.5522798\n",
      "Validation loss decreased (0.570949 --> 0.552280).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 8.139138221740723\n",
      "Epoch: 7, Steps: 75 | Train Loss: 0.5429381\n",
      "Validation loss decreased (0.552280 --> 0.542938).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 8.102447748184204\n",
      "Epoch: 8, Steps: 75 | Train Loss: 0.5421850\n",
      "Validation loss decreased (0.542938 --> 0.542185).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 8.133931159973145\n",
      "Epoch: 9, Steps: 75 | Train Loss: 0.5400044\n",
      "Validation loss decreased (0.542185 --> 0.540004).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 8.124322414398193\n",
      "Epoch: 10, Steps: 75 | Train Loss: 0.5395526\n",
      "Validation loss decreased (0.540004 --> 0.539553).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 8.125311851501465\n",
      "Epoch: 11, Steps: 75 | Train Loss: 0.5365759\n",
      "Validation loss decreased (0.539553 --> 0.536576).  Saving model ...\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 8.10765790939331\n",
      "Epoch: 12, Steps: 75 | Train Loss: 0.5370721\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 7.987699747085571\n",
      "Epoch: 13, Steps: 75 | Train Loss: 0.5349100\n",
      "Validation loss decreased (0.536576 --> 0.534910).  Saving model ...\n",
      "Updating learning rate to 2.44140625e-08\n",
      "Epoch: 14 cost time: 8.139370203018188\n",
      "Epoch: 14, Steps: 75 | Train Loss: 0.5376703\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.220703125e-08\n",
      "Epoch: 15 cost time: 8.17630410194397\n",
      "Epoch: 15, Steps: 75 | Train Loss: 0.5383123\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.103515625e-09\n",
      "Epoch: 16 cost time: 8.168017148971558\n",
      "Epoch: 16, Steps: 75 | Train Loss: 0.5372956\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test shape: (12, 24, 96, 24) (12, 24, 96, 24)\n",
      "test shape: (288, 96, 24) (288, 96, 24)\n",
      "mse:0.9955783486366272, mae:0.747149646282196, mape:6.445919990539551, rmse:0.9977867007255554\n"
     ]
    }
   ],
   "source": [
    "curr_model = \"ns_autoformer\" \n",
    "\n",
    "train_seq_x, train_seq_y = create_sequences(electricity_prices_train_scaled, seq_length, pred_length, label_length, curr_model)\n",
    "train_seq_x_mark, train_seq_y_mark = create_sequences(timestamp_features_train.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "test_seq_x, test_seq_y = create_sequences(electricity_prices_test_scaled, seq_length, pred_length,label_length, curr_model)\n",
    "test_seq_x_mark, test_seq_y_mark = create_sequences(timestamp_features_test.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "train_loader = create_dataloader(train_seq_x, train_seq_y, train_seq_x_mark, train_seq_y_mark, batch_size, curr_model)\n",
    "test_loader = create_dataloader(test_seq_x, test_seq_y, test_seq_x_mark, test_seq_y_mark, batch_size, curr_model)\n",
    "\n",
    "ns_autoformer_train_test_96_pred = fit(model=curr_model, train_flag=True, test_flag=True, train_loader=train_loader, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00289f5f-8ceb-4581-aa29-4fb08484ba0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "\titers: 15, epoch: 1 | loss: 3.5914116\n",
      "\titers: 30, epoch: 1 | loss: 2.3875632\n",
      "\titers: 45, epoch: 1 | loss: 1.2033758\n",
      "\titers: 60, epoch: 1 | loss: 1.3070829\n",
      "\titers: 75, epoch: 1 | loss: 1.5071530\n",
      "Epoch: 1 cost time: 3.931365966796875\n",
      "loss_pred:0.9221487402915954\n",
      "loss entropy:1.207003004423653\n",
      "loss smooth:0.12646596511205038\n",
      "Epoch: 1 | Train Loss: 2.2556177\n",
      "\titers: 15, epoch: 2 | loss: 1.0492678\n",
      "\titers: 30, epoch: 2 | loss: 0.9034404\n",
      "\titers: 45, epoch: 2 | loss: 1.2038679\n",
      "\titers: 60, epoch: 2 | loss: 0.9914823\n",
      "\titers: 75, epoch: 2 | loss: 1.1144783\n",
      "Epoch: 2 cost time: 3.923609495162964\n",
      "loss_pred:0.9200511884689331\n",
      "loss entropy:0.04152901978869825\n",
      "loss smooth:0.10395175735155741\n",
      "Epoch: 2 | Train Loss: 1.0655320\n",
      "\titers: 15, epoch: 3 | loss: 1.5872799\n",
      "\titers: 30, epoch: 3 | loss: 1.3433249\n",
      "\titers: 45, epoch: 3 | loss: 0.7150430\n",
      "\titers: 60, epoch: 3 | loss: 0.7334359\n",
      "\titers: 75, epoch: 3 | loss: 1.3549538\n",
      "Epoch: 3 cost time: 3.9604833126068115\n",
      "loss_pred:0.911643439133962\n",
      "loss entropy:0.016137023216467098\n",
      "loss smooth:0.09243941058715184\n",
      "Epoch: 3 | Train Loss: 1.0202199\n",
      "\titers: 15, epoch: 4 | loss: 0.5787796\n",
      "\titers: 30, epoch: 4 | loss: 1.1881697\n",
      "\titers: 45, epoch: 4 | loss: 1.4257400\n",
      "\titers: 60, epoch: 4 | loss: 0.8035695\n",
      "\titers: 75, epoch: 4 | loss: 0.6550869\n",
      "Epoch: 4 cost time: 3.9406795501708984\n",
      "loss_pred:0.8763228944937388\n",
      "loss entropy:0.025925959950933695\n",
      "loss smooth:0.08129384209712347\n",
      "Epoch: 4 | Train Loss: 0.9835427\n",
      "\titers: 15, epoch: 5 | loss: 1.0194129\n",
      "\titers: 30, epoch: 5 | loss: 1.3769654\n",
      "\titers: 45, epoch: 5 | loss: 0.9843433\n",
      "\titers: 60, epoch: 5 | loss: 1.6393489\n",
      "\titers: 75, epoch: 5 | loss: 0.9923453\n",
      "Epoch: 5 cost time: 3.9680895805358887\n",
      "loss_pred:0.8431431190172831\n",
      "loss entropy:0.21458914558460027\n",
      "loss smooth:0.0863321927189827\n",
      "Epoch: 5 | Train Loss: 1.1440645\n",
      "\titers: 15, epoch: 6 | loss: 0.9696512\n",
      "\titers: 30, epoch: 6 | loss: 1.1011256\n",
      "\titers: 45, epoch: 6 | loss: 1.2770380\n",
      "\titers: 60, epoch: 6 | loss: 0.6918973\n",
      "\titers: 75, epoch: 6 | loss: 0.8068958\n",
      "Epoch: 6 cost time: 4.050212144851685\n",
      "loss_pred:0.7854657224814097\n",
      "loss entropy:0.027740011955807293\n",
      "loss smooth:0.09250580420096716\n",
      "Epoch: 6 | Train Loss: 0.9057115\n",
      "\titers: 15, epoch: 7 | loss: 0.6799431\n",
      "\titers: 30, epoch: 7 | loss: 0.5934665\n",
      "\titers: 45, epoch: 7 | loss: 0.7720206\n",
      "\titers: 60, epoch: 7 | loss: 0.6382526\n",
      "\titers: 75, epoch: 7 | loss: 0.9970226\n",
      "Epoch: 7 cost time: 3.925044059753418\n",
      "loss_pred:0.7409123090902964\n",
      "loss entropy:0.0028129817438549104\n",
      "loss smooth:0.08704188674688339\n",
      "Epoch: 7 | Train Loss: 0.8307672\n",
      "\titers: 15, epoch: 8 | loss: 0.9135112\n",
      "\titers: 30, epoch: 8 | loss: 0.9413337\n",
      "\titers: 45, epoch: 8 | loss: 0.5990620\n",
      "\titers: 60, epoch: 8 | loss: 0.5880913\n",
      "\titers: 75, epoch: 8 | loss: 0.8836192\n",
      "Epoch: 8 cost time: 3.946117877960205\n",
      "loss_pred:0.7042278261979421\n",
      "loss entropy:4.6259789624147805e-05\n",
      "loss smooth:0.08023878922065099\n",
      "Epoch: 8 | Train Loss: 0.7845129\n",
      "\titers: 15, epoch: 9 | loss: 0.5121748\n",
      "\titers: 30, epoch: 9 | loss: 0.9402267\n",
      "\titers: 45, epoch: 9 | loss: 0.7992386\n",
      "\titers: 60, epoch: 9 | loss: 0.6285238\n",
      "\titers: 75, epoch: 9 | loss: 0.8481596\n",
      "Epoch: 9 cost time: 3.8753812313079834\n",
      "loss_pred:0.6652741583188375\n",
      "loss entropy:0.002138495547670799\n",
      "loss smooth:0.07434742748737336\n",
      "Epoch: 9 | Train Loss: 0.7417601\n",
      "\titers: 15, epoch: 10 | loss: 0.7235032\n",
      "\titers: 30, epoch: 10 | loss: 0.9880420\n",
      "\titers: 45, epoch: 10 | loss: 0.6737900\n",
      "\titers: 60, epoch: 10 | loss: 0.7285081\n",
      "\titers: 75, epoch: 10 | loss: 0.5901739\n",
      "Epoch: 10 cost time: 3.961155891418457\n",
      "loss_pred:0.6318065567811331\n",
      "loss entropy:0.0016640935665334059\n",
      "loss smooth:0.06959215432405472\n",
      "Epoch: 10 | Train Loss: 0.7030628\n",
      "\titers: 15, epoch: 11 | loss: 0.7132707\n",
      "\titers: 30, epoch: 11 | loss: 0.4605257\n",
      "\titers: 45, epoch: 11 | loss: 0.8152763\n",
      "\titers: 60, epoch: 11 | loss: 0.9954986\n",
      "\titers: 75, epoch: 11 | loss: 0.5021169\n",
      "Epoch: 11 cost time: 4.051635265350342\n",
      "loss_pred:0.6055363750457764\n",
      "loss entropy:0.003671237610965221\n",
      "loss smooth:0.06479031503200532\n",
      "Epoch: 11 | Train Loss: 0.6739979\n",
      "\titers: 15, epoch: 12 | loss: 0.7472960\n",
      "\titers: 30, epoch: 12 | loss: 0.6672702\n",
      "\titers: 45, epoch: 12 | loss: 0.7330966\n",
      "\titers: 60, epoch: 12 | loss: 0.6081350\n",
      "\titers: 75, epoch: 12 | loss: 0.9436031\n",
      "Epoch: 12 cost time: 4.02352499961853\n",
      "loss_pred:0.5779145844777425\n",
      "loss entropy:0.0025272175232116507\n",
      "loss smooth:0.0620915761590004\n",
      "Epoch: 12 | Train Loss: 0.6425334\n",
      "\titers: 15, epoch: 13 | loss: 0.5238589\n",
      "\titers: 30, epoch: 13 | loss: 0.8690646\n",
      "\titers: 45, epoch: 13 | loss: 0.9140681\n",
      "\titers: 60, epoch: 13 | loss: 1.2200127\n",
      "\titers: 75, epoch: 13 | loss: 0.5818688\n",
      "Epoch: 13 cost time: 3.930607318878174\n",
      "loss_pred:0.5778569630781809\n",
      "loss entropy:0.0961055273002262\n",
      "loss smooth:0.06316179752349854\n",
      "Epoch: 13 | Train Loss: 0.7371243\n",
      "\titers: 15, epoch: 14 | loss: 1.4105200\n",
      "\titers: 30, epoch: 14 | loss: 0.8470454\n",
      "\titers: 45, epoch: 14 | loss: 0.8290997\n",
      "\titers: 60, epoch: 14 | loss: 0.7068402\n",
      "\titers: 75, epoch: 14 | loss: 0.8356500\n",
      "Epoch: 14 cost time: 3.969853401184082\n",
      "loss_pred:0.6570631976922353\n",
      "loss entropy:0.3497520273658649\n",
      "loss smooth:0.07765588849782944\n",
      "Epoch: 14 | Train Loss: 1.0844711\n",
      "\titers: 15, epoch: 15 | loss: 0.9367067\n",
      "\titers: 30, epoch: 15 | loss: 0.6118770\n",
      "\titers: 45, epoch: 15 | loss: 0.6502627\n",
      "\titers: 60, epoch: 15 | loss: 0.8444495\n",
      "\titers: 75, epoch: 15 | loss: 0.8502536\n",
      "Epoch: 15 cost time: 3.997095823287964\n",
      "loss_pred:0.5879541091124216\n",
      "loss entropy:0.007425072286058789\n",
      "loss smooth:0.0780957152446111\n",
      "Epoch: 15 | Train Loss: 0.6734749\n",
      "loading model\n",
      "total_time:1.989030361175537\n",
      "avg_time:0.16575253009796143\n",
      "mse:0.7851323485374451, mae:0.6544158458709717, mape:481.8103790283203, rmse:0.8860769271850586\n"
     ]
    }
   ],
   "source": [
    "curr_model = \"basis_former\" \n",
    "\n",
    "train_seq_x, train_seq_y = create_sequences(electricity_prices_train_scaled, seq_length, pred_length, label_length, curr_model)\n",
    "train_seq_x_mark, train_seq_y_mark = create_sequences(timestamp_features_train.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "\n",
    "test_seq_x, test_seq_y = create_sequences(electricity_prices_test_scaled, seq_length, pred_length,label_length, curr_model)\n",
    "test_seq_x_mark, test_seq_y_mark = create_sequences(timestamp_features_test.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "\n",
    "train_loader = create_dataloader(train_seq_x, train_seq_y, train_seq_x_mark, train_seq_y_mark, batch_size, curr_model)\n",
    "test_loader = create_dataloader(test_seq_x, test_seq_y, test_seq_x_mark, test_seq_y_mark, batch_size, curr_model)\n",
    "\n",
    "basisformer_train_test_96_pred = fit(model=curr_model, train_flag=True, test_flag=True, train_loader=train_loader, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db84f36a-31ea-4a5c-9129-f4ec18a86269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "Epoch: 1 cost time: 1.5678038597106934\n",
      "Epoch: 1, Steps: 75 | Train Loss: 0.7505169\n",
      "Validation loss decreased (inf --> 0.750517).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 1.531540870666504\n",
      "Epoch: 2, Steps: 75 | Train Loss: 0.6204305\n",
      "Validation loss decreased (0.750517 --> 0.620431).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 1.5764129161834717\n",
      "Epoch: 3, Steps: 75 | Train Loss: 0.5608784\n",
      "Validation loss decreased (0.620431 --> 0.560878).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 1.5272290706634521\n",
      "Epoch: 4, Steps: 75 | Train Loss: 0.5285256\n",
      "Validation loss decreased (0.560878 --> 0.528526).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 1.5751512050628662\n",
      "Epoch: 5, Steps: 75 | Train Loss: 0.5143290\n",
      "Validation loss decreased (0.528526 --> 0.514329).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 1.5692532062530518\n",
      "Epoch: 6, Steps: 75 | Train Loss: 0.5069972\n",
      "Validation loss decreased (0.514329 --> 0.506997).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 1.557462215423584\n",
      "Epoch: 7, Steps: 75 | Train Loss: 0.5054433\n",
      "Validation loss decreased (0.506997 --> 0.505443).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 1.5634560585021973\n",
      "Epoch: 8, Steps: 75 | Train Loss: 0.5026467\n",
      "Validation loss decreased (0.505443 --> 0.502647).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 1.51686692237854\n",
      "Epoch: 9, Steps: 75 | Train Loss: 0.4988172\n",
      "Validation loss decreased (0.502647 --> 0.498817).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 1.5765583515167236\n",
      "Epoch: 10, Steps: 75 | Train Loss: 0.4987860\n",
      "Validation loss decreased (0.498817 --> 0.498786).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 1.5233278274536133\n",
      "Epoch: 11, Steps: 75 | Train Loss: 0.5006859\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 1.5326056480407715\n",
      "Epoch: 12, Steps: 75 | Train Loss: 0.4992689\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 1.596125602722168\n",
      "Epoch: 13, Steps: 75 | Train Loss: 0.4985586\n",
      "Validation loss decreased (0.498786 --> 0.498559).  Saving model ...\n",
      "Updating learning rate to 2.44140625e-08\n",
      "Epoch: 14 cost time: 1.5507895946502686\n",
      "Epoch: 14, Steps: 75 | Train Loss: 0.5016180\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.220703125e-08\n",
      "Epoch: 15 cost time: 1.5354642868041992\n",
      "Epoch: 15, Steps: 75 | Train Loss: 0.4994156\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.103515625e-09\n",
      "Epoch: 16 cost time: 1.5278959274291992\n",
      "Epoch: 16, Steps: 75 | Train Loss: 0.4999094\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test shape: (12, 24, 96, 24) (12, 24, 96, 24)\n",
      "test shape: (288, 96, 24) (288, 96, 24)\n",
      "mse:0.6195731163024902, mae:0.575814425945282, mape:4.3758769035339355, rmse0.7871296405792236:\n"
     ]
    }
   ],
   "source": [
    "curr_model = \"itransformer\" \n",
    "\n",
    "train_seq_x, train_seq_y = create_sequences(electricity_prices_train_scaled, seq_length, pred_length, label_length, curr_model)\n",
    "train_seq_x_mark, train_seq_y_mark = create_sequences(timestamp_features_train.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "test_seq_x, test_seq_y = create_sequences(electricity_prices_test_scaled, seq_length, pred_length,label_length, curr_model)\n",
    "test_seq_x_mark, test_seq_y_mark = create_sequences(timestamp_features_test.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "train_loader = create_dataloader(train_seq_x, train_seq_y, train_seq_x_mark, train_seq_y_mark, batch_size, curr_model)\n",
    "test_loader = create_dataloader(test_seq_x, test_seq_y, test_seq_x_mark, test_seq_y_mark, batch_size, curr_model)\n",
    "\n",
    "itransformer_train_test_96_pred = fit(model=curr_model, train_flag=True, test_flag=True, train_loader=train_loader, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2803d193-eb4d-4ba8-b719-e2fa360e4167",
   "metadata": {},
   "source": [
    "# 3. Results - Models Performance Comparison\n",
    "\n",
    "In this section, we compare the performance of different models based on their Root Mean Squared Error (RMSE) values. \n",
    "\n",
    "The table below summarizes the RMSE and MAE values obtained from each model, providing a comparison of their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b48d07c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Model   RMSE    MAE\n",
      "0                Linear Regression  12.29   7.12\n",
      "1                             LSTM  15.60   9.70\n",
      "2                    Chronos small  33.12  28.14\n",
      "3                     Chronos base  28.81  24.11\n",
      "4  Ns_Autoformer (pred_length= 48)   0.77   0.58\n",
      "5  Ns_Autoformer (pred_length= 96)   0.99   0.74\n",
      "6    Basisformer (pred_length= 48)   0.89   0.64\n",
      "7    Basisformer (pred_length= 96)   0.88   0.65\n",
      "8   iTransformer (pred_length= 48)   0.75   0.54\n",
      "9   iTransformer (pred_length= 96)   0.78   0.57\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to hold the results\n",
    "results = {\n",
    "    'Model': ['Linear Regression', 'LSTM', \n",
    "              'Chronos small', 'Chronos base',\n",
    "              'Ns_Autoformer (pred_length= 48)',\n",
    "              'Ns_Autoformer (pred_length= 96)', \n",
    "              'Basisformer (pred_length= 48)',\n",
    "              'Basisformer (pred_length= 96)',\n",
    "              'iTransformer (pred_length= 48)',\n",
    "             'iTransformer (pred_length= 96)'],\n",
    "    'RMSE': [12.29, 15.60, 33.12, 28.81, 0.77, 0.99, 0.89, 0.88, 0.75, 0.78],\n",
    "    'MAE': [7.12, 9.70, 28.14, 24.11, 0.58, 0.74, 0.64, 0.65, 0.54, 0.57]\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results table\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0bbe9e-2ecc-49c0-bf7b-356fb6f80758",
   "metadata": {},
   "source": [
    "# 4. Outlook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "461e07e0-ce61-446b-92c4-5e6c51a3aa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## inserting these libraries here because by loading them local can crush\n",
    "import pyarrow.ipc as ipc\n",
    "from causalnex.structure.notears import from_pandas \n",
    "from causalnex.plots import plot_structure, NODE_STYLE, EDGE_STYLE \n",
    "from causalnex.structure.notears import from_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0876475-7871-4b24-b71c-4d70f4d5adea",
   "metadata": {},
   "source": [
    "## Chronos Simulation\n",
    "\n",
    "Kernel Synth is part of the Chronos pre-training with synthetic data. It uses Gaussian processes to simulate data distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb5bb54-ba52-4564-9775-05648c81013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python supporting_files_chronos/kernel-synth.py --num-series 500 --max-kernels 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c174fb6-a8cb-4ffb-b5fd-09a6d7908d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         start target._np_shape  \\\n",
      "0   2000-01-01        [1024, 3]   \n",
      "1   2000-01-01        [1024, 3]   \n",
      "2   2000-01-01        [1024, 3]   \n",
      "3   2000-01-01        [1024, 3]   \n",
      "4   2000-01-01        [1024, 3]   \n",
      "..         ...              ...   \n",
      "495 2000-01-01        [1024, 3]   \n",
      "496 2000-01-01        [1024, 3]   \n",
      "497 2000-01-01        [1024, 3]   \n",
      "498 2000-01-01        [1024, 3]   \n",
      "499 2000-01-01        [1024, 3]   \n",
      "\n",
      "                                                target  \n",
      "0    [-1.3293273404902177e-07, 1.7617705479648852e-...  \n",
      "1    [0.8820515850319665, -2.630758929416405, -0.28...  \n",
      "2    [1.0917233174006584, -0.30767090449730106, 0.1...  \n",
      "3    [-1.4419568333102197, -0.2799756872675115, -0....  \n",
      "4    [-0.8402086553986396, -1.5435372346614247, -0....  \n",
      "..                                                 ...  \n",
      "495  [5.2983733022775885, -9.044641569560579, -3.15...  \n",
      "496  [-0.7313010836303305, -0.8540684084420854, 0.9...  \n",
      "497  [-0.8684795217377739, -0.5001586491794001, 0.2...  \n",
      "498  [0.8238722298539525, -1.3771194164186111, 1.19...  \n",
      "499  [-1.0899352102176127, 1.0528479056643296, -2.3...  \n",
      "\n",
      "[500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = 'supporting_files_chronos/kernelsynth-data.arrow'\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    reader = ipc.RecordBatchFileReader(f)\n",
    "    table = reader.read_all()\n",
    "\n",
    "df_ch = table.to_pandas()\n",
    "\n",
    "print(df_ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dc4c9b-c1ed-4ed0-8703-1b8920dda5ac",
   "metadata": {},
   "source": [
    "To better see the results, plots of the first 15 simulations are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "961121e6-2507-475c-8a80-7d6eb4489466",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_series = 15 ## plotting first 15 time series\n",
    "plots_per_row = 5\n",
    "num_rows = (num_series + plots_per_row - 1) // plots_per_row\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, plots_per_row, figsize=(15, num_rows * 3))\n",
    "\n",
    "for i in range(num_series):\n",
    "    row = i // plots_per_row\n",
    "    col = i % plots_per_row\n",
    "    ax = axes[row, col]\n",
    "    ax.plot(df_ch['target'].iloc[i])\n",
    "    ax.set_title(f'Time Series {i}')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Value')\n",
    "\n",
    "# Remove any empty subplots\n",
    "#for j in range(i + 1, num_rows * plots_per_row):\n",
    "#    fig.delaxes(axes.flatten()[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8868e96d-c11f-44da-8284-5e3bdd7aa438",
   "metadata": {},
   "source": [
    "## DYNOTEARS Causal Structure\n",
    "\n",
    "DYNOTEARS is a linear causal structure learning framework. It learns the graph structure of a Dynamic Bayesian Network describing conditional dependencies between variables in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3be40c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Datetime (UTC)  Austria  Belgium  Czechia  Denmark  Estonia  \\\n",
      "80329 2024-03-01 01:00:00    58.14    58.14    58.14    41.61    49.17   \n",
      "80330 2024-03-01 02:00:00    57.83    57.83    57.83    42.03    13.00   \n",
      "80331 2024-03-01 03:00:00    58.30    58.30    58.30    52.03    14.33   \n",
      "80332 2024-03-01 04:00:00    62.49    62.49    62.49    52.52    48.04   \n",
      "80333 2024-03-01 05:00:00    71.58    71.58    71.58    54.46    71.58   \n",
      "...                   ...      ...      ...      ...      ...      ...   \n",
      "81067 2024-03-31 19:00:00    66.17    47.01    68.37    70.00    50.09   \n",
      "81068 2024-03-31 20:00:00    61.25    43.70    63.26    64.51    46.28   \n",
      "81069 2024-03-31 21:00:00    44.99    50.29    51.29    54.90    43.98   \n",
      "81070 2024-03-31 22:00:00    40.70    50.32    46.39    49.95    40.41   \n",
      "81071 2024-03-31 23:00:00    32.10    44.39    42.60    48.98    40.39   \n",
      "\n",
      "       Finland  France  Germany  Greece  ...  Netherlands  Norway  Poland  \\\n",
      "80329     0.00   58.14    58.14   58.14  ...        58.14   40.65   58.14   \n",
      "80330     0.00   57.83    57.83   57.83  ...        57.83   40.75   57.83   \n",
      "80331     0.01   58.30    58.30   58.30  ...        58.30   40.87   58.30   \n",
      "80332    20.46   62.49    62.49   62.49  ...        62.49   41.47   70.24   \n",
      "80333    23.00   71.58    71.58   71.58  ...        71.58   44.76   71.58   \n",
      "...        ...     ...      ...     ...  ...          ...     ...     ...   \n",
      "81067    50.09   26.12    70.00   65.81  ...        65.20   57.09   69.99   \n",
      "81068    46.28   24.53    64.51   60.90  ...        60.55   55.85   72.43   \n",
      "81069    43.98   32.35    54.90   48.07  ...        54.90   53.50   75.27   \n",
      "81070    40.41   40.70    49.95   43.45  ...        51.03   51.08   68.70   \n",
      "81071    40.39   32.10    48.98   37.15  ...        48.98   48.13   68.69   \n",
      "\n",
      "       Portugal  Romania  Slovakia  Slovenia  Spain  Sweden  Switzerland  \n",
      "80329      0.20    58.14     58.14     58.14   0.20   11.00        63.90  \n",
      "80330      0.10    57.83     57.83     57.83   0.10   13.00        64.11  \n",
      "80331      0.01    58.30     58.30     58.30   0.01   14.33        63.99  \n",
      "80332      0.50    62.49     62.49     62.49   0.50   20.46        63.99  \n",
      "80333      3.00    71.58     71.58     71.58   3.00   23.00        73.90  \n",
      "...         ...      ...       ...       ...    ...     ...          ...  \n",
      "81067      3.20    65.81     67.09     63.43   3.20   50.09        74.52  \n",
      "81068      3.20    60.90     62.10     58.74   3.20   46.28        67.31  \n",
      "81069      1.63    48.07     49.03     46.61   1.63   43.98        62.86  \n",
      "81070      0.70    43.45     44.32     42.13   0.70   40.41        44.23  \n",
      "81071      0.02    37.15     38.77     34.75   0.02   40.39        40.01  \n",
      "\n",
      "[743 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "start_date = '2024-03-01 01:00:00' ## as it takes too long to load filtering data only for 1 month of data\n",
    "electricity_prices_df_filt = electricity_prices_df[electricity_prices_df['Datetime (UTC)'] >= pd.to_datetime(start_date)]\n",
    "print(electricity_prices_df_filt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da29ffad-aca2-4b72-bfd2-9136ddaef936",
   "metadata": {},
   "source": [
    "Creating a causal graph for the data according to the documentation provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa08f91-f2d9-4b70-a7ab-b6b15d20629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_str = electricity_prices_df_filt.drop(columns=['Datetime (UTC)'])\n",
    "sm = from_pandas(df_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b7a18a-5c45-4440-b616-9c6f949c4db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = plot_structure(\n",
    "    sm,\n",
    "    all_node_attributes=NODE_STYLE.WEAK,\n",
    "    all_edge_attributes=EDGE_STYLE.WEAK,\n",
    ")\n",
    "\n",
    "viz.toggle_physics(False)\n",
    "viz.show(\"supporting_files_dynotears/01_fully_connected.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297ebd63-03d7-45ab-8815-f4417d6ffeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.remove_edges_below_threshold(0.8)\n",
    "viz = plot_structure(\n",
    "    sm,\n",
    "    all_node_attributes=NODE_STYLE.WEAK,\n",
    "    all_edge_attributes=EDGE_STYLE.WEAK,\n",
    ")\n",
    "viz.show(\"supporting_files_dynotears/01_thresholded.html\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
