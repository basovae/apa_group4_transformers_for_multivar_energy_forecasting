{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c73133af-7360-4762-9048-3aa0b3bb71b4",
   "metadata": {},
   "source": [
    "### Agenda:\n",
    "1. Data Loading & Preprocessing\n",
    "   - Missing values handling\n",
    "   - Date features creation\n",
    "   - Train/Test split\n",
    "   - Scaling\n",
    "   - Sequences\n",
    "   - Data Loader (incl. indexing for Basisformer)\n",
    "2. Experimental Design\n",
    "    - Benchmark Models\n",
    "      - Linear Regression\n",
    "      - LSTM\n",
    "    - Pre trained Chronos\n",
    "    - Transformers\n",
    "      - Unification\n",
    "      - Non-Stationary Autoformer\n",
    "      - BasisFormer\n",
    "      - iTransformer\n",
    "3. Results\n",
    "4. Outlook\n",
    "   - Chronos Simulation Framework\n",
    "   - DYNOTEARS Causal Structure\n",
    "   - Non linear causal structure\n",
    "   - Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "veljByFX557b",
   "metadata": {
    "id": "veljByFX557b"
   },
   "outputs": [],
   "source": [
    "#!pip install torch==2.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370ef93a-0cd3-471b-a6d1-1b3ed3da369c",
   "metadata": {},
   "source": [
    "# 1. Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b1c78b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "cad7a09c-a0e5-4eff-b76b-752fcb66665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "2f4de819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.weight_norm as wn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "98a448b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import argparse\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "8c0948b2-e0b7-4862-9a96-8f186c1d4244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "iGtogtkxzGiT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "iGtogtkxzGiT",
    "outputId": "d63b1548-a355-4ac8-89ed-fc0029c44b31"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>ISO3 Code</th>\n",
       "      <th>Datetime (UTC)</th>\n",
       "      <th>Datetime (Local)</th>\n",
       "      <th>Price (EUR/MWhe)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>2015-01-01 01:00:00</td>\n",
       "      <td>17.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>2015-01-01 01:00:00</td>\n",
       "      <td>2015-01-01 02:00:00</td>\n",
       "      <td>15.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>2015-01-01 02:00:00</td>\n",
       "      <td>2015-01-01 03:00:00</td>\n",
       "      <td>16.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>2015-01-01 03:00:00</td>\n",
       "      <td>2015-01-01 04:00:00</td>\n",
       "      <td>17.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>2015-01-01 04:00:00</td>\n",
       "      <td>2015-01-01 05:00:00</td>\n",
       "      <td>16.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country ISO3 Code       Datetime (UTC)     Datetime (Local)  \\\n",
       "0  Austria       AUT  2015-01-01 00:00:00  2015-01-01 01:00:00   \n",
       "1  Austria       AUT  2015-01-01 01:00:00  2015-01-01 02:00:00   \n",
       "2  Austria       AUT  2015-01-01 02:00:00  2015-01-01 03:00:00   \n",
       "3  Austria       AUT  2015-01-01 03:00:00  2015-01-01 04:00:00   \n",
       "4  Austria       AUT  2015-01-01 04:00:00  2015-01-01 05:00:00   \n",
       "\n",
       "   Price (EUR/MWhe)  \n",
       "0             17.93  \n",
       "1             15.17  \n",
       "2             16.38  \n",
       "3             17.38  \n",
       "4             16.38  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##file_path = '/content/all_countries.csv' ## colab path\n",
    "file_path = 'data/all_countries.csv' ## jupyter path\n",
    "df = pd.read_csv(file_path)\n",
    "df = pd.DataFrame(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "vQW9jbwq4lFG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "vQW9jbwq4lFG",
    "outputId": "e9aa57ef-18a2-4243-cd79-51b284512116"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Country</th>\n",
       "      <th>Austria</th>\n",
       "      <th>Belgium</th>\n",
       "      <th>Bulgaria</th>\n",
       "      <th>Croatia</th>\n",
       "      <th>Czechia</th>\n",
       "      <th>Denmark</th>\n",
       "      <th>Estonia</th>\n",
       "      <th>Finland</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>...</th>\n",
       "      <th>Norway</th>\n",
       "      <th>Poland</th>\n",
       "      <th>Portugal</th>\n",
       "      <th>Romania</th>\n",
       "      <th>Serbia</th>\n",
       "      <th>Slovakia</th>\n",
       "      <th>Slovenia</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Sweden</th>\n",
       "      <th>Switzerland</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime (UTC)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00</th>\n",
       "      <td>17.93</td>\n",
       "      <td>34.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.20</td>\n",
       "      <td>18.29</td>\n",
       "      <td>23.37</td>\n",
       "      <td>23.37</td>\n",
       "      <td>34.94</td>\n",
       "      <td>17.93</td>\n",
       "      <td>...</td>\n",
       "      <td>27.36</td>\n",
       "      <td>17.18</td>\n",
       "      <td>48.10</td>\n",
       "      <td>44.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.20</td>\n",
       "      <td>23.25</td>\n",
       "      <td>48.10</td>\n",
       "      <td>23.37</td>\n",
       "      <td>43.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 01:00:00</th>\n",
       "      <td>15.17</td>\n",
       "      <td>32.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.06</td>\n",
       "      <td>16.04</td>\n",
       "      <td>19.33</td>\n",
       "      <td>19.33</td>\n",
       "      <td>32.19</td>\n",
       "      <td>15.17</td>\n",
       "      <td>...</td>\n",
       "      <td>27.24</td>\n",
       "      <td>17.38</td>\n",
       "      <td>47.33</td>\n",
       "      <td>39.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.06</td>\n",
       "      <td>22.20</td>\n",
       "      <td>47.33</td>\n",
       "      <td>19.33</td>\n",
       "      <td>38.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 02:00:00</th>\n",
       "      <td>16.38</td>\n",
       "      <td>28.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.27</td>\n",
       "      <td>14.60</td>\n",
       "      <td>17.66</td>\n",
       "      <td>17.66</td>\n",
       "      <td>23.53</td>\n",
       "      <td>16.38</td>\n",
       "      <td>...</td>\n",
       "      <td>27.16</td>\n",
       "      <td>17.40</td>\n",
       "      <td>42.27</td>\n",
       "      <td>26.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.27</td>\n",
       "      <td>19.56</td>\n",
       "      <td>42.27</td>\n",
       "      <td>17.66</td>\n",
       "      <td>35.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 03:00:00</th>\n",
       "      <td>17.38</td>\n",
       "      <td>28.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.17</td>\n",
       "      <td>14.95</td>\n",
       "      <td>17.53</td>\n",
       "      <td>17.53</td>\n",
       "      <td>22.92</td>\n",
       "      <td>17.38</td>\n",
       "      <td>...</td>\n",
       "      <td>27.15</td>\n",
       "      <td>18.60</td>\n",
       "      <td>38.41</td>\n",
       "      <td>20.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.17</td>\n",
       "      <td>18.88</td>\n",
       "      <td>38.41</td>\n",
       "      <td>17.53</td>\n",
       "      <td>30.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 04:00:00</th>\n",
       "      <td>16.38</td>\n",
       "      <td>34.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.90</td>\n",
       "      <td>14.50</td>\n",
       "      <td>18.07</td>\n",
       "      <td>18.07</td>\n",
       "      <td>34.26</td>\n",
       "      <td>16.38</td>\n",
       "      <td>...</td>\n",
       "      <td>27.30</td>\n",
       "      <td>19.30</td>\n",
       "      <td>35.72</td>\n",
       "      <td>18.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.90</td>\n",
       "      <td>18.39</td>\n",
       "      <td>35.72</td>\n",
       "      <td>18.07</td>\n",
       "      <td>28.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Country              Austria  Belgium  Bulgaria  Croatia  Czechia  Denmark  \\\n",
       "Datetime (UTC)                                                               \n",
       "2015-01-01 00:00:00    17.93    34.94       NaN      NaN    24.20    18.29   \n",
       "2015-01-01 01:00:00    15.17    32.19       NaN      NaN    22.06    16.04   \n",
       "2015-01-01 02:00:00    16.38    28.05       NaN      NaN    20.27    14.60   \n",
       "2015-01-01 03:00:00    17.38    28.04       NaN      NaN    19.17    14.95   \n",
       "2015-01-01 04:00:00    16.38    34.26       NaN      NaN    17.90    14.50   \n",
       "\n",
       "Country              Estonia  Finland  France  Germany  ...  Norway  Poland  \\\n",
       "Datetime (UTC)                                          ...                   \n",
       "2015-01-01 00:00:00    23.37    23.37   34.94    17.93  ...   27.36   17.18   \n",
       "2015-01-01 01:00:00    19.33    19.33   32.19    15.17  ...   27.24   17.38   \n",
       "2015-01-01 02:00:00    17.66    17.66   23.53    16.38  ...   27.16   17.40   \n",
       "2015-01-01 03:00:00    17.53    17.53   22.92    17.38  ...   27.15   18.60   \n",
       "2015-01-01 04:00:00    18.07    18.07   34.26    16.38  ...   27.30   19.30   \n",
       "\n",
       "Country              Portugal  Romania  Serbia  Slovakia  Slovenia  Spain  \\\n",
       "Datetime (UTC)                                                              \n",
       "2015-01-01 00:00:00     48.10    44.17     NaN     24.20     23.25  48.10   \n",
       "2015-01-01 01:00:00     47.33    39.17     NaN     22.06     22.20  47.33   \n",
       "2015-01-01 02:00:00     42.27    26.93     NaN     20.27     19.56  42.27   \n",
       "2015-01-01 03:00:00     38.41    20.94     NaN     19.17     18.88  38.41   \n",
       "2015-01-01 04:00:00     35.72    18.52     NaN     17.90     18.39  35.72   \n",
       "\n",
       "Country              Sweden  Switzerland  \n",
       "Datetime (UTC)                            \n",
       "2015-01-01 00:00:00   23.37        43.43  \n",
       "2015-01-01 01:00:00   19.33        38.08  \n",
       "2015-01-01 02:00:00   17.66        35.47  \n",
       "2015-01-01 03:00:00   17.53        30.83  \n",
       "2015-01-01 04:00:00   18.07        28.26  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df [['Country','Datetime (UTC)',  'Price (EUR/MWhe)']]\n",
    "df = df.pivot(index='Datetime (UTC)', columns='Country', values='Price (EUR/MWhe)')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "mfQvgSnM3_1v",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mfQvgSnM3_1v",
    "outputId": "9cd1c2f9-c7f7-46d1-df8b-df5c13df26d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country\n",
      "Austria                0\n",
      "Belgium                0\n",
      "Bulgaria           15336\n",
      "Croatia            24096\n",
      "Czechia                0\n",
      "Denmark                0\n",
      "Estonia                0\n",
      "Finland                0\n",
      "France                 0\n",
      "Germany                0\n",
      "Greece                 0\n",
      "Hungary                0\n",
      "Ireland            12480\n",
      "Italy                  0\n",
      "Latvia                 0\n",
      "Lithuania              0\n",
      "Luxembourg             0\n",
      "Netherlands            0\n",
      "North Macedonia    73008\n",
      "Norway                 0\n",
      "Poland                 0\n",
      "Portugal               0\n",
      "Romania                0\n",
      "Serbia             16800\n",
      "Slovakia               0\n",
      "Slovenia               0\n",
      "Spain                  0\n",
      "Sweden                 0\n",
      "Switzerland            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "WObloVqL4aH3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WObloVqL4aH3",
    "outputId": "c1a5702e-1761-4cca-d65c-14966b09d8dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country\n",
      "Austria        0\n",
      "Belgium        0\n",
      "Czechia        0\n",
      "Denmark        0\n",
      "Estonia        0\n",
      "Finland        0\n",
      "France         0\n",
      "Germany        0\n",
      "Greece         0\n",
      "Hungary        0\n",
      "Italy          0\n",
      "Latvia         0\n",
      "Lithuania      0\n",
      "Luxembourg     0\n",
      "Netherlands    0\n",
      "Norway         0\n",
      "Poland         0\n",
      "Portugal       0\n",
      "Romania        0\n",
      "Slovakia       0\n",
      "Slovenia       0\n",
      "Spain          0\n",
      "Sweden         0\n",
      "Switzerland    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(axis=1)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "AB6vyJX-C6h3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AB6vyJX-C6h3",
    "outputId": "aa9990f8-cb44-4367-b4ff-e2a1bf1732d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datetime (UTC)  Austria  Belgium  Czechia  Denmark  Estonia  Finland  \\\n",
      "0  2015-01-01 00:00:00    17.93    34.94    24.20    18.29    23.37    23.37   \n",
      "1  2015-01-01 01:00:00    15.17    32.19    22.06    16.04    19.33    19.33   \n",
      "2  2015-01-01 02:00:00    16.38    28.05    20.27    14.60    17.66    17.66   \n",
      "3  2015-01-01 03:00:00    17.38    28.04    19.17    14.95    17.53    17.53   \n",
      "4  2015-01-01 04:00:00    16.38    34.26    17.90    14.50    18.07    18.07   \n",
      "\n",
      "   France  Germany  Greece  ...  Netherlands  Norway  Poland  Portugal  \\\n",
      "0   34.94    17.93   48.78  ...        34.94   27.36   17.18     48.10   \n",
      "1   32.19    15.17   31.10  ...        32.19   27.24   17.38     47.33   \n",
      "2   23.53    16.38   20.78  ...        28.05   27.16   17.40     42.27   \n",
      "3   22.92    17.38   25.40  ...        28.04   27.15   18.60     38.41   \n",
      "4   34.26    16.38   26.00  ...        34.26   27.30   19.30     35.72   \n",
      "\n",
      "   Romania  Slovakia  Slovenia  Spain  Sweden  Switzerland  \n",
      "0    44.17     24.20     23.25  48.10   23.37        43.43  \n",
      "1    39.17     22.06     22.20  47.33   19.33        38.08  \n",
      "2    26.93     20.27     19.56  42.27   17.66        35.47  \n",
      "3    20.94     19.17     18.88  38.41   17.53        30.83  \n",
      "4    18.52     17.90     18.39  35.72   18.07        28.26  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.columns.name = None\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "99211c4c-9b8f-4d60-9bb6-add80102ca5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last time point available: 2024-03-31 23:00:00\n"
     ]
    }
   ],
   "source": [
    "df['Datetime (UTC)'] = pd.to_datetime(df['Datetime (UTC)'])\n",
    "last_time_point = df['Datetime (UTC)'].max()\n",
    "print(\"Last time point available:\", last_time_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "d9365312-6296-4b97-ace6-9dd9191fccea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Datetime (UTC)  Austria  Belgium  Czechia  Denmark  Estonia  \\\n",
      "78571 2023-12-18 19:00:00    89.00    81.68    91.54    37.53    85.79   \n",
      "78572 2023-12-18 20:00:00    84.92    79.97    76.34    33.87    76.89   \n",
      "78573 2023-12-18 21:00:00    72.05    73.79    63.56    27.91    12.66   \n",
      "78574 2023-12-18 22:00:00    59.58    68.67    53.21    31.94    10.08   \n",
      "78575 2023-12-18 23:00:00    64.79    65.61    63.10    24.84    10.04   \n",
      "...                   ...      ...      ...      ...      ...      ...   \n",
      "81067 2024-03-31 19:00:00    66.17    47.01    68.37    70.00    50.09   \n",
      "81068 2024-03-31 20:00:00    61.25    43.70    63.26    64.51    46.28   \n",
      "81069 2024-03-31 21:00:00    44.99    50.29    51.29    54.90    43.98   \n",
      "81070 2024-03-31 22:00:00    40.70    50.32    46.39    49.95    40.41   \n",
      "81071 2024-03-31 23:00:00    32.10    44.39    42.60    48.98    40.39   \n",
      "\n",
      "       Finland  France  Germany  Greece  ...  Netherlands  Norway  Poland  \\\n",
      "78571    17.20   82.07    77.98  121.73  ...        83.09   44.87   85.79   \n",
      "78572    15.21   77.93    71.09  101.76  ...        74.89   44.18   79.32   \n",
      "78573    12.66   83.20    62.98  108.33  ...        63.79   42.67   77.35   \n",
      "78574    10.08   79.46    55.12  102.52  ...        57.94   38.09   52.63   \n",
      "78575     8.06   78.51    47.29   91.55  ...        52.24   37.27   50.70   \n",
      "...        ...     ...      ...     ...  ...          ...     ...     ...   \n",
      "81067    50.09   26.12    70.00   65.81  ...        65.20   57.09   69.99   \n",
      "81068    46.28   24.53    64.51   60.90  ...        60.55   55.85   72.43   \n",
      "81069    43.98   32.35    54.90   48.07  ...        54.90   53.50   75.27   \n",
      "81070    40.41   40.70    49.95   43.45  ...        51.03   51.08   68.70   \n",
      "81071    40.39   32.10    48.98   37.15  ...        48.98   48.13   68.69   \n",
      "\n",
      "       Portugal  Romania  Slovakia  Slovenia   Spain  Sweden  Switzerland  \n",
      "78571    174.00   121.73     79.23     97.78  174.00   17.20        90.48  \n",
      "78572    129.47   101.76    105.45     89.42  129.47   15.21        85.21  \n",
      "78573    110.00    93.64     66.12     79.61  110.00   12.66        80.07  \n",
      "78574    105.71    57.20     55.42     61.41  105.71   10.08        76.25  \n",
      "78575     94.28    72.64     55.56     69.50   94.28    8.06        73.17  \n",
      "...         ...      ...       ...       ...     ...     ...          ...  \n",
      "81067      3.20    65.81     67.09     63.43    3.20   50.09        74.52  \n",
      "81068      3.20    60.90     62.10     58.74    3.20   46.28        67.31  \n",
      "81069      1.63    48.07     49.03     46.61    1.63   43.98        62.86  \n",
      "81070      0.70    43.45     44.32     42.13    0.70   40.41        44.23  \n",
      "81071      0.02    37.15     38.77     34.75    0.02   40.39        40.01  \n",
      "\n",
      "[2501 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find the latest timestamp in the DataFrame\n",
    "latest_timestamp = df['Datetime (UTC)'].max()\n",
    "\n",
    "# Calculate the timestamp for 2500 hours before the latest timestamp\n",
    "start_timestamp = latest_timestamp - pd.Timedelta(hours=2500)\n",
    "\n",
    "# Filter the DataFrame for the last 2500 hours\n",
    "df = df[df['Datetime (UTC)'] >= start_timestamp]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "_Jtyfje24Pdq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Jtyfje24Pdq",
    "outputId": "507d28c6-0347-4446-9078-c6fda9ffa9a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Datetime (UTC)  Austria  Belgium  Czechia  Denmark  Estonia  \\\n",
      "78571 2023-12-18 19:00:00    89.00    81.68    91.54    37.53    85.79   \n",
      "78572 2023-12-18 20:00:00    84.92    79.97    76.34    33.87    76.89   \n",
      "78573 2023-12-18 21:00:00    72.05    73.79    63.56    27.91    12.66   \n",
      "78574 2023-12-18 22:00:00    59.58    68.67    53.21    31.94    10.08   \n",
      "78575 2023-12-18 23:00:00    64.79    65.61    63.10    24.84    10.04   \n",
      "\n",
      "       Finland  France  Germany  Greece  ...  Romania  Slovakia  Slovenia  \\\n",
      "78571    17.20   82.07    77.98  121.73  ...   121.73     79.23     97.78   \n",
      "78572    15.21   77.93    71.09  101.76  ...   101.76    105.45     89.42   \n",
      "78573    12.66   83.20    62.98  108.33  ...    93.64     66.12     79.61   \n",
      "78574    10.08   79.46    55.12  102.52  ...    57.20     55.42     61.41   \n",
      "78575     8.06   78.51    47.29   91.55  ...    72.64     55.56     69.50   \n",
      "\n",
      "        Spain  Sweden  Switzerland  month  day  weekday  hour  \n",
      "78571  174.00   17.20        90.48     12   18        0    19  \n",
      "78572  129.47   15.21        85.21     12   18        0    20  \n",
      "78573  110.00   12.66        80.07     12   18        0    21  \n",
      "78574  105.71   10.08        76.25     12   18        0    22  \n",
      "78575   94.28    8.06        73.17     12   18        0    23  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "df['month'] = df['Datetime (UTC)'].apply(lambda row: row.month)\n",
    "df['day'] = df['Datetime (UTC)'].apply(lambda row: row.day)\n",
    "df['weekday'] = df['Datetime (UTC)'].apply(lambda row: row.weekday())\n",
    "df['hour'] = df['Datetime (UTC)'].apply(lambda row: row.hour)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "80mxqDAh5Mwd",
   "metadata": {
    "id": "80mxqDAh5Mwd"
   },
   "outputs": [],
   "source": [
    "# separating the electricity prices and timestamp features\n",
    "electricity_prices_df = df[['Datetime (UTC)', 'Austria', 'Belgium', 'Czechia', 'Denmark', 'Estonia', 'Finland', 'France',\n",
    "              'Germany', 'Greece', 'Hungary', 'Italy', 'Latvia', 'Lithuania', 'Luxembourg',\n",
    "             'Netherlands', 'Norway', 'Poland', 'Portugal', 'Romania', 'Slovakia',\n",
    "             'Slovenia', 'Spain', 'Sweden', 'Switzerland']]\n",
    "timestamp_features_df = df[['Datetime (UTC)', 'month', 'day', 'weekday', 'hour']]\n",
    "\n",
    "# defining the split ratio\n",
    "train_size = 0.8\n",
    "train_size_electricity = int(len(electricity_prices_df) * train_size)\n",
    "train_size_timestamp = int(len(timestamp_features_df) * train_size)\n",
    "\n",
    "# spliting the data into train and test sets\n",
    "electricity_prices_train = electricity_prices_df[:train_size_electricity]\n",
    "electricity_prices_test = electricity_prices_df[train_size_electricity:]\n",
    "timestamp_features_train = timestamp_features_df[:train_size_timestamp]\n",
    "timestamp_features_test = timestamp_features_df[train_size_timestamp:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "95180c89-5259-40f8-af8b-e90241aa8864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(electricity_prices_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "3a2c3f05-460c-4d80-868e-48ff8f5cfd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#country_names = electricity_prices_train.drop(columns=['Datetime (UTC)']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "4oRyT6un5WWm",
   "metadata": {
    "id": "4oRyT6un5WWm"
   },
   "outputs": [],
   "source": [
    "# rescaling the electricity prices\n",
    "#scaler = StandardScaler()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "electricity_prices_train_scaled = scaler.fit_transform(electricity_prices_train.drop(columns=['Datetime (UTC)']))\n",
    "electricity_prices_test_scaled = scaler.transform(electricity_prices_test.drop(columns=['Datetime (UTC)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "241b9b80-b3c1-423c-a0ac-0e100fe0858e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zero values in actual data: 222\n"
     ]
    }
   ],
   "source": [
    "zero_count = np.sum(electricity_prices_train_scaled == 0)\n",
    "print(f\"Number of zero values in actual data: {zero_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "07d72a8e-4df2-4255-bdb3-3353426389cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#electricity_prices_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "407a011b-3187-4e94-9c3a-e36c17253639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length, pred_length, label_length, curr_model):\n",
    "    seq_x = [] # storing for input seqiences\n",
    "    seq_y = [] # storing for output seqiences\n",
    "    for i in range(len(data) - seq_length - pred_length):\n",
    "        seq_x.append(data[i:i+seq_length])\n",
    "        if curr_model in [\"basis_former\", \"itransformer\", \"ns_autoformer\"]:\n",
    "          seq_y.append(data[i+seq_length-label_length:i+seq_length+pred_length])\n",
    "        else: ## only chronos\n",
    "          seq_y.append(data[i+seq_length:i+seq_length+pred_length])\n",
    "    return np.array(seq_x), np.array(seq_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "8c17fd64-77c4-42ab-9e63-bf919d801d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(seq_x, seq_y, seq_x_mark, seq_y_mark, batch_size, curr_model):\n",
    "    seq_x = torch.tensor(seq_x, dtype=torch.float32)\n",
    "    seq_y = torch.tensor(seq_y, dtype=torch.float32)\n",
    "    seq_x_mark = torch.tensor(seq_x_mark, dtype=torch.float32)\n",
    "    seq_y_mark = torch.tensor(seq_y_mark, dtype=torch.float32)\n",
    "    \n",
    "    if curr_model == \"basis_former\":\n",
    "        indices = []\n",
    "        total_len = len(seq_x)\n",
    "        for i in range(total_len):\n",
    "            index_list = np.arange(i, i + len(seq_x[0]) + len(seq_y[0]), 1)\n",
    "            norm_index = index_list / total_len\n",
    "            indices.append(norm_index)\n",
    "        indices = torch.tensor(indices, dtype=torch.float32)\n",
    "        dataset = TensorDataset(seq_x, seq_y, seq_x_mark, seq_y_mark, indices)\n",
    "    else:\n",
    "        dataset = TensorDataset(seq_x, seq_y, seq_x_mark, seq_y_mark)\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=2, shuffle=True, drop_last=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898763c2-25af-4236-b6b4-43466525ccdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21225b3d-5c69-425f-9f8e-17ebcc39cd8b",
   "metadata": {},
   "source": [
    "# 2. Experimental Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "5f6a0895",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 96\n",
    "pred_length = 48\n",
    "label_length = 48\n",
    "batch_size = 24\n",
    "#device = torch.device(f\"cuda:{args.device}\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9598752-60c2-45e0-a3da-535bb910219e",
   "metadata": {},
   "source": [
    "# Benchmark Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1627bd8d-ab8f-4f35-81c8-25b91760b230",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c10844",
   "metadata": {},
   "source": [
    "### Linear Model Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0ad38e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Copy the main dataframe for linear model preprocessing\n",
    "df_linear = df.copy()\n",
    "\n",
    "# Define the number of lagged features\n",
    "lag_steps = 3\n",
    "\n",
    "# List of all columns (already defined in the main preprocessing)\n",
    "all_columns = df_linear.columns.tolist()\n",
    "\n",
    "# List of columns to exclude (non-country columns)\n",
    "exclude_columns = ['Datetime (UTC)', 'month', 'day', 'weekday', 'hour']\n",
    "\n",
    "# Define the country columns by excluding non-country columns\n",
    "countries = [col for col in all_columns if col not in exclude_columns]\n",
    "\n",
    "# Create lagged features for each country\n",
    "for country in countries:\n",
    "    for lag in range(1, lag_steps + 1):\n",
    "        df_linear[f'{country}_lag_{lag}'] = df_linear[country].shift(lag)\n",
    "\n",
    "# Drop rows with NaN values due to lagging\n",
    "df_linear.dropna(inplace=True)\n",
    "\n",
    "# Define features (X) and targets (Y)\n",
    "X_numerical = df_linear.drop(columns=countries + ['Datetime (UTC)'])\n",
    "Y = df_linear[countries]  # Target: current prices of all countries\n",
    "\n",
    "# Standardize the features and targets\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X_numerical)\n",
    "\n",
    "scaler_Y = StandardScaler()\n",
    "Y_scaled = scaler_Y.fit_transform(Y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_size = 0.8\n",
    "train_size_idx = int(len(X_scaled) * train_size)\n",
    "X_train, X_test = X_scaled[:train_size_idx], X_scaled[train_size_idx:]\n",
    "Y_train, Y_test = Y_scaled[:train_size_idx], Y_scaled[train_size_idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c39d0c",
   "metadata": {},
   "source": [
    "### Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "575df258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Mean Absolute Error: 7.121460465848678\n",
      "Linear Regression Root Mean Squared Error: 12.298510526240207\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Initialize and train the linear regression model\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "Y_pred_lr = model_lr.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions and the actual values back to the original scale\n",
    "Y_pred_lr_original = scaler_Y.inverse_transform(Y_pred_lr)\n",
    "Y_test_original = scaler_Y.inverse_transform(Y_test)\n",
    "\n",
    "# MAE\n",
    "mae_lr = mean_absolute_error(Y_test_original, Y_pred_lr_original)\n",
    "print(f\"Linear Regression Mean Absolute Error: {mae_lr}\")\n",
    "\n",
    "# Evaluate the model using RMSE\n",
    "rmse_lr = np.sqrt(mean_squared_error(Y_test_original, Y_pred_lr_original))\n",
    "print(f\"Linear Regression Root Mean Squared Error: {rmse_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb17613-c608-4a1b-b8dd-7773464d72b1",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07edd48",
   "metadata": {},
   "source": [
    "### LSTM Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "740f3adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Copy the main dataframe for LSTM model preprocessing\n",
    "df_lstm = df.copy()\n",
    "\n",
    "# Rescale the data using StandardScaler for LSTM\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(df_lstm.drop(columns=['Datetime (UTC)', 'month', 'day', 'weekday', 'hour']))\n",
    "\n",
    "# Convert to a supervised learning problem by creating sequences\n",
    "def create_sequences_lstm(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Define sequence length (number of time steps)\n",
    "seq_length = 24\n",
    "\n",
    "# Create sequences\n",
    "X, y = create_sequences_lstm(data_scaled, seq_length)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_size = int(X.shape[0] * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b871c7e",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "fd87f6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.9136 - val_loss: 0.5468\n",
      "Epoch 2/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.4562 - val_loss: 0.4291\n",
      "Epoch 3/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.3066 - val_loss: 0.3136\n",
      "Epoch 4/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2233 - val_loss: 0.2464\n",
      "Epoch 5/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1892 - val_loss: 0.2221\n",
      "Epoch 6/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1654 - val_loss: 0.2072\n",
      "Epoch 7/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1273 - val_loss: 0.2002\n",
      "Epoch 8/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1243 - val_loss: 0.1920\n",
      "Epoch 9/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1132 - val_loss: 0.1896\n",
      "Epoch 10/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0961 - val_loss: 0.1798\n",
      "Epoch 11/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0965 - val_loss: 0.1735\n",
      "Epoch 12/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0925 - val_loss: 0.1774\n",
      "Epoch 13/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0959 - val_loss: 0.1663\n",
      "Epoch 14/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0850 - val_loss: 0.1734\n",
      "Epoch 15/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0885 - val_loss: 0.1715\n",
      "Epoch 16/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0894 - val_loss: 0.1587\n",
      "Epoch 17/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0725 - val_loss: 0.1576\n",
      "Epoch 18/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0725 - val_loss: 0.1568\n",
      "Epoch 19/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0677 - val_loss: 0.1562\n",
      "Epoch 20/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0736 - val_loss: 0.1516\n",
      "Epoch 21/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0722 - val_loss: 0.1522\n",
      "Epoch 22/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0763 - val_loss: 0.1480\n",
      "Epoch 23/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0646 - val_loss: 0.1496\n",
      "Epoch 24/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0678 - val_loss: 0.1435\n",
      "Epoch 25/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0719 - val_loss: 0.1527\n",
      "Epoch 26/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0651 - val_loss: 0.1495\n",
      "Epoch 27/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0737 - val_loss: 0.1465\n",
      "Epoch 28/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0564 - val_loss: 0.1410\n",
      "Epoch 29/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0672 - val_loss: 0.1451\n",
      "Epoch 30/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0632 - val_loss: 0.1421\n",
      "Epoch 31/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0606 - val_loss: 0.1450\n",
      "Epoch 32/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0575 - val_loss: 0.1454\n",
      "Epoch 33/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0583 - val_loss: 0.1442\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "LSTM Mean Absolute Error: 9.25420819274092\n",
      "LSTM Root Mean Squared Error: 14.850165514005804\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define the LSTM model\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(units=50, return_sequences=True, input_shape=(seq_length, X.shape[2])))\n",
    "model_lstm.add(LSTM(units=50, return_sequences=False))\n",
    "model_lstm.add(Dense(units=y.shape[1]))\n",
    "\n",
    "# Compile the model\n",
    "model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Set up EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Fit the model with EarlyStopping\n",
    "model_lstm.fit(X_train, y_train, epochs=50, batch_size=24, \n",
    "               validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lstm = model_lstm.predict(X_test)\n",
    "\n",
    "# Inverse transform the scaled data to original values\n",
    "y_test_inverse = scaler.inverse_transform(y_test)\n",
    "y_pred_inverse = scaler.inverse_transform(y_pred_lstm)\n",
    "\n",
    "# Evaluate the model using MAE\n",
    "mae_lstm = mean_absolute_error(y_test_inverse, y_pred_inverse)\n",
    "print(f\"LSTM Mean Absolute Error: {mae_lstm}\")\n",
    "\n",
    "# Evaluate the model using RMSE\n",
    "rmse_lstm = np.sqrt(mean_squared_error(y_test_inverse, y_pred_inverse))\n",
    "print(f\"LSTM Root Mean Squared Error: {rmse_lstm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524dced6-ac13-4939-9362-ab95493547d0",
   "metadata": {},
   "source": [
    "# Pre trained model Chronos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133a20c4-aa7e-4fd7-95e7-8e60275dc839",
   "metadata": {},
   "source": [
    "zero shot evaluation with Chronos Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2617ec8b-f710-450b-81b1-1f8ce6f4fba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/amazon-science/chronos-forecasting.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9d4e2e76-e80a-45da-aba7-c82e5dae03b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/inceemir/apa_group4_transformers_for_multivar_energy_forecasting/.venv/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Austria\n",
      "Data range for Austria: -12.5 to 147.04\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Belgium\n",
      "Data range for Belgium: -11.8 to 144.11\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Czechia\n",
      "Data range for Czechia: -17.09 to 158.44\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Denmark\n",
      "Data range for Denmark: -4.97 to 275.85\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Estonia\n",
      "Data range for Estonia: -2.02 to 1896.0\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Finland\n",
      "Data range for Finland: -2.5 to 1896.0\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing France\n",
      "Data range for France: -11.93 to 144.11\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Germany\n",
      "Data range for Germany: -13.37 to 150.09\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Greece\n",
      "Data range for Greece: 0.04 to 190.96\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Hungary\n",
      "Data range for Hungary: -13.01 to 183.11\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Italy\n",
      "Data range for Italy: 27.92 to 165.0\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Latvia\n",
      "Data range for Latvia: -2.02 to 1478.91\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Lithuania\n",
      "Data range for Lithuania: -2.02 to 1478.91\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Luxembourg\n",
      "Data range for Luxembourg: -13.37 to 150.09\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Netherlands\n",
      "Data range for Netherlands: -39.79 to 147.06\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Norway\n",
      "Data range for Norway: 10.95 to 355.82\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Poland\n",
      "Data range for Poland: -13.81 to 160.15\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Portugal\n",
      "Data range for Portugal: 0.0 to 181.26\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Romania\n",
      "Data range for Romania: -0.01 to 231.37\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Slovakia\n",
      "Data range for Slovakia: -14.06 to 147.93\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Slovenia\n",
      "Data range for Slovenia: -11.53 to 147.12\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Spain\n",
      "Data range for Spain: 0.0 to 181.26\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Sweden\n",
      "Data range for Sweden: -2.5 to 526.25\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "Processing Switzerland\n",
      "Data range for Switzerland: -10.36 to 143.05\n",
      "Chronos input shape: torch.Size([1, 96])\n",
      "Forecast shape: torch.Size([1, 20, 48])\n",
      "\n",
      "MSE for Austria: 1124.9843305672082\n",
      "MAE for Austria: 29.62595588525137\n",
      "\n",
      "RMSE for Austria: 33.540786075570864\n",
      "MAPE for Austria: 0.3738327586398828\n",
      "\n",
      "MSE for Belgium: 103.5740543995953\n",
      "MAE for Belgium: 7.931807403564453\n",
      "\n",
      "RMSE for Belgium: 10.177133899069782\n",
      "MAPE for Belgium: 0.10036565590819986\n",
      "\n",
      "MSE for Czechia: 1338.3464329023234\n",
      "MAE for Czechia: 32.805104467074074\n",
      "\n",
      "RMSE for Czechia: 36.583417457945664\n",
      "MAPE for Czechia: 0.402673024578225\n",
      "\n",
      "MSE for Denmark: 1963.9421964126077\n",
      "MAE for Denmark: 38.08866392099609\n",
      "\n",
      "RMSE for Denmark: 44.316387447676824\n",
      "MAPE for Denmark: 0.496334043049708\n",
      "\n",
      "MSE for Estonia: 2123.8142992333123\n",
      "MAE for Estonia: 41.862717556655404\n",
      "\n",
      "RMSE for Estonia: 46.08485976145867\n",
      "MAPE for Estonia: 0.5411559475531861\n",
      "\n",
      "MSE for Finland: 556.2253421664951\n",
      "MAE for Finland: 19.790554672876993\n",
      "\n",
      "RMSE for Finland: 23.584430079323415\n",
      "MAPE for Finland: 0.26658352562162113\n",
      "\n",
      "MSE for France: 211.91858952108387\n",
      "MAE for France: 12.03940556526184\n",
      "\n",
      "RMSE for France: 14.557423862795364\n",
      "MAPE for France: 0.1618309695363451\n",
      "\n",
      "MSE for Germany: 1416.4052217976853\n",
      "MAE for Germany: 33.48690071423848\n",
      "\n",
      "RMSE for Germany: 37.6351593831843\n",
      "MAPE for Germany: 0.4100049257559058\n",
      "\n",
      "MSE for Greece: 577.2579753080935\n",
      "MAE for Greece: 20.09040220419566\n",
      "\n",
      "RMSE for Greece: 24.02619352515278\n",
      "MAPE for Greece: 0.3936485898587146\n",
      "\n",
      "MSE for Hungary: 1607.875596092433\n",
      "MAE for Hungary: 35.87675814668338\n",
      "\n",
      "RMSE for Hungary: 40.098324105783185\n",
      "MAPE for Hungary: 0.4444038876222974\n",
      "\n",
      "MSE for Italy: 220.78453176106441\n",
      "MAE for Italy: 11.258779350916546\n",
      "\n",
      "RMSE for Italy: 14.858819998945556\n",
      "MAPE for Italy: 0.12083753682253456\n",
      "\n",
      "MSE for Latvia: 2132.5834740171335\n",
      "MAE for Latvia: 41.69394151886304\n",
      "\n",
      "RMSE for Latvia: 46.17990335651574\n",
      "MAPE for Latvia: 0.5414038425711314\n",
      "\n",
      "MSE for Lithuania: 2203.16070550268\n",
      "MAE for Lithuania: 42.8559778781732\n",
      "\n",
      "RMSE for Lithuania: 46.93783873915244\n",
      "MAPE for Lithuania: 0.5576587173736507\n",
      "\n",
      "MSE for Luxembourg: 1753.0497216054182\n",
      "MAE for Luxembourg: 36.65226725024481\n",
      "\n",
      "RMSE for Luxembourg: 41.86943660482451\n",
      "MAPE for Luxembourg: 0.44961293260264706\n",
      "\n",
      "MSE for Netherlands: 768.7156273033764\n",
      "MAE for Netherlands: 19.79258146762848\n",
      "\n",
      "RMSE for Netherlands: 27.72572140275842\n",
      "MAPE for Netherlands: 0.25850574116162944\n",
      "\n",
      "MSE for Norway: 294.6873293068716\n",
      "MAE for Norway: 14.704255723953247\n",
      "\n",
      "RMSE for Norway: 17.16645942839908\n",
      "MAPE for Norway: 0.20484622609744765\n",
      "\n",
      "MSE for Poland: 2668.407975545747\n",
      "MAE for Poland: 48.37967934863275\n",
      "\n",
      "RMSE for Poland: 51.65663534867275\n",
      "MAPE for Poland: 0.590436090904361\n",
      "\n",
      "MSE for Portugal: 2065.313447111023\n",
      "MAE for Portugal: 27.5012789265886\n",
      "\n",
      "RMSE for Portugal: 45.44571978867782\n",
      "MAPE for Portugal: inf\n",
      "\n",
      "MSE for Romania: 843.5868404833527\n",
      "MAE for Romania: 25.180459665457406\n",
      "\n",
      "RMSE for Romania: 29.044566453699264\n",
      "MAPE for Romania: 0.4071263986175424\n",
      "\n",
      "MSE for Slovakia: 1761.4294049406335\n",
      "MAE for Slovakia: 37.592512432734175\n",
      "\n",
      "RMSE for Slovakia: 41.96938652089918\n",
      "MAPE for Slovakia: 0.4676425567798071\n",
      "\n",
      "MSE for Slovenia: 865.0089767671324\n",
      "MAE for Slovenia: 26.89355324427287\n",
      "\n",
      "RMSE for Slovenia: 29.411034948929156\n",
      "MAPE for Slovenia: 0.3388853682112014\n",
      "\n",
      "MSE for Spain: 2445.9308416127164\n",
      "MAE for Spain: 31.153308735217554\n",
      "\n",
      "RMSE for Spain: 49.45635289437259\n",
      "MAPE for Spain: inf\n",
      "\n",
      "MSE for Sweden: 788.0242648298141\n",
      "MAE for Sweden: 26.24528966744741\n",
      "\n",
      "RMSE for Sweden: 28.071769891294956\n",
      "MAPE for Sweden: 0.3742896977415955\n",
      "\n",
      "MSE for Switzerland: 332.66570269322614\n",
      "MAE for Switzerland: 12.185870151519774\n",
      "\n",
      "RMSE for Switzerland: 18.239125601114385\n",
      "MAPE for Switzerland: 0.12581559782555898\n",
      "\n",
      "Average MSE across selected countries: 1256.9872034117095\n",
      "\n",
      "Average MAE across selected countries: 28.07033441243532\n",
      "\n",
      "Average RMSE across selected countries: 33.2765369406757\n",
      "\n",
      "Average MAPE across selected countries: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1323976/618574630.py:88: RuntimeWarning: divide by zero encountered in divide\n",
      "  return np.mean(np.abs((forecast - actual) / actual))\n"
     ]
    }
   ],
   "source": [
    "import chronos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from chronos import ChronosPipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your initial dataset\n",
    "# Make sure 'Datetime (UTC)' is set as the index\n",
    "#df = df.set_index('Datetime (UTC)')\n",
    "\n",
    "# Select the countries we want to forecast\n",
    "selected_countries = ['Austria', 'Belgium', 'Czechia', 'Denmark', 'Estonia', 'Finland', 'France',\n",
    "              'Germany', 'Greece', 'Hungary', 'Italy', 'Latvia', 'Lithuania', 'Luxembourg',\n",
    "             'Netherlands', 'Norway', 'Poland', 'Portugal', 'Romania', 'Slovakia',\n",
    "             'Slovenia', 'Spain', 'Sweden', 'Switzerland']\n",
    "\n",
    "# Extract the data for selected countries\n",
    "data = df[selected_countries]\n",
    "\n",
    "# Print some basic information about the dataset\n",
    "#print(f\"Dataset shape: {data.shape}\")\n",
    "#print(f\"Date range: from {data.index.min()} to {data.index.max()}\")\n",
    "#print(f\"Any missing values: {data.isnull().any().any()}\")\n",
    "\n",
    "# Define the split point for train and test\n",
    "split_point = int(len(data) * 0.8)  # 80% for training, 20% for testing\n",
    "\n",
    "# Split the data\n",
    "train_data = data.iloc[:split_point]\n",
    "test_data = data.iloc[split_point:]\n",
    "\n",
    "#print(f\"\\nTrain data shape: {train_data.shape}\")\n",
    "#print(f\"Test data shape: {test_data.shape}\")\n",
    "\n",
    "# Function to prepare data for Chronos\n",
    "def prepare_chronos_data(data, seq_length):\n",
    "    return torch.tensor(data[-seq_length:].values, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "# Initialize Chronos pipeline\n",
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-small\",\n",
    "    device_map=\"cpu\",  # use \"cpu\" for CPU inference and \"mps\" for Apple Silicon\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "# Set parameters\n",
    "seq_length = 96\n",
    "pred_length = 48\n",
    "\n",
    "#print(f\"\\nSequence length: {seq_length} (equivalent to {seq_length/24} days)\")\n",
    "#print(f\"Prediction length: {pred_length} (equivalent to {pred_length/24} days)\")\n",
    "\n",
    "# Prepare data and run forecasts\n",
    "results = {}\n",
    "\n",
    "for country in selected_countries:\n",
    "    print(f\"\\nProcessing {country}\")\n",
    "    print(f\"Data range for {country}: {train_data[country].min()} to {train_data[country].max()}\")\n",
    "    \n",
    "    # Prepare input for Chronos\n",
    "    chronos_input = prepare_chronos_data(train_data[country], seq_length)\n",
    "    print(f\"Chronos input shape: {chronos_input.shape}\")\n",
    "    \n",
    "    # Generate forecast\n",
    "    forecast = pipeline.predict(\n",
    "        context=chronos_input,\n",
    "        prediction_length=pred_length,\n",
    "        num_samples=20,\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    results[country] = forecast\n",
    "    print(f\"Forecast shape: {forecast.shape}\")\n",
    "\n",
    "\n",
    "# Evaluate results\n",
    "def calculate_mse(actual, forecast):\n",
    "    return np.mean((actual - forecast) ** 2)\n",
    "    \n",
    "def calculate_mae(actual, forecast):\n",
    "    return np.mean(np.abs(actual - forecast))\n",
    "    \n",
    "def calculate_rmse(actual, forecast):\n",
    "    return np.sqrt(calculate_mse(forecast, actual))\n",
    "    \n",
    "def calculate_mape(actual, forecast):\n",
    "    return np.mean(np.abs((forecast - actual) / actual))\n",
    "\n",
    "mse_results = {}\n",
    "mae_results = {}\n",
    "mape_results = {}\n",
    "rmse_results = {}\n",
    "\n",
    "for country in selected_countries:\n",
    "    actual_values = test_data[country].values[:pred_length]\n",
    "    forecasted_values = np.median(results[country], axis=1).flatten()\n",
    "    \n",
    "    min_length = min(len(actual_values), len(forecasted_values))\n",
    "    actual_values = actual_values[:min_length]\n",
    "    forecasted_values = forecasted_values[:min_length]\n",
    "    \n",
    "    mse = calculate_mse(actual_values, forecasted_values)\n",
    "    mae = calculate_mae(actual_values, forecasted_values)\n",
    "    rmse = calculate_rmse(actual_values, forecasted_values)\n",
    "    mape = calculate_mape(actual_values, forecasted_values)\n",
    "    mse_results[country] = mse\n",
    "    mae_results[country] = mae\n",
    "    rmse_results[country] = rmse\n",
    "    mape_results[country] = mape\n",
    "    print(f\"\\nMSE for {country}: {mse}\")\n",
    "    print(f\"MAE for {country}: {mae}\")\n",
    "    print(f\"\\nRMSE for {country}: {rmse}\")\n",
    "    print(f\"MAPE for {country}: {mape}\")\n",
    "    \n",
    "    # Debug information\n",
    "    #print(f\"Actual values shape: {actual_values.shape}\")\n",
    "    #print(f\"Forecasted values shape: {forecasted_values.shape}\")\n",
    "    #print(f\"Actual values range: {actual_values.min()} to {actual_values.max()}\")\n",
    "    #print(f\"Forecasted values range: {forecasted_values.min()} to {forecasted_values.max()}\")\n",
    "    \n",
    "    # Plot actual vs predicted\n",
    "    #plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot actual values\n",
    "    #if len(actual_values) == 1:\n",
    "    #    plt.scatter(0, actual_values[0], label='Actual', marker='o', s=100, color='blue')\n",
    "    #else:\n",
    "    #    plt.plot(actual_values, label='Actual', marker='o')\n",
    "    \n",
    "    # Plot forecasted values\n",
    "    #plt.plot(forecasted_values, label='Predicted', marker='x', color='red')\n",
    "    \n",
    "    #plt.title(f'{country} - Actual vs Predicted')\n",
    "    #plt.xlabel('Time Steps')\n",
    "    #plt.ylabel('Price')\n",
    "    #plt.legend()\n",
    "    #plt.grid(True)\n",
    "    \n",
    "    # Add text annotations\n",
    "    #if len(actual_values) > 0:\n",
    "    #    plt.annotate(f'{actual_values[0]:.2f}', (0, actual_values[0]), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "    #if len(actual_values) > 1:\n",
    "    #    plt.annotate(f'{actual_values[-1]:.2f}', (len(actual_values)-1, actual_values[-1]), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "    \n",
    "    #plt.annotate(f'{forecasted_values[0]:.2f}', (0, forecasted_values[0]), textcoords=\"offset points\", xytext=(0,-15), ha='center')\n",
    "    #plt.annotate(f'{forecasted_values[-1]:.2f}', (len(forecasted_values)-1, forecasted_values[-1]), textcoords=\"offset points\", xytext=(0,-15), ha='center')\n",
    "    \n",
    "    #plt.tight_layout()\n",
    "    #plt.show()\n",
    "\n",
    "# Calculate and print average MSE\n",
    "average_mse = np.mean(list(mse_results.values()))\n",
    "print(f\"\\nAverage MSE across selected countries: {average_mse}\")\n",
    "average_mae = np.mean(list(mae_results.values()))\n",
    "print(f\"\\nAverage MAE across selected countries: {average_mae}\")\n",
    "average_rmse = np.mean(list(rmse_results.values()))\n",
    "print(f\"\\nAverage RMSE across selected countries: {average_rmse}\")\n",
    "average_mape = np.mean(list(mape_results.values()))\n",
    "print(f\"\\nAverage MAPE across selected countries: {average_mape}\")\n",
    "\n",
    "# Print summary statistics\n",
    "#for country in selected_countries:\n",
    "    #print(f\"\\nSummary for {country}:\")\n",
    "    #print(f\"Train data mean: {train_data[country].mean():.2f}, std: {train_data[country].std():.2f}\")\n",
    "    #print(f\"Test data mean: {test_data[country].mean():.2f}, std: {test_data[country].std():.2f}\")\n",
    "    #print(f\"MSE: {mse_results[country]:.2f}\")\n",
    "    #print(f\"RMSE: {np.sqrt(mse_results[country]):.2f}\")\n",
    "    #print(f\"MAE: {mae_results[country]:.2f}\")\n",
    "    #print(f\"RMSE as percentage of mean: {(np.sqrt(mse_results[country]) / test_data[country].mean()) * 100:.2f}%\")\n",
    "    #print(f\"MAE as percentage of mean: {(mae_results[country] / test_data[country].mean()) * 100:.2f}%\")\n",
    "\n",
    "# Save MSE results\n",
    "#import pickle\n",
    "#with open('error_results_chronos_unscaled.pkl', 'wb') as f:\n",
    "    #pickle.dump({'mse': mse_results, 'mae': mae_results}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b8a27c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.2765369406757\n"
     ]
    }
   ],
   "source": [
    "rmse_chronos = average_rmse\n",
    "print(rmse_chronos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5a7ac4-ef50-4568-aeb2-ed1cec9d015f",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02c458b-65b0-4808-a620-24831f9482c8",
   "metadata": {},
   "source": [
    "## Unification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "10670e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit (model, train_flag, test_flag, train_loader=None, test_loader=None, pretrained_model=None):\n",
    "    '''Fits a transformer model to the train and/or test loaders\n",
    "    \n",
    "    model - \"basis_former\", \"itransformer\", \"ns_autoformer\"\n",
    "    \n",
    "    train_flag: typ(bool) - True: to train the model on train_loader, False: if pretrained_model is passed\n",
    "    \n",
    "    test_flag: typ(bool) - True: to test on test_loader, False: if only training\n",
    "    \n",
    "    pretrained_model - pass a pretrained model if available to be fitted on a test_loader. \n",
    "    eg. fit(basis_former, train_flag=False, test_flag=True, test_loader=test_loader, pretrained_model=model)\n",
    "    '''\n",
    "    \n",
    "    if curr_model == 'basis_former':\n",
    "        # Code for Basisforme\n",
    "\n",
    "        import Basisformer.model\n",
    "        importlib.reload(Basisformer.model)\n",
    "        from Basisformer.model import Basisformer\n",
    "\n",
    "        import Basisformer.main\n",
    "        importlib.reload(Basisformer.main)\n",
    "        from Basisformer.main import parse_args, model_setup, log_and_print\n",
    "        importlib.reload(Basisformer.pyplot)\n",
    "\n",
    "        class Args:\n",
    "            is_training = True\n",
    "            data_path = 'data'\n",
    "            device = 0\n",
    "            num_workers = 10\n",
    "            features = 'M'\n",
    "            freq = 'h'\n",
    "            seq_len = 96\n",
    "            pred_len = 48\n",
    "            heads = 16\n",
    "            d_model = 512\n",
    "            N = 10\n",
    "            block_nums = 2\n",
    "            bottleneck = 2\n",
    "            map_bottleneck = 20\n",
    "            train_epochs = 50\n",
    "            batch_size = 24\n",
    "            learning_rate = 0.0001\n",
    "            tau = 0.07\n",
    "            loss_weight_prediction = 1.0\n",
    "            loss_weight_infonce = 1.0\n",
    "            loss_weight_smooth = 1.0\n",
    "            check_point = 'checkpoint'\n",
    "            patience = 3\n",
    "\n",
    "        args = Args()\n",
    "        \n",
    "        #args = parse_args()\n",
    "\n",
    "        # Set up device\n",
    "        device = torch.device(f\"cuda:{args.device}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Set up model\n",
    "        model = model_setup(args, device)\n",
    "        \n",
    "        if pretrained_model == None:\n",
    "            # Set up model\n",
    "            model = model_setup(args, device)\n",
    "\n",
    "        else:\n",
    "            model = pretrained_model\n",
    "\n",
    "        # Log arguments and model\n",
    "        ##log_and_print('Args in experiment:')\n",
    "        ##log_and_print(args)\n",
    "        ##log_and_print(model)\n",
    "        \n",
    "        if train_flag:\n",
    "            import Basisformer.model\n",
    "            importlib.reload(Basisformer.model)\n",
    "            from Basisformer.model import Basisformer\n",
    "\n",
    "            import Basisformer.main\n",
    "            importlib.reload(Basisformer.main)\n",
    "            from Basisformer.main import train\n",
    "\n",
    "\n",
    "            record_dir = os.path.join('records', args.data_path.split('.')[0], 'features_' + args.features,\n",
    "                                    'seq_len' + str(args.seq_len) + ',' + 'pred_len' + str(args.pred_len))\n",
    "            \n",
    "            if train_loader == None:\n",
    "                return 'train_loader not found'\n",
    "\n",
    "            # Call the train function\n",
    "            train(model, train_loader, args, device, record_dir)\n",
    "            \n",
    "        else:\n",
    "            if pretrained_model == None:\n",
    "                return 'model not found which is required for testing'\n",
    "            \n",
    "        if test_flag :\n",
    "            import Basisformer.main\n",
    "            importlib.reload(Basisformer.main)\n",
    "            from Basisformer.main import test\n",
    "            \n",
    "            if test_loader == None:\n",
    "                return 'test_loader not found'\n",
    "\n",
    "            test(model, test_loader, args, device, record_dir)\n",
    "        return model\n",
    "            \n",
    "    \n",
    "    elif curr_model == 'itransformer':\n",
    "        # code for itransformer\n",
    "        \n",
    "        import iTransformer.experiment\n",
    "        importlib.reload(iTransformer.experiment)\n",
    "        from iTransformer.experiment import Exp_Long_Term_Forecast\n",
    "        \n",
    "        class Args:\n",
    "            is_training = 1\n",
    "            model_id = 'iTransformer_train'\n",
    "            model = 'iTransformer'\n",
    "            data = 'all_countries'\n",
    "            features = 'M'\n",
    "            target = 'OT'\n",
    "            freq = 'h'\n",
    "            checkpoints = './checkpoints/'\n",
    "            seq_len = 96\n",
    "            label_len = 48\n",
    "            pred_len = 48\n",
    "            enc_in = 24\n",
    "            dec_in = 24\n",
    "            c_out = 24\n",
    "            d_model = 512\n",
    "            n_heads = 8\n",
    "            e_layers = 2\n",
    "            d_layers = 1\n",
    "            d_ff = 2048\n",
    "            moving_avg = 25\n",
    "            factor = 1\n",
    "            distil = True\n",
    "            dropout = 0.05\n",
    "            embed = 'timeF'\n",
    "            activation = 'gelu'\n",
    "            output_attention = False\n",
    "            do_predict = True\n",
    "            num_workers = 10\n",
    "            itr = 2\n",
    "            train_epochs = 50\n",
    "            batch_size = 24\n",
    "            patience = 3\n",
    "            learning_rate = 0.0001\n",
    "            des = 'test'\n",
    "            loss = 'mse'\n",
    "            lradj = 'type1'\n",
    "            use_amp = False\n",
    "            use_gpu = True if torch.cuda.is_available() else False\n",
    "            gpu = 0\n",
    "            use_multi_gpu = False\n",
    "            devices = '0,1,2,3'\n",
    "            exp_name = 'MTSF'\n",
    "            channel_independence = False\n",
    "            inverse = False\n",
    "            class_strategy = 'projection'\n",
    "            target_root_path = './data'\n",
    "            target_data_path = 'all_countries'\n",
    "            efficient_training = False\n",
    "            use_norm = True\n",
    "            partial_start_index = 0\n",
    "            seed = 2021\n",
    "            p_hidden_dims = [128, 128]\n",
    "            p_hidden_layers = 2\n",
    "\n",
    "        args = Args()\n",
    "        \n",
    "        if pretrained_model == None:\n",
    "            # Initialize the experiment\n",
    "            exp = Exp_Long_Term_Forecast(args)\n",
    "\n",
    "        else:\n",
    "            return 'pretrained not valid for iTransformer and ns_autoformer'\n",
    "\n",
    "        # Define the settings\n",
    "        setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}'.format(\n",
    "            args.model_id, args.model, args.data, args.features, args.seq_len, args.label_len,\n",
    "            args.pred_len, args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff,\n",
    "            args.factor, args.embed, args.distil, args.des, 0)\n",
    "        \n",
    "        if train_flag:\n",
    "            Exp_Long_Term_Forecast.train(self=exp, train_loader=train_loader, setting=setting)\n",
    "        \n",
    "        if test_flag:\n",
    "            Exp_Long_Term_Forecast.test(self=exp, test_loader=test_loader, setting=setting, test=0)\n",
    "        return exp.model\n",
    "    \n",
    "    elif curr_model == 'ns_autoformer':\n",
    "        # code for itransformer\n",
    "        import ns_Autoformer.ns_Autoformer\n",
    "        importlib.reload(ns_Autoformer.ns_Autoformer)\n",
    "        from ns_Autoformer.ns_Autoformer import Model\n",
    "\n",
    "        # import ns_Autoformer.main\n",
    "        # importlib.reload(ns_Autoformer.main)\n",
    "        # from ns_Autoformer.main import parse_args\n",
    "        \n",
    "        from ns_Autoformer.main import Exp_Main\n",
    "\n",
    "        class Args:\n",
    "            is_training = 1\n",
    "            model_id = 'ns_autoformer_train'\n",
    "            model = 'ns_Autoformer'\n",
    "            features = 'M'\n",
    "            target = 'OT'\n",
    "            freq = 'h'\n",
    "            checkpoints = './checkpoints/'\n",
    "            seq_len = 96\n",
    "            label_len = 48\n",
    "            pred_len = 48\n",
    "            enc_in = 24\n",
    "            dec_in = 24\n",
    "            c_out = 24\n",
    "            d_model = 512\n",
    "            n_heads = 8\n",
    "            e_layers = 2\n",
    "            d_layers = 1\n",
    "            d_ff = 2048\n",
    "            moving_avg = 25\n",
    "            factor = 1\n",
    "            distil = True\n",
    "            dropout = 0.05\n",
    "            embed = 'timeF'\n",
    "            activation = 'gelu'\n",
    "            output_attention = False\n",
    "            do_predict = True\n",
    "            num_workers = 10\n",
    "            itr = 2\n",
    "            train_epochs = 50\n",
    "            batch_size = 24\n",
    "            patience = 3\n",
    "            learning_rate = 0.0001\n",
    "            des = 'test'\n",
    "            loss = 'mse'\n",
    "            lradj = 'type1'\n",
    "            use_amp = False\n",
    "            use_gpu = True if torch.cuda.is_available() else False\n",
    "            gpu = 0\n",
    "            use_multi_gpu = False\n",
    "            devices = '0,1,2,3'\n",
    "            seed = 2021\n",
    "            p_hidden_dims = [128, 128]\n",
    "            p_hidden_layers = 2\n",
    "\n",
    "        args = Args()\n",
    "\n",
    "        # if args.use_gpu:\n",
    "        #     if args.use_multi_gpu:\n",
    "        #         args.devices = args.devices.replace(' ', '')\n",
    "        #         device_ids = args.devices.split(',')\n",
    "        #         args.device_ids = [int(id_) for id_ in device_ids]\n",
    "        #         args.gpu = args.device_ids[0]\n",
    "        #     else:\n",
    "        #         torch.cuda.set_device(args.gpu)\n",
    "\n",
    "        # print('Args in experiment:')\n",
    "        # print(args)\n",
    "        \n",
    "        if pretrained_model == None:\n",
    "            # Initialize the experiment\n",
    "            exp = Exp_Main(args)\n",
    "\n",
    "        # Define the setting string\n",
    "        setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}'.format(\n",
    "            args.model_id, args.model, args.features, args.seq_len, args.label_len,\n",
    "            args.pred_len, args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff,\n",
    "            args.factor, args.embed, args.distil, args.des, 0)\n",
    "        \n",
    "        if train_flag:\n",
    "            Exp_Main.train(self=exp, train_loader=train_loader, setting=setting)\n",
    "        \n",
    "        if test_flag:\n",
    "            Exp_Main.test(self=exp, test_loader=test_loader, setting=setting, test=0)\n",
    "        return exp.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ee0fbc-fd5f-4b8e-99f0-e0d05ff0826d",
   "metadata": {},
   "source": [
    "## Basisformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ILk9LX4k5Yuu",
   "metadata": {
    "id": "ILk9LX4k5Yuu"
   },
   "outputs": [],
   "source": [
    "seq_length = 96\n",
    "pred_length = 48\n",
    "label_length = 48\n",
    "curr_model = \"basis_former\"\n",
    "\n",
    "train_seq_x, train_seq_y = create_sequences(electricity_prices_train_scaled, seq_length, pred_length, label_length, curr_model)\n",
    "train_seq_x_mark, train_seq_y_mark = create_sequences(timestamp_features_train.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "\n",
    "test_seq_x, test_seq_y = create_sequences(electricity_prices_test_scaled, seq_length, pred_length,label_length, curr_model)\n",
    "test_seq_x_mark, test_seq_y_mark = create_sequences(timestamp_features_test.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "IeE-jvzOEVw-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IeE-jvzOEVw-",
    "outputId": "d4778504-79d4-475b-c868-17b3994fd3fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample training sequence x: [[0.63620409 0.59957668 0.61886857 ... 0.95994704 0.03725768 0.65732351]\n",
      " [0.61063056 0.58860881 0.53227369 ... 0.71427783 0.03349409 0.62297112]\n",
      " [0.52996114 0.54897056 0.45946562 ... 0.60686307 0.02867139 0.58946614]\n",
      " ...\n",
      " [0.39632694 0.40985184 0.37440893 ... 0.3586009  0.08359338 0.60902158]\n",
      " [0.41707409 0.43390418 0.39013274 ... 0.38894406 0.0790922  0.60771788]\n",
      " [0.38071957 0.38406773 0.35595055 ... 0.39710913 0.07313475 0.58229581]]\n",
      "Sample training sequence y: [[0.572521   0.57706369 0.539338   ... 0.43236235 0.13401418 0.62831628]\n",
      " [0.50231917 0.50522737 0.4752464  ... 0.39644709 0.12514421 0.63489994]\n",
      " [0.46333208 0.46962991 0.44727397 ... 0.33885027 0.11810875 0.66905678]\n",
      " ...\n",
      " [0.08668672 0.13873388 0.0151541  ... 0.4279488  0.07952719 0.13010886]\n",
      " [0.08668672 0.14040151 0.0623825  ... 0.56024495 0.07232151 0.15155466]\n",
      " [0.06506205 0.13655314 0.05184299 ... 0.60300121 0.0661182  0.12541555]]\n",
      "Sample training sequence x mark: [[12 18  0 19]\n",
      " [12 18  0 20]\n",
      " [12 18  0 21]\n",
      " [12 18  0 22]\n",
      " [12 18  0 23]\n",
      " [12 19  1  0]\n",
      " [12 19  1  1]\n",
      " [12 19  1  2]\n",
      " [12 19  1  3]\n",
      " [12 19  1  4]\n",
      " [12 19  1  5]\n",
      " [12 19  1  6]\n",
      " [12 19  1  7]\n",
      " [12 19  1  8]\n",
      " [12 19  1  9]\n",
      " [12 19  1 10]\n",
      " [12 19  1 11]\n",
      " [12 19  1 12]\n",
      " [12 19  1 13]\n",
      " [12 19  1 14]\n",
      " [12 19  1 15]\n",
      " [12 19  1 16]\n",
      " [12 19  1 17]\n",
      " [12 19  1 18]\n",
      " [12 19  1 19]\n",
      " [12 19  1 20]\n",
      " [12 19  1 21]\n",
      " [12 19  1 22]\n",
      " [12 19  1 23]\n",
      " [12 20  2  0]\n",
      " [12 20  2  1]\n",
      " [12 20  2  2]\n",
      " [12 20  2  3]\n",
      " [12 20  2  4]\n",
      " [12 20  2  5]\n",
      " [12 20  2  6]\n",
      " [12 20  2  7]\n",
      " [12 20  2  8]\n",
      " [12 20  2  9]\n",
      " [12 20  2 10]\n",
      " [12 20  2 11]\n",
      " [12 20  2 12]\n",
      " [12 20  2 13]\n",
      " [12 20  2 14]\n",
      " [12 20  2 15]\n",
      " [12 20  2 16]\n",
      " [12 20  2 17]\n",
      " [12 20  2 18]\n",
      " [12 20  2 19]\n",
      " [12 20  2 20]\n",
      " [12 20  2 21]\n",
      " [12 20  2 22]\n",
      " [12 20  2 23]\n",
      " [12 21  3  0]\n",
      " [12 21  3  1]\n",
      " [12 21  3  2]\n",
      " [12 21  3  3]\n",
      " [12 21  3  4]\n",
      " [12 21  3  5]\n",
      " [12 21  3  6]\n",
      " [12 21  3  7]\n",
      " [12 21  3  8]\n",
      " [12 21  3  9]\n",
      " [12 21  3 10]\n",
      " [12 21  3 11]\n",
      " [12 21  3 12]\n",
      " [12 21  3 13]\n",
      " [12 21  3 14]\n",
      " [12 21  3 15]\n",
      " [12 21  3 16]\n",
      " [12 21  3 17]\n",
      " [12 21  3 18]\n",
      " [12 21  3 19]\n",
      " [12 21  3 20]\n",
      " [12 21  3 21]\n",
      " [12 21  3 22]\n",
      " [12 21  3 23]\n",
      " [12 22  4  0]\n",
      " [12 22  4  1]\n",
      " [12 22  4  2]\n",
      " [12 22  4  3]\n",
      " [12 22  4  4]\n",
      " [12 22  4  5]\n",
      " [12 22  4  6]\n",
      " [12 22  4  7]\n",
      " [12 22  4  8]\n",
      " [12 22  4  9]\n",
      " [12 22  4 10]\n",
      " [12 22  4 11]\n",
      " [12 22  4 12]\n",
      " [12 22  4 13]\n",
      " [12 22  4 14]\n",
      " [12 22  4 15]\n",
      " [12 22  4 16]\n",
      " [12 22  4 17]\n",
      " [12 22  4 18]]\n",
      "Sample training sequence y mark: [[12 20  2 19]\n",
      " [12 20  2 20]\n",
      " [12 20  2 21]\n",
      " [12 20  2 22]\n",
      " [12 20  2 23]\n",
      " [12 21  3  0]\n",
      " [12 21  3  1]\n",
      " [12 21  3  2]\n",
      " [12 21  3  3]\n",
      " [12 21  3  4]\n",
      " [12 21  3  5]\n",
      " [12 21  3  6]\n",
      " [12 21  3  7]\n",
      " [12 21  3  8]\n",
      " [12 21  3  9]\n",
      " [12 21  3 10]\n",
      " [12 21  3 11]\n",
      " [12 21  3 12]\n",
      " [12 21  3 13]\n",
      " [12 21  3 14]\n",
      " [12 21  3 15]\n",
      " [12 21  3 16]\n",
      " [12 21  3 17]\n",
      " [12 21  3 18]\n",
      " [12 21  3 19]\n",
      " [12 21  3 20]\n",
      " [12 21  3 21]\n",
      " [12 21  3 22]\n",
      " [12 21  3 23]\n",
      " [12 22  4  0]\n",
      " [12 22  4  1]\n",
      " [12 22  4  2]\n",
      " [12 22  4  3]\n",
      " [12 22  4  4]\n",
      " [12 22  4  5]\n",
      " [12 22  4  6]\n",
      " [12 22  4  7]\n",
      " [12 22  4  8]\n",
      " [12 22  4  9]\n",
      " [12 22  4 10]\n",
      " [12 22  4 11]\n",
      " [12 22  4 12]\n",
      " [12 22  4 13]\n",
      " [12 22  4 14]\n",
      " [12 22  4 15]\n",
      " [12 22  4 16]\n",
      " [12 22  4 17]\n",
      " [12 22  4 18]\n",
      " [12 22  4 19]\n",
      " [12 22  4 20]\n",
      " [12 22  4 21]\n",
      " [12 22  4 22]\n",
      " [12 22  4 23]\n",
      " [12 23  5  0]\n",
      " [12 23  5  1]\n",
      " [12 23  5  2]\n",
      " [12 23  5  3]\n",
      " [12 23  5  4]\n",
      " [12 23  5  5]\n",
      " [12 23  5  6]\n",
      " [12 23  5  7]\n",
      " [12 23  5  8]\n",
      " [12 23  5  9]\n",
      " [12 23  5 10]\n",
      " [12 23  5 11]\n",
      " [12 23  5 12]\n",
      " [12 23  5 13]\n",
      " [12 23  5 14]\n",
      " [12 23  5 15]\n",
      " [12 23  5 16]\n",
      " [12 23  5 17]\n",
      " [12 23  5 18]\n",
      " [12 23  5 19]\n",
      " [12 23  5 20]\n",
      " [12 23  5 21]\n",
      " [12 23  5 22]\n",
      " [12 23  5 23]\n",
      " [12 24  6  0]\n",
      " [12 24  6  1]\n",
      " [12 24  6  2]\n",
      " [12 24  6  3]\n",
      " [12 24  6  4]\n",
      " [12 24  6  5]\n",
      " [12 24  6  6]\n",
      " [12 24  6  7]\n",
      " [12 24  6  8]\n",
      " [12 24  6  9]\n",
      " [12 24  6 10]\n",
      " [12 24  6 11]\n",
      " [12 24  6 12]\n",
      " [12 24  6 13]\n",
      " [12 24  6 14]\n",
      " [12 24  6 15]\n",
      " [12 24  6 16]\n",
      " [12 24  6 17]\n",
      " [12 24  6 18]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample training sequence x:\", train_seq_x[0])\n",
    "print(\"Sample training sequence y:\", train_seq_y[0])\n",
    "print(\"Sample training sequence x mark:\", train_seq_x_mark[0])\n",
    "print(\"Sample training sequence y mark:\", train_seq_y_mark[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "OrL7qSyl5bqB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OrL7qSyl5bqB",
    "outputId": "01496ef4-4d84-4630-dc4b-5a1b9c36a404"
   },
   "outputs": [],
   "source": [
    "batch_size = 24\n",
    "\n",
    "# converting sequences to PyTorch DataLoader objects\n",
    "train_loader = create_dataloader(train_seq_x, train_seq_y, train_seq_x_mark, train_seq_y_mark, batch_size, curr_model)\n",
    "test_loader = create_dataloader(test_seq_x, test_seq_y, test_seq_x_mark, test_seq_y_mark, batch_size, curr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "2ca8679b-4ac1-42ab-8065-f6f2519e40cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch contains 5 items:\n",
      "Item 0: Shape = torch.Size([24, 96, 24])\n",
      "Item 1: Shape = torch.Size([24, 96, 24])\n",
      "Item 2: Shape = torch.Size([24, 96, 4])\n",
      "Item 3: Shape = torch.Size([24, 96, 4])\n",
      "Item 4: Shape = torch.Size([24, 192])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(f\"Batch contains {len(batch)} items:\")\n",
    "    for i, item in enumerate(batch):\n",
    "        print(f\"Item {i}: Shape = {item.shape if torch.is_tensor(item) else 'Not a tensor'}\")\n",
    "    break  # Just print the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Des1ClFuevfI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Des1ClFuevfI",
    "outputId": "538a4886-5959-4a8c-a4e8-3239df3ed5ec"
   },
   "outputs": [],
   "source": [
    "##pip install adabelief_pytorch==0.2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25388088-0a01-4a53-9327-36baeb5ec317",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "33d34df7-21cb-4303-87f9-d5ec8c03ec8e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33d34df7-21cb-4303-87f9-d5ec8c03ec8e",
    "outputId": "3c5fe222-fb0a-4abc-d84a-489ef41b44b1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\titers: 15, epoch: 1 | loss: 2.7772989\n",
      "INFO:root:\titers: 30, epoch: 1 | loss: 1.0085220\n",
      "INFO:root:\titers: 45, epoch: 1 | loss: 0.2749456\n",
      "INFO:root:\titers: 60, epoch: 1 | loss: 0.1483428\n",
      "INFO:root:\titers: 75, epoch: 1 | loss: 0.1595481\n",
      "INFO:root:Epoch: 1 cost time: 3.381474494934082\n",
      "INFO:root:loss_pred:0.016862093350039672\n",
      "INFO:root:loss entropy:1.0131029602972292\n",
      "INFO:root:loss smooth:0.13612646745009857\n",
      "INFO:root:Epoch: 1 | Train Loss: 1.1660915\n",
      "INFO:root:\titers: 15, epoch: 2 | loss: 0.1459127\n",
      "INFO:root:\titers: 30, epoch: 2 | loss: 0.1475278\n",
      "INFO:root:\titers: 45, epoch: 2 | loss: 0.1204328\n",
      "INFO:root:\titers: 60, epoch: 2 | loss: 0.1706662\n",
      "INFO:root:\titers: 75, epoch: 2 | loss: 0.2184069\n",
      "INFO:root:Epoch: 2 cost time: 3.4860928058624268\n",
      "INFO:root:loss_pred:0.01676437042218137\n",
      "INFO:root:loss entropy:0.05144979293713392\n",
      "INFO:root:loss smooth:0.10698402421428012\n",
      "INFO:root:Epoch: 2 | Train Loss: 0.1751982\n",
      "INFO:root:\titers: 15, epoch: 3 | loss: 0.1885138\n",
      "INFO:root:\titers: 30, epoch: 3 | loss: 0.2102640\n",
      "INFO:root:\titers: 45, epoch: 3 | loss: 0.1243715\n",
      "INFO:root:\titers: 60, epoch: 3 | loss: 0.1230228\n",
      "INFO:root:\titers: 75, epoch: 3 | loss: 0.1233212\n",
      "INFO:root:Epoch: 3 cost time: 3.399925470352173\n",
      "INFO:root:loss_pred:0.016807126994063327\n",
      "INFO:root:loss entropy:0.07782303427716851\n",
      "INFO:root:loss smooth:0.10596937705557068\n",
      "INFO:root:Epoch: 3 | Train Loss: 0.2005995\n",
      "INFO:root:\titers: 15, epoch: 4 | loss: 0.1118983\n",
      "INFO:root:\titers: 30, epoch: 4 | loss: 0.1267528\n",
      "INFO:root:\titers: 45, epoch: 4 | loss: 0.1068294\n",
      "INFO:root:\titers: 60, epoch: 4 | loss: 0.1028039\n",
      "INFO:root:\titers: 75, epoch: 4 | loss: 0.1009773\n",
      "INFO:root:Epoch: 4 cost time: 3.338287591934204\n",
      "INFO:root:loss_pred:0.016735352769300535\n",
      "INFO:root:loss entropy:0.002514566149270388\n",
      "INFO:root:loss smooth:0.09392036449212532\n",
      "INFO:root:Epoch: 4 | Train Loss: 0.1131703\n",
      "INFO:root:\titers: 15, epoch: 5 | loss: 0.1720815\n",
      "INFO:root:\titers: 30, epoch: 5 | loss: 0.0939267\n",
      "INFO:root:\titers: 45, epoch: 5 | loss: 0.0988938\n",
      "INFO:root:\titers: 60, epoch: 5 | loss: 0.0954168\n",
      "INFO:root:\titers: 75, epoch: 5 | loss: 0.0882497\n",
      "INFO:root:Epoch: 5 cost time: 3.433119535446167\n",
      "INFO:root:loss_pred:0.01661611113745671\n",
      "INFO:root:loss entropy:0.0030752341640583186\n",
      "INFO:root:loss smooth:0.07969542873370183\n",
      "INFO:root:Epoch: 5 | Train Loss: 0.0993868\n",
      "INFO:root:\titers: 15, epoch: 6 | loss: 0.0884465\n",
      "INFO:root:\titers: 30, epoch: 6 | loss: 0.0920343\n",
      "INFO:root:\titers: 45, epoch: 6 | loss: 0.1656544\n",
      "INFO:root:\titers: 60, epoch: 6 | loss: 0.2262230\n",
      "INFO:root:\titers: 75, epoch: 6 | loss: 0.5933474\n",
      "INFO:root:Epoch: 6 cost time: 3.3673577308654785\n",
      "INFO:root:loss_pred:0.01657864133307299\n",
      "INFO:root:loss entropy:0.0879071390135546\n",
      "INFO:root:loss smooth:0.07650745592334053\n",
      "INFO:root:Epoch: 6 | Train Loss: 0.1809932\n",
      "INFO:root:\titers: 15, epoch: 7 | loss: 0.1115627\n",
      "INFO:root:\titers: 30, epoch: 7 | loss: 0.1546473\n",
      "INFO:root:\titers: 45, epoch: 7 | loss: 0.2908963\n",
      "INFO:root:\titers: 60, epoch: 7 | loss: 0.1964644\n",
      "INFO:root:\titers: 75, epoch: 7 | loss: 0.1046128\n",
      "INFO:root:Epoch: 7 cost time: 3.5853147506713867\n",
      "INFO:root:loss_pred:0.016706014330220686\n",
      "INFO:root:loss entropy:0.15300569422636717\n",
      "INFO:root:loss smooth:0.0935366859103178\n",
      "INFO:root:Epoch: 7 | Train Loss: 0.2632484\n",
      "INFO:root:\titers: 15, epoch: 8 | loss: 0.1125318\n",
      "INFO:root:\titers: 30, epoch: 8 | loss: 0.1025579\n",
      "INFO:root:\titers: 45, epoch: 8 | loss: 0.1192835\n",
      "INFO:root:\titers: 60, epoch: 8 | loss: 0.1037788\n",
      "INFO:root:\titers: 75, epoch: 8 | loss: 0.0992633\n",
      "INFO:root:Epoch: 8 cost time: 3.4231138229370117\n",
      "INFO:root:loss_pred:0.016564456371034122\n",
      "INFO:root:loss entropy:0.012295286524302985\n",
      "INFO:root:loss smooth:0.08772918107834729\n",
      "INFO:root:Epoch: 8 | Train Loss: 0.1165889\n",
      "INFO:root:loading model\n",
      "INFO:root:total_time:2.620861053466797\n",
      "INFO:root:avg_time:0.18720436096191406\n",
      "INFO:root:mse:0.023538149893283844, mae:0.10369474440813065, mape:inf, rmse:0.15342147648334503\n"
     ]
    }
   ],
   "source": [
    "%%capture captured_output\n",
    "curr_model = \"basis_former\" \n",
    "basisformer_train_test = fit(model=curr_model, train_flag=True, test_flag=True, train_loader=train_loader, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ffc309-339b-43e4-ab87-1e1ece074e45",
   "metadata": {},
   "source": [
    "## iTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "adf6cf6e-e6dc-41fd-a14e-db5a55912360",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 96\n",
    "pred_length = 48\n",
    "label_length = 48\n",
    "curr_model = \"itransformer\"\n",
    "\n",
    "train_seq_x, train_seq_y = create_sequences(electricity_prices_train_scaled, seq_length, pred_length, label_length, curr_model)\n",
    "train_seq_x_mark, train_seq_y_mark = create_sequences(timestamp_features_train.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "\n",
    "test_seq_x, test_seq_y = create_sequences(electricity_prices_test_scaled, seq_length, pred_length,label_length, curr_model)\n",
    "test_seq_x_mark, test_seq_y_mark = create_sequences(timestamp_features_test.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "\n",
    "# converting sequences to PyTorch DataLoader objects\n",
    "train_loader = create_dataloader(train_seq_x, train_seq_y, train_seq_x_mark, train_seq_y_mark, batch_size, curr_model)\n",
    "test_loader = create_dataloader(test_seq_x, test_seq_y, test_seq_x_mark, test_seq_y_mark, batch_size, curr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca24c83-5c85-41d7-adfb-4b679d9bb9cf",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "c5207bb8-dd92-41b0-9f62-eb436fb7e4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "Epoch: 1 cost time: 0.9888520240783691\n",
      "Epoch: 1, Steps: 77 | Train Loss: 0.0118243\n",
      "Validation loss decreased (inf --> 0.011824).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 1.0110671520233154\n",
      "Epoch: 2, Steps: 77 | Train Loss: 0.0095816\n",
      "Validation loss decreased (0.011824 --> 0.009582).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 1.0544493198394775\n",
      "Epoch: 3, Steps: 77 | Train Loss: 0.0087091\n",
      "Validation loss decreased (0.009582 --> 0.008709).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 1.0203924179077148\n",
      "Epoch: 4, Steps: 77 | Train Loss: 0.0080874\n",
      "Validation loss decreased (0.008709 --> 0.008087).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 0.9425961971282959\n",
      "Epoch: 5, Steps: 77 | Train Loss: 0.0077332\n",
      "Validation loss decreased (0.008087 --> 0.007733).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 0.9534096717834473\n",
      "Epoch: 6, Steps: 77 | Train Loss: 0.0075112\n",
      "Validation loss decreased (0.007733 --> 0.007511).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 1.0107078552246094\n",
      "Epoch: 7, Steps: 77 | Train Loss: 0.0074273\n",
      "Validation loss decreased (0.007511 --> 0.007427).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 0.9617714881896973\n",
      "Epoch: 8, Steps: 77 | Train Loss: 0.0073644\n",
      "Validation loss decreased (0.007427 --> 0.007364).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 0.9546711444854736\n",
      "Epoch: 9, Steps: 77 | Train Loss: 0.0073478\n",
      "Validation loss decreased (0.007364 --> 0.007348).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 0.9830038547515869\n",
      "Epoch: 10, Steps: 77 | Train Loss: 0.0073247\n",
      "Validation loss decreased (0.007348 --> 0.007325).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 0.9642693996429443\n",
      "Epoch: 11, Steps: 77 | Train Loss: 0.0073346\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 0.9629199504852295\n",
      "Epoch: 12, Steps: 77 | Train Loss: 0.0073015\n",
      "Validation loss decreased (0.007325 --> 0.007302).  Saving model ...\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 0.9894504547119141\n",
      "Epoch: 13, Steps: 77 | Train Loss: 0.0072923\n",
      "Validation loss decreased (0.007302 --> 0.007292).  Saving model ...\n",
      "Updating learning rate to 2.44140625e-08\n",
      "Epoch: 14 cost time: 1.025350570678711\n",
      "Epoch: 14, Steps: 77 | Train Loss: 0.0073130\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.220703125e-08\n",
      "Epoch: 15 cost time: 0.9569032192230225\n",
      "Epoch: 15, Steps: 77 | Train Loss: 0.0072985\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.103515625e-09\n",
      "Epoch: 16 cost time: 1.0334618091583252\n",
      "Epoch: 16, Steps: 77 | Train Loss: 0.0073240\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test shape: (14, 24, 48, 24) (14, 24, 48, 24)\n",
      "test shape: (336, 48, 24) (336, 48, 24)\n",
      "mse:0.014830589294433594, mae:0.08336111903190613, mape:inf, rmse0.12178090959787369:\n"
     ]
    }
   ],
   "source": [
    "itransformer_train_test = fit(model=curr_model, train_flag=True, test_flag=True, train_loader=train_loader, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa62ae11-381d-4aaf-9e32-ade675824eeb",
   "metadata": {},
   "source": [
    "## Nonstationary Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "80a8451f-0280-4b1d-83f4-645080a0ebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_model = \"ns_autoformer\"\n",
    "\n",
    "train_seq_x, train_seq_y = create_sequences(electricity_prices_train_scaled, seq_length, pred_length, label_length, curr_model)\n",
    "train_seq_x_mark, train_seq_y_mark = create_sequences(timestamp_features_train.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "\n",
    "test_seq_x, test_seq_y = create_sequences(electricity_prices_test_scaled, seq_length, pred_length,label_length, curr_model)\n",
    "test_seq_x_mark, test_seq_y_mark = create_sequences(timestamp_features_test.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "\n",
    "# converting sequences to PyTorch DataLoader objects\n",
    "train_loader = create_dataloader(train_seq_x, train_seq_y, train_seq_x_mark, train_seq_y_mark, batch_size, curr_model)\n",
    "test_loader = create_dataloader(test_seq_x, test_seq_y, test_seq_x_mark, test_seq_y_mark, batch_size, curr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8affed",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "55134ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "Epoch: 1 cost time: 3.612320899963379\n",
      "Epoch: 1, Steps: 77 | Train Loss: 0.0235922\n",
      "Validation loss decreased (inf --> 0.023592).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 3.5533363819122314\n",
      "Epoch: 2, Steps: 77 | Train Loss: 0.0137995\n",
      "Validation loss decreased (0.023592 --> 0.013800).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 3.57230806350708\n",
      "Epoch: 3, Steps: 77 | Train Loss: 0.0116421\n",
      "Validation loss decreased (0.013800 --> 0.011642).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 3.575103998184204\n",
      "Epoch: 4, Steps: 77 | Train Loss: 0.0103056\n",
      "Validation loss decreased (0.011642 --> 0.010306).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 3.555845260620117\n",
      "Epoch: 5, Steps: 77 | Train Loss: 0.0096618\n",
      "Validation loss decreased (0.010306 --> 0.009662).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 3.587740421295166\n",
      "Epoch: 6, Steps: 77 | Train Loss: 0.0094291\n",
      "Validation loss decreased (0.009662 --> 0.009429).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 3.6328189373016357\n",
      "Epoch: 7, Steps: 77 | Train Loss: 0.0093249\n",
      "Validation loss decreased (0.009429 --> 0.009325).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 3.575031042098999\n",
      "Epoch: 8, Steps: 77 | Train Loss: 0.0092418\n",
      "Validation loss decreased (0.009325 --> 0.009242).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 3.5684337615966797\n",
      "Epoch: 9, Steps: 77 | Train Loss: 0.0092339\n",
      "Validation loss decreased (0.009242 --> 0.009234).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 3.4604344367980957\n",
      "Epoch: 10, Steps: 77 | Train Loss: 0.0092798\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 3.4394869804382324\n",
      "Epoch: 11, Steps: 77 | Train Loss: 0.0092550\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 3.4086313247680664\n",
      "Epoch: 12, Steps: 77 | Train Loss: 0.0092045\n",
      "Validation loss decreased (0.009234 --> 0.009205).  Saving model ...\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 3.648667097091675\n",
      "Epoch: 13, Steps: 77 | Train Loss: 0.0092363\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "Epoch: 14 cost time: 3.5959348678588867\n",
      "Epoch: 14, Steps: 77 | Train Loss: 0.0092224\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.220703125e-08\n",
      "Epoch: 15 cost time: 3.5445187091827393\n",
      "Epoch: 15, Steps: 77 | Train Loss: 0.0092057\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test shape: (14, 24, 48, 24) (14, 24, 48, 24)\n",
      "test shape: (336, 48, 24) (336, 48, 24)\n",
      "mse:0.020524004474282265, mae:0.09985638409852982, mape:inf, rmse:0.14326201379299164\n"
     ]
    }
   ],
   "source": [
    "ns_autoformer_train_test = fit(model=curr_model, train_flag=True, test_flag=True, train_loader=train_loader, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2803d193-eb4d-4ba8-b719-e2fa360e4167",
   "metadata": {},
   "source": [
    "# 3. Results - Models Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "b48d07c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Model   RMSE\n",
      "0         Linear Regression  12.29\n",
      "1                      LSTM  14.85\n",
      "2                   Chronos  33.28\n",
      "3  Nonstationary Autoformer   0.14\n",
      "4               Basisformer   0.15\n",
      "5              iTransformer   0.12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary to hold the results\n",
    "results = {\n",
    "    'Model': ['Linear Regression', 'LSTM', 'Chronos', 'Nonstationary Autoformer', 'Basisformer', 'iTransformer'],\n",
    "    # 'RMSE': [rmse_lr, rmse_lstm, rmse_chronos, rmse_nsautoformer, rmse_basisformer, rmse_itransformer]\n",
    "    'RMSE': [12.29, 14.85, 33.28, 0.14, 0.15, 0.12]\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results table\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0bbe9e-2ecc-49c0-bf7b-356fb6f80758",
   "metadata": {},
   "source": [
    "# 4. Outlook "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0876475-7871-4b24-b71c-4d70f4d5adea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Chronos Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56344b93-c9be-4c74-a0af-028dfdd20cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"chronos[training] @ git+https://github.com/amazon-science/chronos-forecasting.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb5bb54-ba52-4564-9775-05648c81013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python supporting_files_chronos/kernel-synth.py --num-series 500 --max-kernels 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "4c174fb6-a8cb-4ffb-b5fd-09a6d7908d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         start target._np_shape  \\\n",
      "0   2000-01-01        [1024, 3]   \n",
      "1   2000-01-01        [1024, 3]   \n",
      "2   2000-01-01        [1024, 3]   \n",
      "3   2000-01-01        [1024, 3]   \n",
      "4   2000-01-01        [1024, 3]   \n",
      "..         ...              ...   \n",
      "495 2000-01-01        [1024, 3]   \n",
      "496 2000-01-01        [1024, 3]   \n",
      "497 2000-01-01        [1024, 3]   \n",
      "498 2000-01-01        [1024, 3]   \n",
      "499 2000-01-01        [1024, 3]   \n",
      "\n",
      "                                                target  \n",
      "0    [-1.3293273404902177e-07, 1.7617705479648852e-...  \n",
      "1    [0.8820515850319665, -2.630758929416405, -0.28...  \n",
      "2    [1.0917233174006584, -0.30767090449730106, 0.1...  \n",
      "3    [-1.4419568333102197, -0.2799756872675115, -0....  \n",
      "4    [-0.8402086553986396, -1.5435372346614247, -0....  \n",
      "..                                                 ...  \n",
      "495  [5.2983733022775885, -9.044641569560579, -3.15...  \n",
      "496  [-0.7313010836303305, -0.8540684084420854, 0.9...  \n",
      "497  [-0.8684795217377739, -0.5001586491794001, 0.2...  \n",
      "498  [0.8238722298539525, -1.3771194164186111, 1.19...  \n",
      "499  [-1.0899352102176127, 1.0528479056643296, -2.3...  \n",
      "\n",
      "[500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.ipc as ipc\n",
    "\n",
    "file_path = 'supporting_files_chronos/kernelsynth-data.arrow'\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    reader = ipc.RecordBatchFileReader(f)\n",
    "    table = reader.read_all()\n",
    "\n",
    "df_ch = table.to_pandas()\n",
    "\n",
    "print(df_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "961121e6-2507-475c-8a80-7d6eb4489466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Number of time series\n",
    "num_series = 15\n",
    "# Number of plots per row\n",
    "plots_per_row = 5\n",
    "# Number of rows\n",
    "num_rows = (num_series + plots_per_row - 1) // plots_per_row\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, plots_per_row, figsize=(15, num_rows * 3))\n",
    "\n",
    "for i in range(num_series):\n",
    "    row = i // plots_per_row\n",
    "    col = i % plots_per_row\n",
    "    ax = axes[row, col]\n",
    "    ax.plot(df_ch['target'].iloc[i])\n",
    "    ax.set_title(f'Time Series {i}')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Value')\n",
    "\n",
    "# Remove any empty subplots\n",
    "for j in range(i + 1, num_rows * plots_per_row):\n",
    "    fig.delaxes(axes.flatten()[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9102227-5e5b-43ca-886e-362609622ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python supporting_files_chronos/kernel-synth-mult.py --num-series 500 --max-kernels 2 --dimensions 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "26c8baf1-c81a-4d00-a358-68f3697deda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         start target._np_shape  \\\n",
      "0   2000-01-01        [1024, 3]   \n",
      "1   2000-01-01        [1024, 3]   \n",
      "2   2000-01-01        [1024, 3]   \n",
      "3   2000-01-01        [1024, 3]   \n",
      "4   2000-01-01        [1024, 3]   \n",
      "..         ...              ...   \n",
      "495 2000-01-01        [1024, 3]   \n",
      "496 2000-01-01        [1024, 3]   \n",
      "497 2000-01-01        [1024, 3]   \n",
      "498 2000-01-01        [1024, 3]   \n",
      "499 2000-01-01        [1024, 3]   \n",
      "\n",
      "                                                target  \n",
      "0    [-1.3293273404902177e-07, 1.7617705479648852e-...  \n",
      "1    [0.8820515850319665, -2.630758929416405, -0.28...  \n",
      "2    [1.0917233174006584, -0.30767090449730106, 0.1...  \n",
      "3    [-1.4419568333102197, -0.2799756872675115, -0....  \n",
      "4    [-0.8402086553986396, -1.5435372346614247, -0....  \n",
      "..                                                 ...  \n",
      "495  [5.2983733022775885, -9.044641569560579, -3.15...  \n",
      "496  [-0.7313010836303305, -0.8540684084420854, 0.9...  \n",
      "497  [-0.8684795217377739, -0.5001586491794001, 0.2...  \n",
      "498  [0.8238722298539525, -1.3771194164186111, 1.19...  \n",
      "499  [-1.0899352102176127, 1.0528479056643296, -2.3...  \n",
      "\n",
      "[500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.ipc as ipc\n",
    "\n",
    "file_path = 'supporting_files_chronos/kernelsynth-data.arrow'\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    reader = ipc.RecordBatchFileReader(f)\n",
    "    table = reader.read_all()\n",
    "\n",
    "df_ch_mult = table.to_pandas()\n",
    "\n",
    "print(df_ch_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "fe2f68c5-3899-42e3-a491-fae38480a6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       start target._np_shape  \\\n",
      "0 2000-01-01        [1024, 3]   \n",
      "1 2000-01-01        [1024, 3]   \n",
      "2 2000-01-01        [1024, 3]   \n",
      "3 2000-01-01        [1024, 3]   \n",
      "4 2000-01-01        [1024, 3]   \n",
      "\n",
      "                                              target  \n",
      "0  [-1.3293273404902177e-07, 1.7617705479648852e-...  \n",
      "1  [0.8820515850319665, -2.630758929416405, -0.28...  \n",
      "2  [1.0917233174006584, -0.30767090449730106, 0.1...  \n",
      "3  [-1.4419568333102197, -0.2799756872675115, -0....  \n",
      "4  [-0.8402086553986396, -1.5435372346614247, -0....  \n",
      "0    (3072,)\n",
      "1    (3072,)\n",
      "2    (3072,)\n",
      "3    (3072,)\n",
      "4    (3072,)\n",
      "Name: target, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_ch_mult.head())\n",
    "print(df_ch_mult['target'].head().apply(lambda x: np.array(x).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "e1fb2bce-e5b5-4f44-b2f7-76815d8a78d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot multivariate time series\n",
    "def plot_multivariate_time_series(data, num_rows=3, num_cols=5):\n",
    "    num_series = num_rows * num_cols\n",
    "    time_points = np.arange(len(data[0]) // 3)  # 1024 time points for reshaped data\n",
    "    \n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(20, num_rows * 4))\n",
    "    axs = axs.flatten()  # Flatten to easily iterate over subplots\n",
    "    \n",
    "    for i in range(num_series):\n",
    "        series = np.array(data[i]).reshape(-1, 3)  # Reshape to [1024, 3]\n",
    "        for j in range(series.shape[1]):\n",
    "            axs[i].plot(time_points, series[:, j], label=f'Dimension {j+1}')\n",
    "        axs[i].set_title(f'Time Series {i+1}')\n",
    "        axs[i].set_xlabel('Time')\n",
    "        axs[i].set_ylabel('Value')\n",
    "        axs[i].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Extract the 'target' column as a list and plot the first 15 multivariate time series\n",
    "plot_multivariate_time_series(df_ch_mult['target'].head(15).tolist(), num_rows=3, num_cols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8868e96d-c11f-44da-8284-5e3bdd7aa438",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## DYNOTEARS Causal Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3be40c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalnex.structure.notears import from_pandas\n",
    "df_str = df.drop(columns=['Datetime (UTC)'])\n",
    "sm = from_pandas(df_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b7a18a-5c45-4440-b616-9c6f949c4db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalnex.plots import plot_structure, NODE_STYLE, EDGE_STYLE\n",
    "\n",
    "viz = plot_structure(\n",
    "    sm,\n",
    "    all_node_attributes=NODE_STYLE.WEAK,\n",
    "    all_edge_attributes=EDGE_STYLE.WEAK,\n",
    ")\n",
    "\n",
    "viz.toggle_physics(False)\n",
    "viz.show(\"supporting_files_dynotears/01_fully_connected.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297ebd63-03d7-45ab-8815-f4417d6ffeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.remove_edges_below_threshold(0.8)\n",
    "viz = plot_structure(\n",
    "    sm,\n",
    "    all_node_attributes=NODE_STYLE.WEAK,\n",
    "    all_edge_attributes=EDGE_STYLE.WEAK,\n",
    ")\n",
    "viz.show(\"supporting_files_dynotears/01_thresholded.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed52dbcf-3b38-457a-b105-b536abcccf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalnex.structure.notears import from_pandas\n",
    "df_str = df.drop(columns=['Datetime (UTC)'])\n",
    "sm = from_pandas(df_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad28f5e0-39c1-4129-a872-fa77fc837671",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.remove_edges_below_threshold(0.8)\n",
    "viz = plot_structure(\n",
    "    sm,\n",
    "    all_node_attributes=NODE_STYLE.WEAK,\n",
    "    all_edge_attributes=EDGE_STYLE.WEAK,\n",
    ")\n",
    "viz.show(\"supporting_files_dynotears/01_thresholded.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27208a4-9616-40ff-b2f3-d4455498b979",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Granger causality test with nonlinear forecasting methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71002567-98ca-49d4-a3d1-eb9dc74bf455",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nonlincausality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a85194-ab4f-4f57-b164-abe8bce5091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Feb  7 23:29:32 2022\n",
    "\n",
    "@author: Maciej Rosoł\n",
    "\n",
    "contact: mrosol5@gmail.com, maciej.rosol.dokt@pw.edu.pl\n",
    "\"\"\"\n",
    "#%%\n",
    "import os\n",
    "\n",
    "# os.chdir(os.path.dirname(__file__))\n",
    "import numpy as np\n",
    "##import tensorflow\n",
    "import nonlincausality as nlc\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from nonlincausality.utils import prepare_data_for_prediction, calculate_pred_and_errors\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae4f41d-d94a-4877-987a-206fe905892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Data generation Y->X\n",
    "np.random.seed(10)\n",
    "y = (\n",
    "    np.cos(np.linspace(0, 20, 10_100))\n",
    "    + np.sin(np.linspace(0, 3, 10_100))\n",
    "    - 0.2 * np.random.random(10_100)\n",
    ")\n",
    "np.random.seed(20)\n",
    "x = 2 * y ** 3 - 5 * y ** 2 + 0.3 * y + 2 - 0.05 * np.random.random(10_100)\n",
    "data = np.vstack([x[:-100], y[100:]]).T\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(data[:, 0], label=\"X\")\n",
    "plt.plot(data[:, 1], label=\"Y\")\n",
    "plt.xlabel(\"Number of sample\")\n",
    "plt.ylabel(\"Signals [AU]\")\n",
    "plt.legend()\n",
    "\n",
    "#%% Test in case of presence of the causality\n",
    "lags = [50, 150]\n",
    "data_train = data[:6000, :]\n",
    "data_val = data[6000:8000, :]\n",
    "data_test = data[8000:, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8f4823-6810-4a83-941e-b759cddef251",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = nlc.nonlincausalityNN(\n",
    "    x=data_train,\n",
    "    maxlag=lags,\n",
    "    NN_config=['d','dr','d','dr'],\n",
    "    NN_neurons=[100,0.05,100,0.05],\n",
    "    x_test=data_test,\n",
    "    run=3,\n",
    "    epochs_num=[50, 50],\n",
    "    learning_rate=[0.0001, 0.00001],\n",
    "    batch_size_num=32,\n",
    "    x_val=data_val,\n",
    "    reg_alpha=None,\n",
    "    callbacks=None,\n",
    "    verbose=True,\n",
    "    plot=True,\n",
    ")\n",
    "\n",
    "#%% Example of obtaining the results\n",
    "for lag in lags:\n",
    "    best_model_X = results[lag].best_model_X\n",
    "    best_model_XY = results[lag].best_model_XY\n",
    "\n",
    "    p_value = results[lag].p_value\n",
    "    test_statistic = results[lag]._test_statistic\n",
    "\n",
    "    best_history_X = results[lag].best_history_X\n",
    "    best_history_XY = results[lag].best_history_XY\n",
    "\n",
    "    nlc.plot_history_loss(best_history_X, best_history_XY)\n",
    "    plt.title(\"Lag = %d\" % lag)\n",
    "    best_errors_X = results[lag].best_errors_X\n",
    "    best_errors_XY = results[lag].best_errors_XY\n",
    "\n",
    "    cohens_d = np.abs(\n",
    "        (np.mean(np.abs(best_errors_X)) - np.mean(np.abs(best_errors_XY)))\n",
    "        / np.std([best_errors_X, best_errors_XY])\n",
    "    )\n",
    "    print(\"For lag = %d Cohen's d = %0.3f\" % (lag, cohens_d))\n",
    "    print(f\"Test statistic = {test_statistic} p-value = {p_value}\")\n",
    "\n",
    "    # Using models for prediction\n",
    "    data_X, data_XY = prepare_data_for_prediction(data_test, lag)\n",
    "    X_pred_X = best_model_X.predict(data_X)\n",
    "    X_pred_XY = best_model_XY.predict(data_XY)\n",
    "\n",
    "    # Plot of true X vs X predicted\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].plot(data_test[lag:, 0], X_pred_X, \"o\")\n",
    "    ax[0].set_xlabel(\"X test values\")\n",
    "    ax[0].set_ylabel(\"Predicted X values\")\n",
    "    ax[0].set_title(\"Model based on X\")\n",
    "    ax[1].plot(data_test[lag:, 0], X_pred_XY, \"o\")\n",
    "    ax[1].set_xlabel(\"X test values\")\n",
    "    ax[1].set_ylabel(\"Predicted X values\")\n",
    "    ax[1].set_title(\"Model based on X and Y\")\n",
    "    plt.suptitle(\"Lag = %d\" % lag)\n",
    "\n",
    "    # Another way of obtaining predicted values (and errors)\n",
    "    X_pred_X, X_pred_XY, error_X, error_XY = calculate_pred_and_errors(\n",
    "        data_test[lag:, 0], \n",
    "        data_X, \n",
    "        data_XY, \n",
    "        best_model_X, \n",
    "        best_model_XY\n",
    "    )\n",
    "    # Plot of X predicted vs prediction error\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].plot(X_pred_X, error_X, \"o\")\n",
    "    ax[0].set_xlabel(\"Predicted X values\")\n",
    "    ax[0].set_ylabel(\"Prediction errors\")\n",
    "    ax[0].set_title(\"Model based on X\")\n",
    "    ax[1].plot(X_pred_XY, error_XY, \"o\")\n",
    "    ax[1].set_xlabel(\"Predicted X values\")\n",
    "    ax[1].set_ylabel(\"Prediction errors\")\n",
    "    ax[1].set_title(\"Model based on X and Y\")\n",
    "    plt.suptitle(\"Lag = %d\" % lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706cea49-2e4e-4b80-9dc4-be81936b1cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Test in case of absence of the causality\n",
    "np.random.seed(30)\n",
    "data_noise = np.vstack([x[:-100], np.random.random(10_000)]).T\n",
    "\n",
    "lags = [50, 150]\n",
    "data_noise_train = data_noise[:6000, :]\n",
    "data_noise_val = data_noise[6000:8000, :]\n",
    "data_noise_test = data_noise[8000:, :]\n",
    "\n",
    "results = nlc.nonlincausalityNN(\n",
    "    x=data_noise_train,\n",
    "    maxlag=lags,\n",
    "    NN_config=['d','dr','d','dr'],\n",
    "    NN_neurons=[100,0.05,100,0.05],\n",
    "    x_test=data_noise_test,\n",
    "    run=3,\n",
    "    epochs_num=[50, 50],\n",
    "    learning_rate=[0.001, 0.0001],\n",
    "    batch_size_num=32,\n",
    "    x_val=data_noise_val,\n",
    "    reg_alpha=None,\n",
    "    callbacks=None,\n",
    "    verbose=True,\n",
    "    plot=True,\n",
    ")\n",
    "\n",
    "#%% Example of obtaining the results\n",
    "for lag in lags:\n",
    "    best_model_X_lag50 = results[lag].best_model_X\n",
    "    best_model_XY_lag50 = results[lag].best_model_XY\n",
    "\n",
    "    p_value = results[lag].p_value\n",
    "    test_statistic = results[lag].test_statistic\n",
    "\n",
    "    best_history_X = results[lag].best_history_X\n",
    "    best_history_XY = results[lag].best_history_XY\n",
    "\n",
    "    nlc.plot_history_loss(best_history_X, best_history_XY)\n",
    "    plt.title(\"Lag = %d\" % lag)\n",
    "\n",
    "    best_errors_X = results[lag].best_errors_X\n",
    "    best_errors_XY = results[lag].best_errors_XY\n",
    "\n",
    "    cohens_d = np.abs(\n",
    "        (np.mean(np.abs(best_errors_X)) - np.mean(np.abs(best_errors_XY)))\n",
    "        / np.std([best_errors_X, best_errors_XY])\n",
    "    )\n",
    "    print(\"For lag = %d Cohen's d = %0.3f\" % (lag, cohens_d))\n",
    "    print(f\"test statistic = {test_statistic} p-value = {p_value}\")\n",
    "#%% Example of the measure of the causality change over time\n",
    "\n",
    "data_test_measure = copy.copy(data_test)\n",
    "np.random.seed(30)\n",
    "data_test_measure[:1000, 1] = np.random.random(1000)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(data_test_measure[:, 0], label=\"X\")\n",
    "plt.plot(data_test_measure[:, 1], label=\"Y\")\n",
    "plt.xlabel(\"Number of sample\")\n",
    "plt.ylabel(\"Signals [AU]\")\n",
    "plt.legend()\n",
    "\n",
    "results = nlc.nonlincausalitymeasureNN(\n",
    "    x=data_train,\n",
    "    maxlag=lags,\n",
    "    window=100,\n",
    "    step=1,\n",
    "    NN_config=['d','dr','d','dr'],\n",
    "    NN_neurons=[100,0.05,100,0.05],\n",
    "    x_test=data_test_measure,\n",
    "    run=3,\n",
    "    epochs_num=[50,50],\n",
    "    learning_rate=[0.0001, 0.00001],\n",
    "    batch_size_num=32,\n",
    "    x_val=data_val,\n",
    "    verbose=True,\n",
    "    plot=True,\n",
    ")\n",
    "\n",
    "\n",
    "#%% Example of usage for conditional analysis\n",
    "np.random.seed(30)\n",
    "z = np.random.random([10_000, 2])\n",
    "\n",
    "z_train = z[:6000, :]\n",
    "z_val = z[6000:8000, :]\n",
    "z_test = z[8000:, :]\n",
    "\n",
    "results_conditional = nlc.nonlincausalityNN(\n",
    "    x=data_train,\n",
    "    maxlag=lags,\n",
    "    NN_config=['d','dr','d','dr'],\n",
    "    NN_neurons=[100,0.05,100,0.05],\n",
    "    x_test=data_test,\n",
    "    run=1,\n",
    "    z=z_train,\n",
    "    z_test=z_test,\n",
    "    epochs_num=[50, 50],\n",
    "    learning_rate=[0.0001, 0.00001],\n",
    "    batch_size_num=32,\n",
    "    x_val=data_val,\n",
    "    z_val=z_val,\n",
    "    reg_alpha=None,\n",
    "    callbacks=None,\n",
    "    verbose=True,\n",
    "    plot=True,\n",
    ")\n",
    "# %% Exaple of the usage the package with Scikit-learn model\n",
    "\n",
    "parametres = {\n",
    "    'kernel':['poly', 'rbf'],\n",
    "    'C':[0.01,0.1,1], \n",
    "    'epsilon':[0.01,0.1,1.]\n",
    "}\n",
    "results_skl = nlc.nonlincausality_sklearn(    \n",
    "    x=data_train,\n",
    "    sklearn_model=SVR,\n",
    "    maxlag=lags,\n",
    "    params=parametres,\n",
    "    x_test=data_test,\n",
    "    x_val=data_val,\n",
    "    plot=True)\n",
    "\n",
    "#%% Example of usage other functions for causality analysis\n",
    "\n",
    "# ARIMA/ARIMAX models\n",
    "results_ARIMA = nlc.nonlincausalityARIMA(x=data_train[::10], maxlag=[5,15], x_test=data_test[::10])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (basisformer_x86_env)",
   "language": "python",
   "name": "basisformer_x86_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
