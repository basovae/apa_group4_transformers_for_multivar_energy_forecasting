INFO:root:Args in experiment:
INFO:root:Namespace(is_training=True, device=0, num_workers=0, data='custom', root_path='data', data_path='all_countries.csv', features='M', target='Price (EUR/MWhe)', freq='h', seq_len=96, label_len=96, pred_len=720, embed='timeF', heads=8, d_model=64, N=5, block_nums=2, bottleneck=2, map_bottleneck=20, train_epochs=1, batch_size=32, patience=3, learning_rate=0.0005, tau=0.07, loss_weight_prediction=1.0, loss_weight_infonce=1.0, loss_weight_smooth=1.0, check_point='checkpoint')
INFO:root:Basisformer(
  (coefnet): Coefnet(
    (layers): ModuleList(
      (0-1): 2 x BCAB(
        (cross_attention_basis): channel_AutoCorrelationLayer(
          (query_projection): Linear(in_features=64, out_features=64, bias=True)
          (key_projection): Linear(in_features=64, out_features=64, bias=True)
          (value_projection): Linear(in_features=64, out_features=64, bias=True)
          (out_projection): Linear(in_features=64, out_features=64, bias=True)
          (attend): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (conv1_basis): Linear(in_features=64, out_features=256, bias=True)
        (conv2_basis): Linear(in_features=256, out_features=64, bias=True)
        (dropout_basis): Dropout(p=0.1, inplace=False)
        (cross_attention_ts): channel_AutoCorrelationLayer(
          (query_projection): Linear(in_features=64, out_features=64, bias=True)
          (key_projection): Linear(in_features=64, out_features=64, bias=True)
          (value_projection): Linear(in_features=64, out_features=64, bias=True)
          (out_projection): Linear(in_features=64, out_features=64, bias=True)
          (attend): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (conv1_ts): Linear(in_features=64, out_features=256, bias=True)
        (conv2_ts): Linear(in_features=256, out_features=64, bias=True)
        (dropout_ts): Dropout(p=0.1, inplace=False)
        (layer_norm11): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (layer_norm12): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (layer_norm21): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (layer_norm22): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
    )
    (last_layer): last_layer(
      (query_projection): Linear(in_features=64, out_features=64, bias=True)
      (key_projection): Linear(in_features=64, out_features=64, bias=True)
    )
  )
  (MLP_x): MLP_bottle(
    (linear1): Sequential(
      (0): Linear(in_features=96, out_features=48, bias=True)
      (1): ReLU()
      (2): Linear(in_features=48, out_features=48, bias=True)
    )
    (linear2): Sequential(
      (0): Linear(in_features=48, out_features=48, bias=True)
      (1): ReLU()
      (2): Linear(in_features=48, out_features=96, bias=True)
    )
    (skip): Linear(in_features=96, out_features=48, bias=True)
    (act): ReLU()
  )
  (MLP_y): MLP_bottle(
    (linear1): Sequential(
      (0): Linear(in_features=720, out_features=360, bias=True)
      (1): ReLU()
      (2): Linear(in_features=360, out_features=360, bias=True)
    )
    (linear2): Sequential(
      (0): Linear(in_features=360, out_features=360, bias=True)
      (1): ReLU()
      (2): Linear(in_features=360, out_features=720, bias=True)
    )
    (skip): Linear(in_features=720, out_features=360, bias=True)
    (act): ReLU()
  )
  (MLP_sx): MLP_bottle(
    (linear1): Sequential(
      (0): Linear(in_features=96, out_features=48, bias=True)
      (1): ReLU()
      (2): Linear(in_features=48, out_features=48, bias=True)
    )
    (linear2): Sequential(
      (0): Linear(in_features=48, out_features=48, bias=True)
      (1): ReLU()
      (2): Linear(in_features=48, out_features=96, bias=True)
    )
    (skip): Linear(in_features=96, out_features=48, bias=True)
    (act): ReLU()
  )
  (MLP_sy): MLP_bottle(
    (linear1): Sequential(
      (0): Linear(in_features=720, out_features=360, bias=True)
      (1): ReLU()
      (2): Linear(in_features=360, out_features=360, bias=True)
    )
    (linear2): Sequential(
      (0): Linear(in_features=360, out_features=360, bias=True)
      (1): ReLU()
      (2): Linear(in_features=360, out_features=720, bias=True)
    )
    (skip): Linear(in_features=720, out_features=360, bias=True)
    (act): ReLU()
  )
  (project1): Linear(in_features=96, out_features=64, bias=True)
  (project2): Linear(in_features=96, out_features=64, bias=True)
  (project3): Linear(in_features=720, out_features=64, bias=True)
  (project4): Linear(in_features=720, out_features=64, bias=True)
  (criterion1): MSELoss()
  (criterion2): L1Loss()
  (map_MLP): MLP_bottle(
    (linear1): Sequential(
      (0): Linear(in_features=1, out_features=20, bias=True)
      (1): ReLU()
      (2): Linear(in_features=20, out_features=20, bias=True)
    )
    (linear2): Sequential(
      (0): Linear(in_features=20, out_features=20, bias=True)
      (1): ReLU()
      (2): Linear(in_features=20, out_features=4080, bias=True)
    )
    (skip): Linear(in_features=1, out_features=20, bias=True)
    (act): ReLU()
  )
)
INFO:root:[Info] Number of parameters: 2526664
INFO:root:	iters: 9752, epoch: 1 | loss: 0.0315978
INFO:root:	iters: 19504, epoch: 1 | loss: 0.0072647
INFO:root:	iters: 29256, epoch: 1 | loss: 0.0040712
INFO:root:	iters: 39008, epoch: 1 | loss: 0.0057152
INFO:root:	iters: 48760, epoch: 1 | loss: 0.0132238
INFO:root:Epoch: 1 cost time: 4388.012967824936
INFO:root:loss_pred:0.020502921171709872
INFO:root:loss entropy:0.002726393998175982
INFO:root:loss smooth:0.002195145425148305
INFO:root:Epoch: 1 | Train Loss: 0.0254245 Vali Loss: 0.0088556 Test Loss: 0.0098619
