{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c73133af-7360-4762-9048-3aa0b3bb71b4",
   "metadata": {},
   "source": [
    "### Agenda:\n",
    "1. Data Loading & Preprocessing\n",
    "   - Missing values handling\n",
    "   - Date features creation\n",
    "   - Train/Test split\n",
    "   - Scaling\n",
    "   - Sequences\n",
    "   - Data Loader (incl. indexing for Basisformer)\n",
    "2. Experimental Design\n",
    "    - Benchmark Models\n",
    "      - Linear Regression\n",
    "      - LSTM\n",
    "    - Pre trained Chronos\n",
    "    - Transformers\n",
    "      - Non-Stationary Autoformer\n",
    "      - BasisFormer\n",
    "      - iTransformer\n",
    "3. Results\n",
    "4. Outlook\n",
    "   - Chronos Simulation Framework\n",
    "   - DYNOTEARS Causal Structure\n",
    "   - Non linear causal structure\n",
    "   - Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "veljByFX557b",
   "metadata": {
    "id": "veljByFX557b"
   },
   "outputs": [],
   "source": [
    "#!pip install torch==2.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370ef93a-0cd3-471b-a6d1-1b3ed3da369c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1. Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1c78b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cad7a09c-a0e5-4eff-b76b-752fcb66665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f4de819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.weight_norm as wn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98a448b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import argparse\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c0948b2-e0b7-4862-9a96-8f186c1d4244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "iGtogtkxzGiT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "iGtogtkxzGiT",
    "outputId": "d63b1548-a355-4ac8-89ed-fc0029c44b31"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>ISO3 Code</th>\n",
       "      <th>Datetime (UTC)</th>\n",
       "      <th>Datetime (Local)</th>\n",
       "      <th>Price (EUR/MWhe)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>2015-01-01 01:00:00</td>\n",
       "      <td>17.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>2015-01-01 01:00:00</td>\n",
       "      <td>2015-01-01 02:00:00</td>\n",
       "      <td>15.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>2015-01-01 02:00:00</td>\n",
       "      <td>2015-01-01 03:00:00</td>\n",
       "      <td>16.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>2015-01-01 03:00:00</td>\n",
       "      <td>2015-01-01 04:00:00</td>\n",
       "      <td>17.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>2015-01-01 04:00:00</td>\n",
       "      <td>2015-01-01 05:00:00</td>\n",
       "      <td>16.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country ISO3 Code       Datetime (UTC)     Datetime (Local)  \\\n",
       "0  Austria       AUT  2015-01-01 00:00:00  2015-01-01 01:00:00   \n",
       "1  Austria       AUT  2015-01-01 01:00:00  2015-01-01 02:00:00   \n",
       "2  Austria       AUT  2015-01-01 02:00:00  2015-01-01 03:00:00   \n",
       "3  Austria       AUT  2015-01-01 03:00:00  2015-01-01 04:00:00   \n",
       "4  Austria       AUT  2015-01-01 04:00:00  2015-01-01 05:00:00   \n",
       "\n",
       "   Price (EUR/MWhe)  \n",
       "0             17.93  \n",
       "1             15.17  \n",
       "2             16.38  \n",
       "3             17.38  \n",
       "4             16.38  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##file_path = '/content/all_countries.csv' ## colab path\n",
    "file_path = 'data/all_countries.csv' ## jupyter path\n",
    "df = pd.read_csv(file_path)\n",
    "df = pd.DataFrame(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "vQW9jbwq4lFG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "vQW9jbwq4lFG",
    "outputId": "e9aa57ef-18a2-4243-cd79-51b284512116"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Country</th>\n",
       "      <th>Austria</th>\n",
       "      <th>Belgium</th>\n",
       "      <th>Bulgaria</th>\n",
       "      <th>Croatia</th>\n",
       "      <th>Czechia</th>\n",
       "      <th>Denmark</th>\n",
       "      <th>Estonia</th>\n",
       "      <th>Finland</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>...</th>\n",
       "      <th>Norway</th>\n",
       "      <th>Poland</th>\n",
       "      <th>Portugal</th>\n",
       "      <th>Romania</th>\n",
       "      <th>Serbia</th>\n",
       "      <th>Slovakia</th>\n",
       "      <th>Slovenia</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Sweden</th>\n",
       "      <th>Switzerland</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime (UTC)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00</th>\n",
       "      <td>17.93</td>\n",
       "      <td>34.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.20</td>\n",
       "      <td>18.29</td>\n",
       "      <td>23.37</td>\n",
       "      <td>23.37</td>\n",
       "      <td>34.94</td>\n",
       "      <td>17.93</td>\n",
       "      <td>...</td>\n",
       "      <td>27.36</td>\n",
       "      <td>17.18</td>\n",
       "      <td>48.10</td>\n",
       "      <td>44.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.20</td>\n",
       "      <td>23.25</td>\n",
       "      <td>48.10</td>\n",
       "      <td>23.37</td>\n",
       "      <td>43.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 01:00:00</th>\n",
       "      <td>15.17</td>\n",
       "      <td>32.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.06</td>\n",
       "      <td>16.04</td>\n",
       "      <td>19.33</td>\n",
       "      <td>19.33</td>\n",
       "      <td>32.19</td>\n",
       "      <td>15.17</td>\n",
       "      <td>...</td>\n",
       "      <td>27.24</td>\n",
       "      <td>17.38</td>\n",
       "      <td>47.33</td>\n",
       "      <td>39.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.06</td>\n",
       "      <td>22.20</td>\n",
       "      <td>47.33</td>\n",
       "      <td>19.33</td>\n",
       "      <td>38.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 02:00:00</th>\n",
       "      <td>16.38</td>\n",
       "      <td>28.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.27</td>\n",
       "      <td>14.60</td>\n",
       "      <td>17.66</td>\n",
       "      <td>17.66</td>\n",
       "      <td>23.53</td>\n",
       "      <td>16.38</td>\n",
       "      <td>...</td>\n",
       "      <td>27.16</td>\n",
       "      <td>17.40</td>\n",
       "      <td>42.27</td>\n",
       "      <td>26.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.27</td>\n",
       "      <td>19.56</td>\n",
       "      <td>42.27</td>\n",
       "      <td>17.66</td>\n",
       "      <td>35.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 03:00:00</th>\n",
       "      <td>17.38</td>\n",
       "      <td>28.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.17</td>\n",
       "      <td>14.95</td>\n",
       "      <td>17.53</td>\n",
       "      <td>17.53</td>\n",
       "      <td>22.92</td>\n",
       "      <td>17.38</td>\n",
       "      <td>...</td>\n",
       "      <td>27.15</td>\n",
       "      <td>18.60</td>\n",
       "      <td>38.41</td>\n",
       "      <td>20.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.17</td>\n",
       "      <td>18.88</td>\n",
       "      <td>38.41</td>\n",
       "      <td>17.53</td>\n",
       "      <td>30.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 04:00:00</th>\n",
       "      <td>16.38</td>\n",
       "      <td>34.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.90</td>\n",
       "      <td>14.50</td>\n",
       "      <td>18.07</td>\n",
       "      <td>18.07</td>\n",
       "      <td>34.26</td>\n",
       "      <td>16.38</td>\n",
       "      <td>...</td>\n",
       "      <td>27.30</td>\n",
       "      <td>19.30</td>\n",
       "      <td>35.72</td>\n",
       "      <td>18.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.90</td>\n",
       "      <td>18.39</td>\n",
       "      <td>35.72</td>\n",
       "      <td>18.07</td>\n",
       "      <td>28.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Country              Austria  Belgium  Bulgaria  Croatia  Czechia  Denmark  \\\n",
       "Datetime (UTC)                                                               \n",
       "2015-01-01 00:00:00    17.93    34.94       NaN      NaN    24.20    18.29   \n",
       "2015-01-01 01:00:00    15.17    32.19       NaN      NaN    22.06    16.04   \n",
       "2015-01-01 02:00:00    16.38    28.05       NaN      NaN    20.27    14.60   \n",
       "2015-01-01 03:00:00    17.38    28.04       NaN      NaN    19.17    14.95   \n",
       "2015-01-01 04:00:00    16.38    34.26       NaN      NaN    17.90    14.50   \n",
       "\n",
       "Country              Estonia  Finland  France  Germany  ...  Norway  Poland  \\\n",
       "Datetime (UTC)                                          ...                   \n",
       "2015-01-01 00:00:00    23.37    23.37   34.94    17.93  ...   27.36   17.18   \n",
       "2015-01-01 01:00:00    19.33    19.33   32.19    15.17  ...   27.24   17.38   \n",
       "2015-01-01 02:00:00    17.66    17.66   23.53    16.38  ...   27.16   17.40   \n",
       "2015-01-01 03:00:00    17.53    17.53   22.92    17.38  ...   27.15   18.60   \n",
       "2015-01-01 04:00:00    18.07    18.07   34.26    16.38  ...   27.30   19.30   \n",
       "\n",
       "Country              Portugal  Romania  Serbia  Slovakia  Slovenia  Spain  \\\n",
       "Datetime (UTC)                                                              \n",
       "2015-01-01 00:00:00     48.10    44.17     NaN     24.20     23.25  48.10   \n",
       "2015-01-01 01:00:00     47.33    39.17     NaN     22.06     22.20  47.33   \n",
       "2015-01-01 02:00:00     42.27    26.93     NaN     20.27     19.56  42.27   \n",
       "2015-01-01 03:00:00     38.41    20.94     NaN     19.17     18.88  38.41   \n",
       "2015-01-01 04:00:00     35.72    18.52     NaN     17.90     18.39  35.72   \n",
       "\n",
       "Country              Sweden  Switzerland  \n",
       "Datetime (UTC)                            \n",
       "2015-01-01 00:00:00   23.37        43.43  \n",
       "2015-01-01 01:00:00   19.33        38.08  \n",
       "2015-01-01 02:00:00   17.66        35.47  \n",
       "2015-01-01 03:00:00   17.53        30.83  \n",
       "2015-01-01 04:00:00   18.07        28.26  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df [['Country','Datetime (UTC)',  'Price (EUR/MWhe)']]\n",
    "df = df.pivot(index='Datetime (UTC)', columns='Country', values='Price (EUR/MWhe)')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "mfQvgSnM3_1v",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mfQvgSnM3_1v",
    "outputId": "9cd1c2f9-c7f7-46d1-df8b-df5c13df26d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country\n",
      "Austria                0\n",
      "Belgium                0\n",
      "Bulgaria           15336\n",
      "Croatia            24096\n",
      "Czechia                0\n",
      "Denmark                0\n",
      "Estonia                0\n",
      "Finland                0\n",
      "France                 0\n",
      "Germany                0\n",
      "Greece                 0\n",
      "Hungary                0\n",
      "Ireland            12480\n",
      "Italy                  0\n",
      "Latvia                 0\n",
      "Lithuania              0\n",
      "Luxembourg             0\n",
      "Netherlands            0\n",
      "North Macedonia    73008\n",
      "Norway                 0\n",
      "Poland                 0\n",
      "Portugal               0\n",
      "Romania                0\n",
      "Serbia             16800\n",
      "Slovakia               0\n",
      "Slovenia               0\n",
      "Spain                  0\n",
      "Sweden                 0\n",
      "Switzerland            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "WObloVqL4aH3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WObloVqL4aH3",
    "outputId": "c1a5702e-1761-4cca-d65c-14966b09d8dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country\n",
      "Austria        0\n",
      "Belgium        0\n",
      "Czechia        0\n",
      "Denmark        0\n",
      "Estonia        0\n",
      "Finland        0\n",
      "France         0\n",
      "Germany        0\n",
      "Greece         0\n",
      "Hungary        0\n",
      "Italy          0\n",
      "Latvia         0\n",
      "Lithuania      0\n",
      "Luxembourg     0\n",
      "Netherlands    0\n",
      "Norway         0\n",
      "Poland         0\n",
      "Portugal       0\n",
      "Romania        0\n",
      "Slovakia       0\n",
      "Slovenia       0\n",
      "Spain          0\n",
      "Sweden         0\n",
      "Switzerland    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(axis=1)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "AB6vyJX-C6h3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AB6vyJX-C6h3",
    "outputId": "aa9990f8-cb44-4367-b4ff-e2a1bf1732d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datetime (UTC)  Austria  Belgium  Czechia  Denmark  Estonia  Finland  \\\n",
      "0  2015-01-01 00:00:00    17.93    34.94    24.20    18.29    23.37    23.37   \n",
      "1  2015-01-01 01:00:00    15.17    32.19    22.06    16.04    19.33    19.33   \n",
      "2  2015-01-01 02:00:00    16.38    28.05    20.27    14.60    17.66    17.66   \n",
      "3  2015-01-01 03:00:00    17.38    28.04    19.17    14.95    17.53    17.53   \n",
      "4  2015-01-01 04:00:00    16.38    34.26    17.90    14.50    18.07    18.07   \n",
      "\n",
      "   France  Germany  Greece  ...  Netherlands  Norway  Poland  Portugal  \\\n",
      "0   34.94    17.93   48.78  ...        34.94   27.36   17.18     48.10   \n",
      "1   32.19    15.17   31.10  ...        32.19   27.24   17.38     47.33   \n",
      "2   23.53    16.38   20.78  ...        28.05   27.16   17.40     42.27   \n",
      "3   22.92    17.38   25.40  ...        28.04   27.15   18.60     38.41   \n",
      "4   34.26    16.38   26.00  ...        34.26   27.30   19.30     35.72   \n",
      "\n",
      "   Romania  Slovakia  Slovenia  Spain  Sweden  Switzerland  \n",
      "0    44.17     24.20     23.25  48.10   23.37        43.43  \n",
      "1    39.17     22.06     22.20  47.33   19.33        38.08  \n",
      "2    26.93     20.27     19.56  42.27   17.66        35.47  \n",
      "3    20.94     19.17     18.88  38.41   17.53        30.83  \n",
      "4    18.52     17.90     18.39  35.72   18.07        28.26  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.columns.name = None\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99211c4c-9b8f-4d60-9bb6-add80102ca5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last time point available: 2024-04-30 23:00:00\n"
     ]
    }
   ],
   "source": [
    "df['Datetime (UTC)'] = pd.to_datetime(df['Datetime (UTC)'])\n",
    "last_time_point = df['Datetime (UTC)'].max()\n",
    "print(\"Last time point available:\", last_time_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9365312-6296-4b97-ace6-9dd9191fccea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Datetime (UTC)  Austria  Belgium  Czechia  Denmark  Estonia  \\\n",
      "79633 2024-02-01 01:00:00    66.59    44.47    80.01    30.49    26.71   \n",
      "79634 2024-02-01 02:00:00    64.13    45.15    80.01    31.12    38.22   \n",
      "79635 2024-02-01 03:00:00    69.80    49.02    80.01    31.95    27.71   \n",
      "79636 2024-02-01 04:00:00    80.78    57.56    87.10    35.01    20.10   \n",
      "79637 2024-02-01 05:00:00    86.95    70.56    95.00    39.04    72.59   \n",
      "...                   ...      ...      ...      ...      ...      ...   \n",
      "81787 2024-04-30 19:00:00    87.82    87.02    88.29    66.05    88.36   \n",
      "81788 2024-04-30 20:00:00    77.50    75.39    77.99    54.09    78.02   \n",
      "81789 2024-04-30 21:00:00    76.10    77.51    75.93    50.98    54.93   \n",
      "81790 2024-04-30 22:00:00    64.22    58.00    67.16    44.71    38.00   \n",
      "81791 2024-04-30 23:00:00    54.89    54.28    56.35    44.18    36.61   \n",
      "\n",
      "       Finland  France  Germany  Greece  ...  Netherlands  Norway  Poland  \\\n",
      "79633    -2.49   46.66    42.16   80.00  ...        43.04   34.35   42.38   \n",
      "79634    -2.50   47.04    43.05   73.06  ...        43.94   34.62   40.93   \n",
      "79635    -2.07   51.06    46.91   83.80  ...        47.63   37.25   40.89   \n",
      "79636    -1.84   59.82    55.34   99.57  ...        56.06   39.16   51.65   \n",
      "79637    -0.10   72.42    69.01  107.36  ...        69.20   40.32   72.59   \n",
      "...        ...     ...      ...     ...  ...          ...     ...     ...   \n",
      "81787    88.36   83.91    88.37   80.01  ...        88.15   53.42   88.36   \n",
      "81788    78.02   70.98    77.97   77.53  ...        80.00   52.52   83.29   \n",
      "81789    54.93   75.79    75.69   75.97  ...        81.80   50.05   80.97   \n",
      "81790    38.00   35.01    66.81   36.99  ...        76.77   43.80   67.43   \n",
      "81791    36.61   34.99    55.09   34.86  ...        79.89   43.30   74.02   \n",
      "\n",
      "       Portugal  Romania  Slovakia  Slovenia  Spain  Sweden  Switzerland  \n",
      "79633     55.10    80.00     91.00     71.73  55.10   -2.49        70.80  \n",
      "79634     54.60    73.06     80.19     67.66  54.60   -2.50        73.85  \n",
      "79635     53.47    83.80     96.02     75.10  53.47   -2.07        74.06  \n",
      "79636     59.82    99.57    116.13     87.74  59.82   -1.84        74.09  \n",
      "79637     72.42   107.36    108.87     95.63  72.42   -0.10        86.00  \n",
      "...         ...      ...       ...       ...    ...     ...          ...  \n",
      "81787     83.91    88.08     88.15     88.09  83.91   55.47        88.81  \n",
      "81788     70.98    77.53     77.74     77.19  70.98   52.77        78.03  \n",
      "81789     65.00    75.97     75.94     76.02  65.00   50.05        71.07  \n",
      "81790     35.01    64.74     65.81     62.97  35.01   38.00        57.37  \n",
      "81791     34.99    54.86     55.49     53.86  34.99   36.61        53.04  \n",
      "\n",
      "[2159 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "start_date = '2024-02-01 01:00:00' ## FILTERING ONLY FOR 3 MONTHS\n",
    "df = df[df['Datetime (UTC)'] >= pd.to_datetime(start_date)]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "_Jtyfje24Pdq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Jtyfje24Pdq",
    "outputId": "507d28c6-0347-4446-9078-c6fda9ffa9a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Datetime (UTC)  Austria  Belgium  Czechia  Denmark  Estonia  \\\n",
      "79633 2024-02-01 01:00:00    66.59    44.47    80.01    30.49    26.71   \n",
      "79634 2024-02-01 02:00:00    64.13    45.15    80.01    31.12    38.22   \n",
      "79635 2024-02-01 03:00:00    69.80    49.02    80.01    31.95    27.71   \n",
      "79636 2024-02-01 04:00:00    80.78    57.56    87.10    35.01    20.10   \n",
      "79637 2024-02-01 05:00:00    86.95    70.56    95.00    39.04    72.59   \n",
      "\n",
      "       Finland  France  Germany  Greece  ...  Romania  Slovakia  Slovenia  \\\n",
      "79633    -2.49   46.66    42.16   80.00  ...    80.00     91.00     71.73   \n",
      "79634    -2.50   47.04    43.05   73.06  ...    73.06     80.19     67.66   \n",
      "79635    -2.07   51.06    46.91   83.80  ...    83.80     96.02     75.10   \n",
      "79636    -1.84   59.82    55.34   99.57  ...    99.57    116.13     87.74   \n",
      "79637    -0.10   72.42    69.01  107.36  ...   107.36    108.87     95.63   \n",
      "\n",
      "       Spain  Sweden  Switzerland  month  day  weekday  hour  \n",
      "79633  55.10   -2.49        70.80      2    1        3     1  \n",
      "79634  54.60   -2.50        73.85      2    1        3     2  \n",
      "79635  53.47   -2.07        74.06      2    1        3     3  \n",
      "79636  59.82   -1.84        74.09      2    1        3     4  \n",
      "79637  72.42   -0.10        86.00      2    1        3     5  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "df['month'] = df['Datetime (UTC)'].apply(lambda row: row.month)\n",
    "df['day'] = df['Datetime (UTC)'].apply(lambda row: row.day)\n",
    "df['weekday'] = df['Datetime (UTC)'].apply(lambda row: row.weekday())\n",
    "df['hour'] = df['Datetime (UTC)'].apply(lambda row: row.hour)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80mxqDAh5Mwd",
   "metadata": {
    "id": "80mxqDAh5Mwd"
   },
   "outputs": [],
   "source": [
    "# separating the electricity prices and timestamp features\n",
    "electricity_prices_df = df[['Datetime (UTC)', 'Austria', 'Belgium', 'Czechia', 'Denmark', 'Estonia', 'Finland', 'France',\n",
    "              'Germany', 'Greece', 'Hungary', 'Italy', 'Latvia', 'Lithuania', 'Luxembourg',\n",
    "             'Netherlands', 'Norway', 'Poland', 'Portugal', 'Romania', 'Slovakia',\n",
    "             'Slovenia', 'Spain', 'Sweden', 'Switzerland']]\n",
    "timestamp_features_df = df[['Datetime (UTC)', 'month', 'day', 'weekday', 'hour']]\n",
    "\n",
    "# defining the split ratio\n",
    "train_size = 0.8\n",
    "train_size_electricity = int(len(electricity_prices_df) * train_size)\n",
    "train_size_timestamp = int(len(timestamp_features_df) * train_size)\n",
    "\n",
    "# spliting the data into train and test sets\n",
    "electricity_prices_train = electricity_prices_df[:train_size_electricity]\n",
    "electricity_prices_test = electricity_prices_df[train_size_electricity:]\n",
    "timestamp_features_train = timestamp_features_df[:train_size_timestamp]\n",
    "timestamp_features_test = timestamp_features_df[train_size_timestamp:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95180c89-5259-40f8-af8b-e90241aa8864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(electricity_prices_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a2c3f05-460c-4d80-868e-48ff8f5cfd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#country_names = electricity_prices_train.drop(columns=['Datetime (UTC)']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4oRyT6un5WWm",
   "metadata": {
    "id": "4oRyT6un5WWm"
   },
   "outputs": [],
   "source": [
    "# rescaling the electricity prices\n",
    "scaler = StandardScaler()\n",
    "\n",
    "electricity_prices_train_scaled = scaler.fit_transform(electricity_prices_train.drop(columns=['Datetime (UTC)']))\n",
    "electricity_prices_test_scaled = scaler.transform(electricity_prices_test.drop(columns=['Datetime (UTC)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07d72a8e-4df2-4255-bdb3-3353426389cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#electricity_prices_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "407a011b-3187-4e94-9c3a-e36c17253639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length, pred_length, label_length, curr_model):\n",
    "    seq_x = [] # storing for input seqiences\n",
    "    seq_y = [] # storing for output seqiences\n",
    "    for i in range(len(data) - seq_length - pred_length):\n",
    "        seq_x.append(data[i:i+seq_length])\n",
    "        if curr_model in [\"basis_former\", \"itransformer\", \"ns_autoformer\"]:\n",
    "          seq_y.append(data[i+seq_length-label_length:i+seq_length+pred_length])\n",
    "        else: ## only chronos\n",
    "          seq_y.append(data[i+seq_length:i+seq_length+pred_length])\n",
    "    return np.array(seq_x), np.array(seq_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c17fd64-77c4-42ab-9e63-bf919d801d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(seq_x, seq_y, seq_x_mark, seq_y_mark, batch_size, curr_model):\n",
    "    seq_x = torch.tensor(seq_x, dtype=torch.float32)\n",
    "    seq_y = torch.tensor(seq_y, dtype=torch.float32)\n",
    "    seq_x_mark = torch.tensor(seq_x_mark, dtype=torch.float32)\n",
    "    seq_y_mark = torch.tensor(seq_y_mark, dtype=torch.float32)\n",
    "    \n",
    "    if curr_model == \"basis_former\":\n",
    "        indices = []\n",
    "        total_len = len(seq_x)\n",
    "        for i in range(total_len):\n",
    "            index_list = np.arange(i, i + len(seq_x[0]) + len(seq_y[0]), 1)\n",
    "            norm_index = index_list / total_len\n",
    "            indices.append(norm_index)\n",
    "        indices = torch.tensor(indices, dtype=torch.float32)\n",
    "        dataset = TensorDataset(seq_x, seq_y, seq_x_mark, seq_y_mark, indices)\n",
    "    else:\n",
    "        dataset = TensorDataset(seq_x, seq_y, seq_x_mark, seq_y_mark)\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=2, shuffle=True, drop_last=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898763c2-25af-4236-b6b4-43466525ccdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21225b3d-5c69-425f-9f8e-17ebcc39cd8b",
   "metadata": {},
   "source": [
    "# 2. Experimental Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f6a0895",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 96\n",
    "pred_length = 48\n",
    "label_length = 48\n",
    "batch_size = 24\n",
    "device = torch.device(f\"cuda:{args.device}\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9598752-60c2-45e0-a3da-535bb910219e",
   "metadata": {},
   "source": [
    "# Benchmark Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1627bd8d-ab8f-4f35-81c8-25b91760b230",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c10844",
   "metadata": {},
   "source": [
    "### Linear Model Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad38e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the main dataframe for linear model preprocessing\n",
    "df_linear = df.copy()\n",
    "\n",
    "# Define the number of lagged features\n",
    "lag_steps = 3\n",
    "\n",
    "# List of all columns (already defined in the main preprocessing)\n",
    "all_columns = df_linear.columns.tolist()\n",
    "\n",
    "# List of columns to exclude (non-country columns)\n",
    "exclude_columns = ['Datetime (UTC)', 'month', 'day', 'weekday', 'hour']\n",
    "\n",
    "# Define the country columns by excluding non-country columns\n",
    "countries = [col for col in all_columns if col not in exclude_columns]\n",
    "\n",
    "# Create lagged features for each country\n",
    "for country in countries:\n",
    "    for lag in range(1, lag_steps + 1):\n",
    "        df_linear[f'{country}_lag_{lag}'] = df_linear[country].shift(lag)\n",
    "\n",
    "# Drop rows with NaN values due to lagging\n",
    "df_linear.dropna(inplace=True)\n",
    "\n",
    "# Define features (X) and targets (Y)\n",
    "X_numerical = df_linear.drop(columns=countries + ['Datetime (UTC)'])\n",
    "Y = df_linear[countries]  # Target: current prices of all countries\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_numerical)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_size = 0.8\n",
    "train_size_idx = int(len(X_scaled) * train_size)\n",
    "X_train, X_test = X_scaled[:train_size_idx], X_scaled[train_size_idx:]\n",
    "Y_train, Y_test = Y[:train_size_idx], Y[train_size_idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c39d0c",
   "metadata": {},
   "source": [
    "### Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575df258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize and train the linear regression model\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "Y_pred_lr = model_lr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_lr = mean_squared_error(Y_test, Y_pred_lr)\n",
    "print(f\"Linear Regression Mean Squared Error: {mse_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb17613-c608-4a1b-b8dd-7773464d72b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07edd48",
   "metadata": {},
   "source": [
    "### LSTM Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740f3adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Copy the main dataframe for LSTM model preprocessing\n",
    "df_lstm = df.copy()\n",
    "\n",
    "# Rescale the data using StandardScaler for LSTM\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(df_lstm.drop(columns=['Datetime (UTC)', 'month', 'day', 'weekday', 'hour']))\n",
    "\n",
    "# Convert to a supervised learning problem by creating sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Define sequence length (number of time steps)\n",
    "seq_length = 24\n",
    "\n",
    "# Create sequences\n",
    "X, y = create_sequences(data_scaled, seq_length)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_size = int(X.shape[0] * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b871c7e",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd87f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the LSTM model\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(units=50, return_sequences=True, input_shape=(seq_length, X.shape[2])))\n",
    "model_lstm.add(LSTM(units=50, return_sequences=False))\n",
    "model_lstm.add(Dense(units=y.shape[1]))\n",
    "\n",
    "# Compile the model\n",
    "model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Fit the model\n",
    "model_lstm.fit(X_train, y_train, epochs=50, batch_size=24, validation_data=(X_test, y_test))\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lstm = model_lstm.predict(X_test)\n",
    "\n",
    "# Inverse transform the scaled data to original values\n",
    "y_test_inverse = scaler.inverse_transform(y_test)\n",
    "y_pred_inverse = scaler.inverse_transform(y_pred_lstm)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_lstm = mean_squared_error(y_test_inverse, y_pred_inverse)\n",
    "print(f\"LSTM Mean Squared Error: {mse_lstm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf856e7",
   "metadata": {},
   "source": [
    "### Improved LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eb0b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define an improved LSTM model\n",
    "model_lstm = Sequential()\n",
    "\n",
    "# Increase the number of units in LSTM layers\n",
    "model_lstm.add(LSTM(units=64, return_sequences=True, input_shape=(seq_length, X.shape[2])))\n",
    "model_lstm.add(Dropout(0.2))  # Add dropout for regularization\n",
    "\n",
    "model_lstm.add(LSTM(units=64, return_sequences=False))\n",
    "model_lstm.add(Dropout(0.2))  # Add dropout for regularization\n",
    "\n",
    "# Output layer\n",
    "model_lstm.add(Dense(units=y.shape[1]))\n",
    "\n",
    "# Compile the model with a slightly lower learning rate\n",
    "model_lstm.compile(optimizer=Adam(learning_rate=0.0005), loss='mean_squared_error')\n",
    "\n",
    "# Early stopping to prevent overfitting and reduce learning rate on plateau\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "\n",
    "# Fit the model\n",
    "model_lstm.fit(X_train, y_train, epochs=100, batch_size=24, \n",
    "               validation_data=(X_test, y_test), \n",
    "               callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lstm = model_lstm.predict(X_test)\n",
    "\n",
    "# Inverse transform the scaled data to original values\n",
    "y_test_inverse = scaler.inverse_transform(y_test)\n",
    "y_pred_inverse = scaler.inverse_transform(y_pred_lstm)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_lstm = mean_squared_error(y_test_inverse, y_pred_inverse)\n",
    "print(f\"Improved LSTM Mean Squared Error: {mse_lstm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5a7ac4-ef50-4568-aeb2-ed1cec9d015f",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02c458b-65b0-4808-a620-24831f9482c8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Unification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10670e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit (model, train_flag, test_flag, train_loader=None, test_loader=None, pretrained_model=None):\n",
    "    '''Fits a transformer model to the train and/or test loaders\n",
    "    \n",
    "    model - \"basis_former\", \"itransformer\", \"ns_autoformer\"\n",
    "    \n",
    "    train_flag: typ(bool) - True: to train the model on train_loader, False: if pretrained_model is passed\n",
    "    \n",
    "    test_flag: typ(bool) - True: to test on test_loader, False: if only training\n",
    "    \n",
    "    pretrained_model - pass a pretrained model if available to be fitted on a test_loader. \n",
    "    eg. fit(basis_former, train_flag=False, test_flag=True, test_loader=test_loader, pretrained_model=model)\n",
    "    '''\n",
    "    \n",
    "    if curr_model == 'basis_former':\n",
    "        # Code for Basisforme\n",
    "\n",
    "        import Basisformer.model\n",
    "        importlib.reload(Basisformer.model)\n",
    "        from Basisformer.model import Basisformer\n",
    "\n",
    "        import Basisformer.main\n",
    "        importlib.reload(Basisformer.main)\n",
    "        from Basisformer.main import parse_args, model_setup, log_and_print\n",
    "\n",
    "        args = parse_args()\n",
    "        \n",
    "        if pretrained_model == None:\n",
    "            # Set up model\n",
    "            model = model_setup(args, device)\n",
    "\n",
    "        else:\n",
    "            model = pretrained_model\n",
    "\n",
    "        # Log arguments and model\n",
    "        log_and_print('Args in experiment:')\n",
    "        log_and_print(args)\n",
    "        log_and_print(model)\n",
    "        \n",
    "        if train_flag:\n",
    "            import Basisformer.model\n",
    "            importlib.reload(Basisformer.model)\n",
    "            from Basisformer.model import Basisformer\n",
    "\n",
    "            import Basisformer.main\n",
    "            importlib.reload(Basisformer.main)\n",
    "            from Basisformer.main import train\n",
    "\n",
    "\n",
    "            record_dir = os.path.join('records', args.data_path.split('.')[0], 'features_' + args.features,\n",
    "                                    'seq_len' + str(args.seq_len) + ',' + 'pred_len' + str(args.pred_len))\n",
    "            \n",
    "            if train_loader == None:\n",
    "                return 'train_loader not found'\n",
    "\n",
    "            # Call the train function\n",
    "            train(model, train_loader, args, device, record_dir)\n",
    "            \n",
    "        else:\n",
    "            if pretrained_model == None:\n",
    "                return 'model not found which is required for testing'\n",
    "            \n",
    "        if test_flag :\n",
    "            import Basisformer.main\n",
    "            importlib.reload(Basisformer.main)\n",
    "            from Basisformer.main import test\n",
    "            \n",
    "            if test_loader == None:\n",
    "                return 'test_loader not found'\n",
    "\n",
    "            test(model, test_loader, args, device, record_dir)\n",
    "        return model\n",
    "            \n",
    "    \n",
    "    elif curr_model == 'itransformer':\n",
    "        # code for itransformer\n",
    "        \n",
    "        import iTransformer.experiment\n",
    "        importlib.reload(iTransformer.experiment)\n",
    "        from iTransformer.experiment import Exp_Long_Term_Forecast\n",
    "        \n",
    "        class Args:\n",
    "            is_training = 1\n",
    "            model_id = 'iTransformer_train'\n",
    "            model = 'iTransformer'\n",
    "            data = 'all_countries'\n",
    "            features = 'M'\n",
    "            target = 'OT'\n",
    "            freq = 'h'\n",
    "            checkpoints = './checkpoints/'\n",
    "            seq_len = 96\n",
    "            label_len = 48\n",
    "            pred_len = 48\n",
    "            enc_in = 24\n",
    "            dec_in = 24\n",
    "            c_out = 24\n",
    "            d_model = 512\n",
    "            n_heads = 8\n",
    "            e_layers = 2\n",
    "            d_layers = 1\n",
    "            d_ff = 2048\n",
    "            moving_avg = 25\n",
    "            factor = 1\n",
    "            distil = True\n",
    "            dropout = 0.05\n",
    "            embed = 'timeF'\n",
    "            activation = 'gelu'\n",
    "            output_attention = False\n",
    "            do_predict = True\n",
    "            num_workers = 10\n",
    "            itr = 2\n",
    "            train_epochs = 1\n",
    "            batch_size = 32\n",
    "            patience = 3\n",
    "            learning_rate = 0.0001\n",
    "            des = 'test'\n",
    "            loss = 'mse'\n",
    "            lradj = 'type1'\n",
    "            use_amp = False\n",
    "            use_gpu = True if torch.cuda.is_available() else False\n",
    "            gpu = 0\n",
    "            use_multi_gpu = False\n",
    "            devices = '0,1,2,3'\n",
    "            exp_name = 'MTSF'\n",
    "            channel_independence = False\n",
    "            inverse = False\n",
    "            class_strategy = 'projection'\n",
    "            target_root_path = './data'\n",
    "            target_data_path = 'all_countries'\n",
    "            efficient_training = False\n",
    "            use_norm = True\n",
    "            partial_start_index = 0\n",
    "            seed = 2021\n",
    "            p_hidden_dims = [128, 128]\n",
    "            p_hidden_layers = 2\n",
    "\n",
    "        args = Args()\n",
    "        \n",
    "        if pretrained_model == None:\n",
    "            # Initialize the experiment\n",
    "            exp = Exp_Long_Term_Forecast(args)\n",
    "\n",
    "        else:\n",
    "            return 'pretrained not valid for iTransformer and ns_autoformer'\n",
    "\n",
    "        # Define the settings\n",
    "        setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}'.format(\n",
    "            args.model_id, args.model, args.data, args.features, args.seq_len, args.label_len,\n",
    "            args.pred_len, args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff,\n",
    "            args.factor, args.embed, args.distil, args.des, 0)\n",
    "        \n",
    "        if train_flag:\n",
    "            Exp_Long_Term_Forecast.train(self=exp, train_loader=train_loader, setting=setting)\n",
    "        \n",
    "        if test_flag:\n",
    "            Exp_Long_Term_Forecast.test(self=exp, test_loader=test_loader, setting=setting, test=0)\n",
    "        return exp.model\n",
    "    \n",
    "    elif curr_model == 'ns_autoformer':\n",
    "        # code for itransformer\n",
    "        import ns_Autoformer.ns_Autoformer\n",
    "        importlib.reload(ns_Autoformer.ns_Autoformer)\n",
    "        from ns_Autoformer.ns_Autoformer import Model\n",
    "\n",
    "        # import ns_Autoformer.main\n",
    "        # importlib.reload(ns_Autoformer.main)\n",
    "        # from ns_Autoformer.main import parse_args\n",
    "        \n",
    "        from ns_Autoformer.main import Exp_Main\n",
    "\n",
    "        class Args:\n",
    "            is_training = 1\n",
    "            model_id = 'ns_autoformer_train'\n",
    "            model = 'ns_Autoformer'\n",
    "            features = 'M'\n",
    "            target = 'OT'\n",
    "            freq = 'h'\n",
    "            checkpoints = './checkpoints/'\n",
    "            seq_len = 96\n",
    "            label_len = 48\n",
    "            pred_len = 48\n",
    "            enc_in = 24\n",
    "            dec_in = 24\n",
    "            c_out = 24\n",
    "            d_model = 512\n",
    "            n_heads = 8\n",
    "            e_layers = 2\n",
    "            d_layers = 1\n",
    "            d_ff = 2048\n",
    "            moving_avg = 25\n",
    "            factor = 1\n",
    "            distil = True\n",
    "            dropout = 0.05\n",
    "            embed = 'timeF'\n",
    "            activation = 'gelu'\n",
    "            output_attention = False\n",
    "            do_predict = True\n",
    "            num_workers = 10\n",
    "            itr = 2\n",
    "            train_epochs = 1\n",
    "            batch_size = 32\n",
    "            patience = 3\n",
    "            learning_rate = 0.0001\n",
    "            des = 'test'\n",
    "            loss = 'mse'\n",
    "            lradj = 'type1'\n",
    "            use_amp = False\n",
    "            use_gpu = True if torch.cuda.is_available() else False\n",
    "            gpu = 0\n",
    "            use_multi_gpu = False\n",
    "            devices = '0,1,2,3'\n",
    "            seed = 2021\n",
    "            p_hidden_dims = [128, 128]\n",
    "            p_hidden_layers = 2\n",
    "\n",
    "        args = Args()\n",
    "\n",
    "        # if args.use_gpu:\n",
    "        #     if args.use_multi_gpu:\n",
    "        #         args.devices = args.devices.replace(' ', '')\n",
    "        #         device_ids = args.devices.split(',')\n",
    "        #         args.device_ids = [int(id_) for id_ in device_ids]\n",
    "        #         args.gpu = args.device_ids[0]\n",
    "        #     else:\n",
    "        #         torch.cuda.set_device(args.gpu)\n",
    "\n",
    "        # print('Args in experiment:')\n",
    "        # print(args)\n",
    "        \n",
    "        if pretrained_model == None:\n",
    "            # Initialize the experiment\n",
    "            exp = Exp_Main(args)\n",
    "\n",
    "        # Define the setting string\n",
    "        setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}'.format(\n",
    "            args.model_id, args.model, args.features, args.seq_len, args.label_len,\n",
    "            args.pred_len, args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff,\n",
    "            args.factor, args.embed, args.distil, args.des, 0)\n",
    "        \n",
    "        if train_flag:\n",
    "            Exp_Main.train(self=exp, train_loader=train_loader, setting=setting)\n",
    "        \n",
    "        if test_flag:\n",
    "            Exp_Main.test(self=exp, test_loader=test_loader, setting=setting, test=0)\n",
    "        return exp.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cca768-c6f9-4d30-ad48-32c86e9ae2c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Chronos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f123e551-7804-404c-9565-bbc4afd4c007",
   "metadata": {},
   "source": [
    "zero shot evaluation with Chronos Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2617ec8b-f710-450b-81b1-1f8ce6f4fba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/amazon-science/chronos-forecasting.git\n",
    "import chronos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d4e2e76-e80a-45da-aba7-c82e5dae03b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ChronosPipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m         chronos_data\u001b[38;5;241m.\u001b[39mappend(batch[\u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# Only take the first element (seq_x)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(chronos_data, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mChronosPipeline\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mamazon/chronos-t5-small\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# use \"cpu\" for CPU inference and \"mps\" for Apple Silicon\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16,\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     16\u001b[0m seq_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m24\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ChronosPipeline' is not defined"
     ]
    }
   ],
   "source": [
    "# Function to prepare data for Chronos\n",
    "def prepare_chronos_data(dataloader):\n",
    "    chronos_data = []\n",
    "    for batch in dataloader:\n",
    "        chronos_data.append(batch[0])  # Only take the first element (seq_x)\n",
    "    return torch.cat(chronos_data, dim=0)\n",
    "\n",
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-small\",\n",
    "    device_map=\"mps\",  # use \"cpu\" for CPU inference and \"mps\" for Apple Silicon\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "seq_length = 24\n",
    "pred_length = 12\n",
    "label_length = 12\n",
    "batch_size = 32\n",
    "countries = electricity_prices_train.columns.drop('Datetime (UTC)').tolist()\n",
    "seq_x_mark = timestamp_features_df.iloc[:len(electricity_prices_train)].drop(columns=['Datetime (UTC)']).values\n",
    "seq_y_mark = timestamp_features_df.iloc[len(electricity_prices_train):].drop(columns=['Datetime (UTC)']).values\n",
    "\n",
    "\n",
    "# Assume you have your data prepared as before\n",
    "# data, seq_x_mark, seq_y_mark = ...\n",
    "\n",
    "results = {}\n",
    "\n",
    "for country in countries:\n",
    "    # Extract data for the current country\n",
    "    country_data = electricity_prices_train_scaled[:, electricity_prices_train.columns.get_loc(country)]\n",
    "    \n",
    "    seq_x, seq_y = create_sequences(country_data, seq_length, pred_length, label_length, \"chronos\")\n",
    "    dataloader = create_dataloader(seq_x, seq_y, seq_x_mark, seq_y_mark, batch_size, \"chronos\")\n",
    "    \n",
    "    # Prepare data for Chronos\n",
    "    chronos_input = prepare_chronos_data(dataloader)\n",
    "    \n",
    "    # Now you can use chronos_input with your Chronos pipeline\n",
    "    # Assuming you have a Chronos pipeline already set up\n",
    "    forecast = pipeline.predict(\n",
    "        context=chronos_input,\n",
    "        prediction_length=pred_length,\n",
    "        num_samples=20,\n",
    "    )\n",
    "    \n",
    "    # Store the forecast results\n",
    "    results[country] = forecast\n",
    "    \n",
    "    print(f\"Completed forecast for {country}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bd82e9-d24f-4a39-9a5c-77821d6b2667",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8fb6121-1efc-4234-91af-39611924149f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ecf9cb-e4f4-4468-9818-c8c6fbf950c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_forecast = (forecast_reshaped * scaler.scale_[0]) + scaler.mean_[0]\n",
    "rescaled_forecast = rescaled_forecast.reshape(forecast_np.shape)\n",
    "print(rescaled_forecast.shape)  # Should print (1, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63fa5d6-0f1e-4c29-924c-aa327b8351e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_index = range(len(electricity_prices_test_scaled), len(electricity_prices_test_scaled) + 48)\n",
    "\n",
    "# Compute quantiles for the forecast\n",
    "low, median, high = np.quantile(forecast, [0.1, 0.5, 0.9], axis=0)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(range(len(electricity_prices_test_scaled)), electricity_prices_test_scaled, color=\"royalblue\", label=\"historical data\")\n",
    "plt.plot(forecast_index, median, color=\"tomato\", label=\"median forecast\")\n",
    "plt.fill_between(forecast_index, low, high, color=\"tomato\", alpha=0.3, label=\"80% prediction interval\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Electricity Prices')\n",
    "plt.title('Electricity Prices Forecast')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ee0fbc-fd5f-4b8e-99f0-e0d05ff0826d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Basisformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df01bc9-9596-49f6-ace9-1acf18f1c23e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ILk9LX4k5Yuu",
   "metadata": {
    "id": "ILk9LX4k5Yuu"
   },
   "outputs": [],
   "source": [
    "seq_length = 96\n",
    "pred_length = 48\n",
    "label_length = 48\n",
    "curr_model = \"basis_former\"\n",
    "\n",
    "train_seq_x, train_seq_y = create_sequences(electricity_prices_train_scaled, seq_length, pred_length, label_length, curr_model)\n",
    "train_seq_x_mark, train_seq_y_mark = create_sequences(timestamp_features_train.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "\n",
    "test_seq_x, test_seq_y = create_sequences(electricity_prices_test_scaled, seq_length, pred_length,label_length, curr_model)\n",
    "test_seq_x_mark, test_seq_y_mark = create_sequences(timestamp_features_test.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IeE-jvzOEVw-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IeE-jvzOEVw-",
    "outputId": "d4778504-79d4-475b-c868-17b3994fd3fc"
   },
   "outputs": [],
   "source": [
    "print(\"Sample training sequence x:\", train_seq_x[0])\n",
    "print(\"Sample training sequence y:\", train_seq_y[0])\n",
    "print(\"Sample training sequence x mark:\", train_seq_x_mark[0])\n",
    "print(\"Sample training sequence y mark:\", train_seq_y_mark[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OrL7qSyl5bqB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OrL7qSyl5bqB",
    "outputId": "01496ef4-4d84-4630-dc4b-5a1b9c36a404"
   },
   "outputs": [],
   "source": [
    "batch_size = 24\n",
    "\n",
    "# converting sequences to PyTorch DataLoader objects\n",
    "train_loader = create_dataloader(train_seq_x, train_seq_y, train_seq_x_mark, train_seq_y_mark, batch_size, curr_model)\n",
    "test_loader = create_dataloader(test_seq_x, test_seq_y, test_seq_x_mark, test_seq_y_mark, batch_size, curr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca8679b-4ac1-42ab-8065-f6f2519e40cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    print(f\"Batch contains {len(batch)} items:\")\n",
    "    for i, item in enumerate(batch):\n",
    "        print(f\"Item {i}: Shape = {item.shape if torch.is_tensor(item) else 'Not a tensor'}\")\n",
    "    break  # Just print the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Des1ClFuevfI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Des1ClFuevfI",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "538a4886-5959-4a8c-a4e8-3239df3ed5ec"
   },
   "outputs": [],
   "source": [
    "##pip install adabelief_pytorch==0.2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c7af02-3c5d-4a35-a1e1-ed6266bed132",
   "metadata": {},
   "source": [
    "### Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f18f708-9681-4f6a-b70b-0ad9009722f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import Basisformer.model\n",
    "importlib.reload(Basisformer.model)\n",
    "from Basisformer.model import Basisformer\n",
    "\n",
    "import Basisformer.main\n",
    "importlib.reload(Basisformer.main)\n",
    "from Basisformer.main import parse_args, model_setup, log_and_print\n",
    "\n",
    "args = parse_args()\n",
    "\n",
    "# Set up device\n",
    "device = torch.device(f\"cuda:{args.device}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set up model\n",
    "model = model_setup(args, device)\n",
    "\n",
    "# Log arguments and model\n",
    "log_and_print('Args in experiment:')\n",
    "log_and_print(args)\n",
    "log_and_print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25388088-0a01-4a53-9327-36baeb5ec317",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d34df7-21cb-4303-87f9-d5ec8c03ec8e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33d34df7-21cb-4303-87f9-d5ec8c03ec8e",
    "outputId": "3c5fe222-fb0a-4abc-d84a-489ef41b44b1"
   },
   "outputs": [],
   "source": [
    "import Basisformer.model\n",
    "importlib.reload(Basisformer.model)\n",
    "from Basisformer.model import Basisformer\n",
    "\n",
    "import Basisformer.main\n",
    "importlib.reload(Basisformer.main)\n",
    "from Basisformer.main import train\n",
    "\n",
    "\n",
    "record_dir = os.path.join('records', args.data_path.split('.')[0], 'features_' + args.features,\n",
    "                          'seq_len' + str(args.seq_len) + ',' + 'pred_len' + str(args.pred_len))\n",
    "\n",
    "# Call the train function\n",
    "train(model, train_loader, args, device, record_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886eefd2-4847-4504-a105-5d4fa9396aef",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j59FnuQFNHcV",
   "metadata": {
    "id": "j59FnuQFNHcV"
   },
   "outputs": [],
   "source": [
    "import Basisformer.main\n",
    "importlib.reload(Basisformer.main)\n",
    "from Basisformer.main import test\n",
    "\n",
    "test(model, test_loader, args, device, record_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1803a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "basisformer_train = train\n",
    "basisformer_test = test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ffc309-339b-43e4-ab87-1e1ece074e45",
   "metadata": {},
   "source": [
    "## iTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf6cf6e-e6dc-41fd-a14e-db5a55912360",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_model = \"itransformer\"  #\"basis_former\", \"itransformer\", \"ns_autoformer\"\n",
    "\n",
    "train_seq_x, train_seq_y = create_sequences(electricity_prices_train_scaled, seq_length, pred_length, label_length, curr_model)\n",
    "train_seq_x_mark, train_seq_y_mark = create_sequences(timestamp_features_train.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "\n",
    "test_seq_x, test_seq_y = create_sequences(electricity_prices_test_scaled, seq_length, pred_length,label_length, curr_model)\n",
    "test_seq_x_mark, test_seq_y_mark = create_sequences(timestamp_features_test.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "\n",
    "# converting sequences to PyTorch DataLoader objects\n",
    "train_loader = create_dataloader(train_seq_x, train_seq_y, train_seq_x_mark, train_seq_y_mark, batch_size, curr_model)\n",
    "test_loader = create_dataloader(test_seq_x, test_seq_y, test_seq_x_mark, test_seq_y_mark, batch_size, curr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca24c83-5c85-41d7-adfb-4b679d9bb9cf",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b770d7dc-c343-4c42-84ee-ab3ab9c3cd1e",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa62ae11-381d-4aaf-9e32-ade675824eeb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Nonstationary Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a8451f-0280-4b1d-83f4-645080a0ebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 96\n",
    "pred_length = 48\n",
    "label_length = 48\n",
    "curr_model = \"ns_autoformer\"\n",
    "\n",
    "train_seq_x, train_seq_y = create_sequences(electricity_prices_train_scaled, seq_length, pred_length, label_length, curr_model)\n",
    "train_seq_x_mark, train_seq_y_mark = create_sequences(timestamp_features_train.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "\n",
    "test_seq_x, test_seq_y = create_sequences(electricity_prices_test_scaled, seq_length, pred_length,label_length, curr_model)\n",
    "test_seq_x_mark, test_seq_y_mark = create_sequences(timestamp_features_test.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "batch_size = 24\n",
    "\n",
    "# converting sequences to PyTorch DataLoader objects\n",
    "train_loader = create_dataloader(train_seq_x, train_seq_y, train_seq_x_mark, train_seq_y_mark, batch_size, curr_model)\n",
    "test_loader = create_dataloader(test_seq_x, test_seq_y, test_seq_x_mark, test_seq_y_mark, batch_size, curr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5613fe15-f1ce-403c-ab95-885a612b9a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    print(f\"Batch contains {len(batch)} items:\")\n",
    "    for i, item in enumerate(batch):\n",
    "        print(f\"Item {i}: Shape = {item.shape if torch.is_tensor(item) else 'Not a tensor'}\")\n",
    "    break  # Just print the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376fd372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import ns_Autoformer.ns_Autoformer\n",
    "importlib.reload(ns_Autoformer.ns_Autoformer)\n",
    "from ns_Autoformer.ns_Autoformer import Model\n",
    "\n",
    "import ns_Autoformer.main\n",
    "importlib.reload(ns_Autoformer.main)\n",
    "from ns_Autoformer.main import parse_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d461a9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ns_Autoformer.main import Exp_Main\n",
    "\n",
    "# setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}'.format(\n",
    "#     args.model_id, args.model, args.features, args.seq_len, args.label_len,\n",
    "#     args.pred_len, args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff,\n",
    "#     args.factor, args.embed, args.distil, args.des, 0)\n",
    "\n",
    "# exp = Exp_Main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eafce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ns_Autoformer.main import Exp_Main\n",
    "\n",
    "class Args:\n",
    "    is_training = 1\n",
    "    model_id = 'ns_autoformer_train'\n",
    "    model = 'ns_Autoformer'\n",
    "    features = 'M'\n",
    "    target = 'OT'\n",
    "    freq = 'h'\n",
    "    checkpoints = './checkpoints/'\n",
    "    seq_len = 96\n",
    "    label_len = 48\n",
    "    pred_len = 48\n",
    "    enc_in = 24\n",
    "    dec_in = 24\n",
    "    c_out = 24\n",
    "    d_model = 512\n",
    "    n_heads = 8\n",
    "    e_layers = 2\n",
    "    d_layers = 1\n",
    "    d_ff = 2048\n",
    "    moving_avg = 25\n",
    "    factor = 1\n",
    "    distil = True\n",
    "    dropout = 0.05\n",
    "    embed = 'timeF'\n",
    "    activation = 'gelu'\n",
    "    output_attention = False\n",
    "    do_predict = True\n",
    "    num_workers = 10\n",
    "    itr = 2\n",
    "    train_epochs = 1\n",
    "    batch_size = 32\n",
    "    patience = 3\n",
    "    learning_rate = 0.0001\n",
    "    des = 'test'\n",
    "    loss = 'mse'\n",
    "    lradj = 'type1'\n",
    "    use_amp = False\n",
    "    use_gpu = True if torch.cuda.is_available() else False\n",
    "    gpu = 0\n",
    "    use_multi_gpu = False\n",
    "    devices = '0,1,2,3'\n",
    "    seed = 2021\n",
    "    p_hidden_dims = [128, 128]\n",
    "    p_hidden_layers = 2\n",
    "\n",
    "args = Args()\n",
    "\n",
    "if args.use_gpu:\n",
    "    if args.use_multi_gpu:\n",
    "        args.devices = args.devices.replace(' ', '')\n",
    "        device_ids = args.devices.split(',')\n",
    "        args.device_ids = [int(id_) for id_ in device_ids]\n",
    "        args.gpu = args.device_ids[0]\n",
    "    else:\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "\n",
    "print('Args in experiment:')\n",
    "print(args)\n",
    "\n",
    "# Initialize the experiment\n",
    "exp = Exp_Main(args)\n",
    "\n",
    "# Define the setting string\n",
    "setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}'.format(\n",
    "    args.model_id, args.model, args.features, args.seq_len, args.label_len,\n",
    "    args.pred_len, args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff,\n",
    "    args.factor, args.embed, args.distil, args.des, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ba12b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ns_Autoformer.main import Exp_Main\n",
    "\n",
    "Exp_Main.train(self=exp, train_loader=train_loader, setting=setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ea5a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "Exp_Main.test(self=exp, test_loader=test_loader, setting=setting, test=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbdc742",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_autoformer_train = Exp_Main.train\n",
    "ns_autoformer_test = Exp_Main.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55134ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Diya\\anaconda3\\envs\\APA\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use CPU\n",
      "Epoch: 1 cost time: 23.51469397544861\n",
      "Epoch: 1, Steps: 65 | Train Loss: 0.7204566\n",
      "Validation loss decreased (inf --> 0.720457).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "test shape: (12, 24, 48, 24) (12, 24, 48, 24)\n",
      "test shape: (288, 48, 24) (288, 48, 24)\n",
      "mse:1.2623029947280884, mae:0.8087429404258728\n"
     ]
    }
   ],
   "source": [
    "ns_autoformer_train_test = fit(model=curr_model, train_flag=True, test_flag=True, train_loader=train_loader, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18c7e457",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ns_autoformer_train_test \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_flag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_flag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[25], line 170\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(model, train_flag, test_flag, train_loader, test_loader, pretrained_model)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mns_Autoformer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mns_Autoformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# import ns_Autoformer.main\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# importlib.reload(ns_Autoformer.main)\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;66;03m# from ns_Autoformer.main import parse_args\u001b[39;00m\n\u001b[1;32m--> 170\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mns_Autoformer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Exp_Main\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mArgs\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     is_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Diya\\Documents\\GItHub\\apa_group4_transformers_for_multivar_energy_forecasting\\ns_Autoformer\\main.py:89\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m args\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m#args = parse_args()\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m \u001b[43margs\u001b[49m\u001b[38;5;241m.\u001b[39muse_gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;129;01mand\u001b[39;00m args\u001b[38;5;241m.\u001b[39muse_gpu \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     91\u001b[0m fix_seed \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mseed\n\u001b[0;32m     92\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(fix_seed)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2803d193-eb4d-4ba8-b719-e2fa360e4167",
   "metadata": {},
   "source": [
    "# 3. Results - Models Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "315f19d0-063a-4932-8af4-7689bcb289f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(model_name, train_loader, test_loader,  self, setting, args=None, device=None, record_dir=None):\n",
    "    if model_name == \"basisformer\":\n",
    "        basisformer_train(model_name, train_loader, args, device, record_dir)\n",
    "        results = basisformer_test(model_name, test_loader, args, device, record_dir)\n",
    "    elif model_name == \"itransformer\":\n",
    "        itransformer_train(self, train_loader, setting)\n",
    "        results = itransformer_test(self, test_loader, setting)\n",
    "    elif model_name == \"ns_autoformer\":\n",
    "        ns_autoformer_train(self, train_loader, setting)\n",
    "        results = ns_autoformer_test(self, train_loader, setting)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {model_name}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def compare_models(train_loader, test_loader, args, self, setting, device, record_dir):\n",
    "    models = [\"basisformer\", \"itransformer\", \"ns_autoformer\"]\n",
    "    results = {}\n",
    "    \n",
    "    for model_name in models:\n",
    "        if model_name == \"basisformer\":\n",
    "            results[model_name] = run_models(model_name, train_loader, test_loader, args, self, setting, device, record_dir)\n",
    "        else:\n",
    "            results[model_name] = run_models(model_name, train_loader, test_loader, self, setting)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f782f44-f11a-4da5-84f7-e2f866782482",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m compare_models(train_loader\u001b[38;5;241m=\u001b[39mtrain_loader, test_loader\u001b[38;5;241m=\u001b[39mtest_loader, args\u001b[38;5;241m=\u001b[39m\u001b[43margs\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m=\u001b[39mexp, setting\u001b[38;5;241m=\u001b[39msetting, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, record_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "results = compare_models(train_loader=train_loader, test_loader=test_loader, args=args, self=exp, setting=setting, device=None, record_dir=None, index=None)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0bbe9e-2ecc-49c0-bf7b-356fb6f80758",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 6. Outlook "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0876475-7871-4b24-b71c-4d70f4d5adea",
   "metadata": {},
   "source": [
    "## Chronos Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56344b93-c9be-4c74-a0af-028dfdd20cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"chronos[training] @ git+https://github.com/amazon-science/chronos-forecasting.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb5bb54-ba52-4564-9775-05648c81013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python supporting_files_chronos/kernel-synth.py --num-series 500 --max-kernels 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c174fb6-a8cb-4ffb-b5fd-09a6d7908d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.ipc as ipc\n",
    "\n",
    "file_path = 'supporting_files_chronos/kernelsynth-data.arrow'\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    reader = ipc.RecordBatchFileReader(f)\n",
    "    table = reader.read_all()\n",
    "\n",
    "df_ch = table.to_pandas()\n",
    "\n",
    "print(df_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961121e6-2507-475c-8a80-7d6eb4489466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Number of time series\n",
    "num_series = 15\n",
    "# Number of plots per row\n",
    "plots_per_row = 5\n",
    "# Number of rows\n",
    "num_rows = (num_series + plots_per_row - 1) // plots_per_row\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, plots_per_row, figsize=(15, num_rows * 3))\n",
    "\n",
    "for i in range(num_series):\n",
    "    row = i // plots_per_row\n",
    "    col = i % plots_per_row\n",
    "    ax = axes[row, col]\n",
    "    ax.plot(df_ch['target'].iloc[i])\n",
    "    ax.set_title(f'Time Series {i}')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Value')\n",
    "\n",
    "# Remove any empty subplots\n",
    "for j in range(i + 1, num_rows * plots_per_row):\n",
    "    fig.delaxes(axes.flatten()[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9102227-5e5b-43ca-886e-362609622ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python supporting_files_chronos/kernel-synth-mult.py --num-series 500 --max-kernels 2 --dimensions 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c8baf1-c81a-4d00-a358-68f3697deda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.ipc as ipc\n",
    "\n",
    "file_path = 'supporting_files_chronos/kernelsynth-data.arrow'\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    reader = ipc.RecordBatchFileReader(f)\n",
    "    table = reader.read_all()\n",
    "\n",
    "df_ch_mult = table.to_pandas()\n",
    "\n",
    "print(df_ch_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2f68c5-3899-42e3-a491-fae38480a6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_ch_mult.head())\n",
    "print(df_ch_mult['target'].head().apply(lambda x: np.array(x).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fb2bce-e5b5-4f44-b2f7-76815d8a78d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot multivariate time series\n",
    "def plot_multivariate_time_series(data, num_rows=3, num_cols=5):\n",
    "    num_series = num_rows * num_cols\n",
    "    time_points = np.arange(len(data[0]) // 3)  # 1024 time points for reshaped data\n",
    "    \n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(20, num_rows * 4))\n",
    "    axs = axs.flatten()  # Flatten to easily iterate over subplots\n",
    "    \n",
    "    for i in range(num_series):\n",
    "        series = np.array(data[i]).reshape(-1, 3)  # Reshape to [1024, 3]\n",
    "        for j in range(series.shape[1]):\n",
    "            axs[i].plot(time_points, series[:, j], label=f'Dimension {j+1}')\n",
    "        axs[i].set_title(f'Time Series {i+1}')\n",
    "        axs[i].set_xlabel('Time')\n",
    "        axs[i].set_ylabel('Value')\n",
    "        axs[i].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Extract the 'target' column as a list and plot the first 15 multivariate time series\n",
    "plot_multivariate_time_series(df_ch_mult['target'].head(15).tolist(), num_rows=3, num_cols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8868e96d-c11f-44da-8284-5e3bdd7aa438",
   "metadata": {},
   "source": [
    "## DYNOTEARS Causal Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a06305-e94e-4e3e-8c8a-5a5036bf69e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalnex.structure.notears import from_pandas\n",
    "df_str = df.drop(columns=['Datetime (UTC)'])\n",
    "sm = from_pandas(df_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b7a18a-5c45-4440-b616-9c6f949c4db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalnex.plots import plot_structure, NODE_STYLE, EDGE_STYLE\n",
    "\n",
    "viz = plot_structure(\n",
    "    sm,\n",
    "    all_node_attributes=NODE_STYLE.WEAK,\n",
    "    all_edge_attributes=EDGE_STYLE.WEAK,\n",
    ")\n",
    "\n",
    "viz.toggle_physics(False)\n",
    "viz.show(\"supporting_files_dynotears/01_fully_connected.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297ebd63-03d7-45ab-8815-f4417d6ffeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.remove_edges_below_threshold(0.8)\n",
    "viz = plot_structure(\n",
    "    sm,\n",
    "    all_node_attributes=NODE_STYLE.WEAK,\n",
    "    all_edge_attributes=EDGE_STYLE.WEAK,\n",
    ")\n",
    "viz.show(\"supporting_files_dynotears/01_thresholded.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed52dbcf-3b38-457a-b105-b536abcccf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalnex.structure.notears import from_pandas\n",
    "df_str = df.drop(columns=['Datetime (UTC)'])\n",
    "sm = from_pandas(df_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad28f5e0-39c1-4129-a872-fa77fc837671",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.remove_edges_below_threshold(0.8)\n",
    "viz = plot_structure(\n",
    "    sm,\n",
    "    all_node_attributes=NODE_STYLE.WEAK,\n",
    "    all_edge_attributes=EDGE_STYLE.WEAK,\n",
    ")\n",
    "viz.show(\"supporting_files_dynotears/01_thresholded.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27208a4-9616-40ff-b2f3-d4455498b979",
   "metadata": {},
   "source": [
    "## Granger causality test with nonlinear forecasting methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71002567-98ca-49d4-a3d1-eb9dc74bf455",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nonlincausality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a85194-ab4f-4f57-b164-abe8bce5091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Feb  7 23:29:32 2022\n",
    "\n",
    "@author: Maciej Rosoł\n",
    "\n",
    "contact: mrosol5@gmail.com, maciej.rosol.dokt@pw.edu.pl\n",
    "\"\"\"\n",
    "#%%\n",
    "import os\n",
    "\n",
    "# os.chdir(os.path.dirname(__file__))\n",
    "import numpy as np\n",
    "##import tensorflow\n",
    "import nonlincausality as nlc\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from nonlincausality.utils import prepare_data_for_prediction, calculate_pred_and_errors\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae4f41d-d94a-4877-987a-206fe905892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Data generation Y->X\n",
    "np.random.seed(10)\n",
    "y = (\n",
    "    np.cos(np.linspace(0, 20, 10_100))\n",
    "    + np.sin(np.linspace(0, 3, 10_100))\n",
    "    - 0.2 * np.random.random(10_100)\n",
    ")\n",
    "np.random.seed(20)\n",
    "x = 2 * y ** 3 - 5 * y ** 2 + 0.3 * y + 2 - 0.05 * np.random.random(10_100)\n",
    "data = np.vstack([x[:-100], y[100:]]).T\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(data[:, 0], label=\"X\")\n",
    "plt.plot(data[:, 1], label=\"Y\")\n",
    "plt.xlabel(\"Number of sample\")\n",
    "plt.ylabel(\"Signals [AU]\")\n",
    "plt.legend()\n",
    "\n",
    "#%% Test in case of presence of the causality\n",
    "lags = [50, 150]\n",
    "data_train = data[:6000, :]\n",
    "data_val = data[6000:8000, :]\n",
    "data_test = data[8000:, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8f4823-6810-4a83-941e-b759cddef251",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = nlc.nonlincausalityNN(\n",
    "    x=data_train,\n",
    "    maxlag=lags,\n",
    "    NN_config=['d','dr','d','dr'],\n",
    "    NN_neurons=[100,0.05,100,0.05],\n",
    "    x_test=data_test,\n",
    "    run=3,\n",
    "    epochs_num=[50, 50],\n",
    "    learning_rate=[0.0001, 0.00001],\n",
    "    batch_size_num=32,\n",
    "    x_val=data_val,\n",
    "    reg_alpha=None,\n",
    "    callbacks=None,\n",
    "    verbose=True,\n",
    "    plot=True,\n",
    ")\n",
    "\n",
    "#%% Example of obtaining the results\n",
    "for lag in lags:\n",
    "    best_model_X = results[lag].best_model_X\n",
    "    best_model_XY = results[lag].best_model_XY\n",
    "\n",
    "    p_value = results[lag].p_value\n",
    "    test_statistic = results[lag]._test_statistic\n",
    "\n",
    "    best_history_X = results[lag].best_history_X\n",
    "    best_history_XY = results[lag].best_history_XY\n",
    "\n",
    "    nlc.plot_history_loss(best_history_X, best_history_XY)\n",
    "    plt.title(\"Lag = %d\" % lag)\n",
    "    best_errors_X = results[lag].best_errors_X\n",
    "    best_errors_XY = results[lag].best_errors_XY\n",
    "\n",
    "    cohens_d = np.abs(\n",
    "        (np.mean(np.abs(best_errors_X)) - np.mean(np.abs(best_errors_XY)))\n",
    "        / np.std([best_errors_X, best_errors_XY])\n",
    "    )\n",
    "    print(\"For lag = %d Cohen's d = %0.3f\" % (lag, cohens_d))\n",
    "    print(f\"Test statistic = {test_statistic} p-value = {p_value}\")\n",
    "\n",
    "    # Using models for prediction\n",
    "    data_X, data_XY = prepare_data_for_prediction(data_test, lag)\n",
    "    X_pred_X = best_model_X.predict(data_X)\n",
    "    X_pred_XY = best_model_XY.predict(data_XY)\n",
    "\n",
    "    # Plot of true X vs X predicted\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].plot(data_test[lag:, 0], X_pred_X, \"o\")\n",
    "    ax[0].set_xlabel(\"X test values\")\n",
    "    ax[0].set_ylabel(\"Predicted X values\")\n",
    "    ax[0].set_title(\"Model based on X\")\n",
    "    ax[1].plot(data_test[lag:, 0], X_pred_XY, \"o\")\n",
    "    ax[1].set_xlabel(\"X test values\")\n",
    "    ax[1].set_ylabel(\"Predicted X values\")\n",
    "    ax[1].set_title(\"Model based on X and Y\")\n",
    "    plt.suptitle(\"Lag = %d\" % lag)\n",
    "\n",
    "    # Another way of obtaining predicted values (and errors)\n",
    "    X_pred_X, X_pred_XY, error_X, error_XY = calculate_pred_and_errors(\n",
    "        data_test[lag:, 0], \n",
    "        data_X, \n",
    "        data_XY, \n",
    "        best_model_X, \n",
    "        best_model_XY\n",
    "    )\n",
    "    # Plot of X predicted vs prediction error\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].plot(X_pred_X, error_X, \"o\")\n",
    "    ax[0].set_xlabel(\"Predicted X values\")\n",
    "    ax[0].set_ylabel(\"Prediction errors\")\n",
    "    ax[0].set_title(\"Model based on X\")\n",
    "    ax[1].plot(X_pred_XY, error_XY, \"o\")\n",
    "    ax[1].set_xlabel(\"Predicted X values\")\n",
    "    ax[1].set_ylabel(\"Prediction errors\")\n",
    "    ax[1].set_title(\"Model based on X and Y\")\n",
    "    plt.suptitle(\"Lag = %d\" % lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706cea49-2e4e-4b80-9dc4-be81936b1cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Test in case of absence of the causality\n",
    "np.random.seed(30)\n",
    "data_noise = np.vstack([x[:-100], np.random.random(10_000)]).T\n",
    "\n",
    "lags = [50, 150]\n",
    "data_noise_train = data_noise[:6000, :]\n",
    "data_noise_val = data_noise[6000:8000, :]\n",
    "data_noise_test = data_noise[8000:, :]\n",
    "\n",
    "results = nlc.nonlincausalityNN(\n",
    "    x=data_noise_train,\n",
    "    maxlag=lags,\n",
    "    NN_config=['d','dr','d','dr'],\n",
    "    NN_neurons=[100,0.05,100,0.05],\n",
    "    x_test=data_noise_test,\n",
    "    run=3,\n",
    "    epochs_num=[50, 50],\n",
    "    learning_rate=[0.001, 0.0001],\n",
    "    batch_size_num=32,\n",
    "    x_val=data_noise_val,\n",
    "    reg_alpha=None,\n",
    "    callbacks=None,\n",
    "    verbose=True,\n",
    "    plot=True,\n",
    ")\n",
    "\n",
    "#%% Example of obtaining the results\n",
    "for lag in lags:\n",
    "    best_model_X_lag50 = results[lag].best_model_X\n",
    "    best_model_XY_lag50 = results[lag].best_model_XY\n",
    "\n",
    "    p_value = results[lag].p_value\n",
    "    test_statistic = results[lag].test_statistic\n",
    "\n",
    "    best_history_X = results[lag].best_history_X\n",
    "    best_history_XY = results[lag].best_history_XY\n",
    "\n",
    "    nlc.plot_history_loss(best_history_X, best_history_XY)\n",
    "    plt.title(\"Lag = %d\" % lag)\n",
    "\n",
    "    best_errors_X = results[lag].best_errors_X\n",
    "    best_errors_XY = results[lag].best_errors_XY\n",
    "\n",
    "    cohens_d = np.abs(\n",
    "        (np.mean(np.abs(best_errors_X)) - np.mean(np.abs(best_errors_XY)))\n",
    "        / np.std([best_errors_X, best_errors_XY])\n",
    "    )\n",
    "    print(\"For lag = %d Cohen's d = %0.3f\" % (lag, cohens_d))\n",
    "    print(f\"test statistic = {test_statistic} p-value = {p_value}\")\n",
    "#%% Example of the measure of the causality change over time\n",
    "\n",
    "data_test_measure = copy.copy(data_test)\n",
    "np.random.seed(30)\n",
    "data_test_measure[:1000, 1] = np.random.random(1000)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(data_test_measure[:, 0], label=\"X\")\n",
    "plt.plot(data_test_measure[:, 1], label=\"Y\")\n",
    "plt.xlabel(\"Number of sample\")\n",
    "plt.ylabel(\"Signals [AU]\")\n",
    "plt.legend()\n",
    "\n",
    "results = nlc.nonlincausalitymeasureNN(\n",
    "    x=data_train,\n",
    "    maxlag=lags,\n",
    "    window=100,\n",
    "    step=1,\n",
    "    NN_config=['d','dr','d','dr'],\n",
    "    NN_neurons=[100,0.05,100,0.05],\n",
    "    x_test=data_test_measure,\n",
    "    run=3,\n",
    "    epochs_num=[50,50],\n",
    "    learning_rate=[0.0001, 0.00001],\n",
    "    batch_size_num=32,\n",
    "    x_val=data_val,\n",
    "    verbose=True,\n",
    "    plot=True,\n",
    ")\n",
    "\n",
    "\n",
    "#%% Example of usage for conditional analysis\n",
    "np.random.seed(30)\n",
    "z = np.random.random([10_000, 2])\n",
    "\n",
    "z_train = z[:6000, :]\n",
    "z_val = z[6000:8000, :]\n",
    "z_test = z[8000:, :]\n",
    "\n",
    "results_conditional = nlc.nonlincausalityNN(\n",
    "    x=data_train,\n",
    "    maxlag=lags,\n",
    "    NN_config=['d','dr','d','dr'],\n",
    "    NN_neurons=[100,0.05,100,0.05],\n",
    "    x_test=data_test,\n",
    "    run=1,\n",
    "    z=z_train,\n",
    "    z_test=z_test,\n",
    "    epochs_num=[50, 50],\n",
    "    learning_rate=[0.0001, 0.00001],\n",
    "    batch_size_num=32,\n",
    "    x_val=data_val,\n",
    "    z_val=z_val,\n",
    "    reg_alpha=None,\n",
    "    callbacks=None,\n",
    "    verbose=True,\n",
    "    plot=True,\n",
    ")\n",
    "# %% Exaple of the usage the package with Scikit-learn model\n",
    "\n",
    "parametres = {\n",
    "    'kernel':['poly', 'rbf'],\n",
    "    'C':[0.01,0.1,1], \n",
    "    'epsilon':[0.01,0.1,1.]\n",
    "}\n",
    "results_skl = nlc.nonlincausality_sklearn(    \n",
    "    x=data_train,\n",
    "    sklearn_model=SVR,\n",
    "    maxlag=lags,\n",
    "    params=parametres,\n",
    "    x_test=data_test,\n",
    "    x_val=data_val,\n",
    "    plot=True)\n",
    "\n",
    "#%% Example of usage other functions for causality analysis\n",
    "\n",
    "# ARIMA/ARIMAX models\n",
    "results_ARIMA = nlc.nonlincausalityARIMA(x=data_train[::10], maxlag=[5,15], x_test=data_test[::10])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
