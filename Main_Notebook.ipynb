{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c73133af-7360-4762-9048-3aa0b3bb71b4",
   "metadata": {},
   "source": [
    "### Agenda:\n",
    "1. Data Loading & Preprocessing\n",
    "   - Pivoting\n",
    "   - Missing values handling\n",
    "   - Date features creation\n",
    "   - Train/Test split\n",
    "   - Scaling\n",
    "   - Sequences\n",
    "   - Data Loader (incl. indexing)\n",
    "2. Chronos Model\n",
    "3. BasisFormer\n",
    "4. Non-Stationary Transformer\n",
    "5. iTransformer\n",
    "6. Synthtic Data Generation\n",
    "   - Chronos Simulation Framework\n",
    "   - DYNOTEARS Causal Structure\n",
    "   - Augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "veljByFX557b",
   "metadata": {
    "id": "veljByFX557b"
   },
   "outputs": [],
   "source": [
    "#!pip install torch==2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5pNFgFQSKB57",
   "metadata": {
    "id": "5pNFgFQSKB57"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.weight_norm as wn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import os\n",
    "import logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "from chronos import ChronosPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b877c7ed-2c69-42cb-ae56-4850ade1586e",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "iGtogtkxzGiT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "iGtogtkxzGiT",
    "outputId": "d63b1548-a355-4ac8-89ed-fc0029c44b31"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>ISO3 Code</th>\n",
       "      <th>Datetime (UTC)</th>\n",
       "      <th>Datetime (Local)</th>\n",
       "      <th>Price (EUR/MWhe)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>2015-01-01 01:00:00</td>\n",
       "      <td>17.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>2015-01-01 01:00:00</td>\n",
       "      <td>2015-01-01 02:00:00</td>\n",
       "      <td>15.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>2015-01-01 02:00:00</td>\n",
       "      <td>2015-01-01 03:00:00</td>\n",
       "      <td>16.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>2015-01-01 03:00:00</td>\n",
       "      <td>2015-01-01 04:00:00</td>\n",
       "      <td>17.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>2015-01-01 04:00:00</td>\n",
       "      <td>2015-01-01 05:00:00</td>\n",
       "      <td>16.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country ISO3 Code       Datetime (UTC)     Datetime (Local)  \\\n",
       "0  Austria       AUT  2015-01-01 00:00:00  2015-01-01 01:00:00   \n",
       "1  Austria       AUT  2015-01-01 01:00:00  2015-01-01 02:00:00   \n",
       "2  Austria       AUT  2015-01-01 02:00:00  2015-01-01 03:00:00   \n",
       "3  Austria       AUT  2015-01-01 03:00:00  2015-01-01 04:00:00   \n",
       "4  Austria       AUT  2015-01-01 04:00:00  2015-01-01 05:00:00   \n",
       "\n",
       "   Price (EUR/MWhe)  \n",
       "0             17.93  \n",
       "1             15.17  \n",
       "2             16.38  \n",
       "3             17.38  \n",
       "4             16.38  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##file_path = '/content/all_countries.csv' ## colab path\n",
    "file_path = 'data/all_countries.csv' ## jupyter path\n",
    "df = pd.read_csv(file_path)\n",
    "df = pd.DataFrame(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "vQW9jbwq4lFG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "vQW9jbwq4lFG",
    "outputId": "e9aa57ef-18a2-4243-cd79-51b284512116"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Country</th>\n",
       "      <th>Austria</th>\n",
       "      <th>Belgium</th>\n",
       "      <th>Bulgaria</th>\n",
       "      <th>Croatia</th>\n",
       "      <th>Czechia</th>\n",
       "      <th>Denmark</th>\n",
       "      <th>Estonia</th>\n",
       "      <th>Finland</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>...</th>\n",
       "      <th>Norway</th>\n",
       "      <th>Poland</th>\n",
       "      <th>Portugal</th>\n",
       "      <th>Romania</th>\n",
       "      <th>Serbia</th>\n",
       "      <th>Slovakia</th>\n",
       "      <th>Slovenia</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Sweden</th>\n",
       "      <th>Switzerland</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime (UTC)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00</th>\n",
       "      <td>17.93</td>\n",
       "      <td>34.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.20</td>\n",
       "      <td>18.29</td>\n",
       "      <td>23.37</td>\n",
       "      <td>23.37</td>\n",
       "      <td>34.94</td>\n",
       "      <td>17.93</td>\n",
       "      <td>...</td>\n",
       "      <td>27.36</td>\n",
       "      <td>17.18</td>\n",
       "      <td>48.10</td>\n",
       "      <td>44.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.20</td>\n",
       "      <td>23.25</td>\n",
       "      <td>48.10</td>\n",
       "      <td>23.37</td>\n",
       "      <td>43.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 01:00:00</th>\n",
       "      <td>15.17</td>\n",
       "      <td>32.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.06</td>\n",
       "      <td>16.04</td>\n",
       "      <td>19.33</td>\n",
       "      <td>19.33</td>\n",
       "      <td>32.19</td>\n",
       "      <td>15.17</td>\n",
       "      <td>...</td>\n",
       "      <td>27.24</td>\n",
       "      <td>17.38</td>\n",
       "      <td>47.33</td>\n",
       "      <td>39.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.06</td>\n",
       "      <td>22.20</td>\n",
       "      <td>47.33</td>\n",
       "      <td>19.33</td>\n",
       "      <td>38.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 02:00:00</th>\n",
       "      <td>16.38</td>\n",
       "      <td>28.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.27</td>\n",
       "      <td>14.60</td>\n",
       "      <td>17.66</td>\n",
       "      <td>17.66</td>\n",
       "      <td>23.53</td>\n",
       "      <td>16.38</td>\n",
       "      <td>...</td>\n",
       "      <td>27.16</td>\n",
       "      <td>17.40</td>\n",
       "      <td>42.27</td>\n",
       "      <td>26.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.27</td>\n",
       "      <td>19.56</td>\n",
       "      <td>42.27</td>\n",
       "      <td>17.66</td>\n",
       "      <td>35.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 03:00:00</th>\n",
       "      <td>17.38</td>\n",
       "      <td>28.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.17</td>\n",
       "      <td>14.95</td>\n",
       "      <td>17.53</td>\n",
       "      <td>17.53</td>\n",
       "      <td>22.92</td>\n",
       "      <td>17.38</td>\n",
       "      <td>...</td>\n",
       "      <td>27.15</td>\n",
       "      <td>18.60</td>\n",
       "      <td>38.41</td>\n",
       "      <td>20.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.17</td>\n",
       "      <td>18.88</td>\n",
       "      <td>38.41</td>\n",
       "      <td>17.53</td>\n",
       "      <td>30.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 04:00:00</th>\n",
       "      <td>16.38</td>\n",
       "      <td>34.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.90</td>\n",
       "      <td>14.50</td>\n",
       "      <td>18.07</td>\n",
       "      <td>18.07</td>\n",
       "      <td>34.26</td>\n",
       "      <td>16.38</td>\n",
       "      <td>...</td>\n",
       "      <td>27.30</td>\n",
       "      <td>19.30</td>\n",
       "      <td>35.72</td>\n",
       "      <td>18.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.90</td>\n",
       "      <td>18.39</td>\n",
       "      <td>35.72</td>\n",
       "      <td>18.07</td>\n",
       "      <td>28.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Country              Austria  Belgium  Bulgaria  Croatia  Czechia  Denmark  \\\n",
       "Datetime (UTC)                                                               \n",
       "2015-01-01 00:00:00    17.93    34.94       NaN      NaN    24.20    18.29   \n",
       "2015-01-01 01:00:00    15.17    32.19       NaN      NaN    22.06    16.04   \n",
       "2015-01-01 02:00:00    16.38    28.05       NaN      NaN    20.27    14.60   \n",
       "2015-01-01 03:00:00    17.38    28.04       NaN      NaN    19.17    14.95   \n",
       "2015-01-01 04:00:00    16.38    34.26       NaN      NaN    17.90    14.50   \n",
       "\n",
       "Country              Estonia  Finland  France  Germany  ...  Norway  Poland  \\\n",
       "Datetime (UTC)                                          ...                   \n",
       "2015-01-01 00:00:00    23.37    23.37   34.94    17.93  ...   27.36   17.18   \n",
       "2015-01-01 01:00:00    19.33    19.33   32.19    15.17  ...   27.24   17.38   \n",
       "2015-01-01 02:00:00    17.66    17.66   23.53    16.38  ...   27.16   17.40   \n",
       "2015-01-01 03:00:00    17.53    17.53   22.92    17.38  ...   27.15   18.60   \n",
       "2015-01-01 04:00:00    18.07    18.07   34.26    16.38  ...   27.30   19.30   \n",
       "\n",
       "Country              Portugal  Romania  Serbia  Slovakia  Slovenia  Spain  \\\n",
       "Datetime (UTC)                                                              \n",
       "2015-01-01 00:00:00     48.10    44.17     NaN     24.20     23.25  48.10   \n",
       "2015-01-01 01:00:00     47.33    39.17     NaN     22.06     22.20  47.33   \n",
       "2015-01-01 02:00:00     42.27    26.93     NaN     20.27     19.56  42.27   \n",
       "2015-01-01 03:00:00     38.41    20.94     NaN     19.17     18.88  38.41   \n",
       "2015-01-01 04:00:00     35.72    18.52     NaN     17.90     18.39  35.72   \n",
       "\n",
       "Country              Sweden  Switzerland  \n",
       "Datetime (UTC)                            \n",
       "2015-01-01 00:00:00   23.37        43.43  \n",
       "2015-01-01 01:00:00   19.33        38.08  \n",
       "2015-01-01 02:00:00   17.66        35.47  \n",
       "2015-01-01 03:00:00   17.53        30.83  \n",
       "2015-01-01 04:00:00   18.07        28.26  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df [['Country','Datetime (UTC)',  'Price (EUR/MWhe)']]\n",
    "df = df.pivot(index='Datetime (UTC)', columns='Country', values='Price (EUR/MWhe)')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "mfQvgSnM3_1v",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mfQvgSnM3_1v",
    "outputId": "9cd1c2f9-c7f7-46d1-df8b-df5c13df26d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country\n",
      "Austria                0\n",
      "Belgium                0\n",
      "Bulgaria           15336\n",
      "Croatia            24096\n",
      "Czechia                0\n",
      "Denmark                0\n",
      "Estonia                0\n",
      "Finland                0\n",
      "France                 0\n",
      "Germany                0\n",
      "Greece                 0\n",
      "Hungary                0\n",
      "Ireland            12480\n",
      "Italy                  0\n",
      "Latvia                 0\n",
      "Lithuania              0\n",
      "Luxembourg             0\n",
      "Netherlands            0\n",
      "North Macedonia    73008\n",
      "Norway                 0\n",
      "Poland                 0\n",
      "Portugal               0\n",
      "Romania                0\n",
      "Serbia             16800\n",
      "Slovakia               0\n",
      "Slovenia               0\n",
      "Spain                  0\n",
      "Sweden                 0\n",
      "Switzerland            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "WObloVqL4aH3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WObloVqL4aH3",
    "outputId": "c1a5702e-1761-4cca-d65c-14966b09d8dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country\n",
      "Austria        0\n",
      "Belgium        0\n",
      "Czechia        0\n",
      "Denmark        0\n",
      "Estonia        0\n",
      "Finland        0\n",
      "France         0\n",
      "Germany        0\n",
      "Greece         0\n",
      "Hungary        0\n",
      "Italy          0\n",
      "Latvia         0\n",
      "Lithuania      0\n",
      "Luxembourg     0\n",
      "Netherlands    0\n",
      "Norway         0\n",
      "Poland         0\n",
      "Portugal       0\n",
      "Romania        0\n",
      "Slovakia       0\n",
      "Slovenia       0\n",
      "Spain          0\n",
      "Sweden         0\n",
      "Switzerland    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(axis=1)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "AB6vyJX-C6h3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AB6vyJX-C6h3",
    "outputId": "aa9990f8-cb44-4367-b4ff-e2a1bf1732d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datetime (UTC)  Austria  Belgium  Czechia  Denmark  Estonia  Finland  \\\n",
      "0  2015-01-01 00:00:00    17.93    34.94    24.20    18.29    23.37    23.37   \n",
      "1  2015-01-01 01:00:00    15.17    32.19    22.06    16.04    19.33    19.33   \n",
      "2  2015-01-01 02:00:00    16.38    28.05    20.27    14.60    17.66    17.66   \n",
      "3  2015-01-01 03:00:00    17.38    28.04    19.17    14.95    17.53    17.53   \n",
      "4  2015-01-01 04:00:00    16.38    34.26    17.90    14.50    18.07    18.07   \n",
      "\n",
      "   France  Germany  Greece  ...  Netherlands  Norway  Poland  Portugal  \\\n",
      "0   34.94    17.93   48.78  ...        34.94   27.36   17.18     48.10   \n",
      "1   32.19    15.17   31.10  ...        32.19   27.24   17.38     47.33   \n",
      "2   23.53    16.38   20.78  ...        28.05   27.16   17.40     42.27   \n",
      "3   22.92    17.38   25.40  ...        28.04   27.15   18.60     38.41   \n",
      "4   34.26    16.38   26.00  ...        34.26   27.30   19.30     35.72   \n",
      "\n",
      "   Romania  Slovakia  Slovenia  Spain  Sweden  Switzerland  \n",
      "0    44.17     24.20     23.25  48.10   23.37        43.43  \n",
      "1    39.17     22.06     22.20  47.33   19.33        38.08  \n",
      "2    26.93     20.27     19.56  42.27   17.66        35.47  \n",
      "3    20.94     19.17     18.88  38.41   17.53        30.83  \n",
      "4    18.52     17.90     18.39  35.72   18.07        28.26  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.columns.name = None\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99211c4c-9b8f-4d60-9bb6-add80102ca5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last time point available: 2024-04-30 23:00:00\n"
     ]
    }
   ],
   "source": [
    "df['Datetime (UTC)'] = pd.to_datetime(df['Datetime (UTC)'])\n",
    "last_time_point = df['Datetime (UTC)'].max()\n",
    "print(\"Last time point available:\", last_time_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9365312-6296-4b97-ace6-9dd9191fccea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Datetime (UTC)  Austria  Belgium  Czechia  Denmark  Estonia  \\\n",
      "64249 2022-05-01 01:00:00   192.20   192.20   192.20   192.20   115.15   \n",
      "64250 2022-05-01 02:00:00   197.43   197.43   197.43   197.43   117.32   \n",
      "64251 2022-05-01 03:00:00   201.32   201.32   201.32   201.32   113.44   \n",
      "64252 2022-05-01 04:00:00   195.00   195.00   195.00   195.00   117.41   \n",
      "64253 2022-05-01 05:00:00   194.95   194.95   194.95   194.95   109.63   \n",
      "...                   ...      ...      ...      ...      ...      ...   \n",
      "81787 2024-04-30 19:00:00    87.82    87.02    88.29    66.05    88.36   \n",
      "81788 2024-04-30 20:00:00    77.50    75.39    77.99    54.09    78.02   \n",
      "81789 2024-04-30 21:00:00    76.10    77.51    75.93    50.98    54.93   \n",
      "81790 2024-04-30 22:00:00    64.22    58.00    67.16    44.71    38.00   \n",
      "81791 2024-04-30 23:00:00    54.89    54.28    56.35    44.18    36.61   \n",
      "\n",
      "       Finland  France  Germany  Greece  ...  Netherlands  Norway  Poland  \\\n",
      "64249   115.15  192.20   192.20  215.85  ...       192.20  127.23  115.15   \n",
      "64250   117.32  197.43   197.43  215.46  ...       197.43  127.92  117.32   \n",
      "64251   113.44  201.32   201.32  215.46  ...       201.32  128.68  113.44   \n",
      "64252   117.41  195.00   195.00  199.52  ...       195.00  125.64  117.41   \n",
      "64253   109.63  194.95   194.95  202.37  ...       194.95  126.10  109.63   \n",
      "...        ...     ...      ...     ...  ...          ...     ...     ...   \n",
      "81787    88.36   83.91    88.37   80.01  ...        88.15   53.42   88.36   \n",
      "81788    78.02   70.98    77.97   77.53  ...        80.00   52.52   83.29   \n",
      "81789    54.93   75.79    75.69   75.97  ...        81.80   50.05   80.97   \n",
      "81790    38.00   35.01    66.81   36.99  ...        76.77   43.80   67.43   \n",
      "81791    36.61   34.99    55.09   34.86  ...        79.89   43.30   74.02   \n",
      "\n",
      "       Portugal  Romania  Slovakia  Slovenia   Spain  Sweden  Switzerland  \n",
      "64249    192.20   192.20    192.20    192.20  192.20   98.51       185.55  \n",
      "64250    197.43   197.43    197.43    197.43  197.43  100.23       183.99  \n",
      "64251    201.32   154.45    201.32    201.32  201.32   97.40       184.35  \n",
      "64252    195.00   195.00    195.00    195.00  195.00  101.77       184.54  \n",
      "64253    194.95   194.95    194.95    194.95  194.95   96.96       188.17  \n",
      "...         ...      ...       ...       ...     ...     ...          ...  \n",
      "81787     83.91    88.08     88.15     88.09   83.91   55.47        88.81  \n",
      "81788     70.98    77.53     77.74     77.19   70.98   52.77        78.03  \n",
      "81789     65.00    75.97     75.94     76.02   65.00   50.05        71.07  \n",
      "81790     35.01    64.74     65.81     62.97   35.01   38.00        57.37  \n",
      "81791     34.99    54.86     55.49     53.86   34.99   36.61        53.04  \n",
      "\n",
      "[17543 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "start_date = '2022-05-01 01:00:00'\n",
    "df = df[df['Datetime (UTC)'] >= pd.to_datetime(start_date)]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "_Jtyfje24Pdq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Jtyfje24Pdq",
    "outputId": "507d28c6-0347-4446-9078-c6fda9ffa9a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Datetime (UTC)  Austria  Belgium  Czechia  Denmark  Estonia  \\\n",
      "64249 2022-05-01 01:00:00   192.20   192.20   192.20   192.20   115.15   \n",
      "64250 2022-05-01 02:00:00   197.43   197.43   197.43   197.43   117.32   \n",
      "64251 2022-05-01 03:00:00   201.32   201.32   201.32   201.32   113.44   \n",
      "64252 2022-05-01 04:00:00   195.00   195.00   195.00   195.00   117.41   \n",
      "64253 2022-05-01 05:00:00   194.95   194.95   194.95   194.95   109.63   \n",
      "\n",
      "       Finland  France  Germany  Greece  ...  Romania  Slovakia  Slovenia  \\\n",
      "64249   115.15  192.20   192.20  215.85  ...   192.20    192.20    192.20   \n",
      "64250   117.32  197.43   197.43  215.46  ...   197.43    197.43    197.43   \n",
      "64251   113.44  201.32   201.32  215.46  ...   154.45    201.32    201.32   \n",
      "64252   117.41  195.00   195.00  199.52  ...   195.00    195.00    195.00   \n",
      "64253   109.63  194.95   194.95  202.37  ...   194.95    194.95    194.95   \n",
      "\n",
      "        Spain  Sweden  Switzerland  month  day  weekday  hour  \n",
      "64249  192.20   98.51       185.55      5    1        6     1  \n",
      "64250  197.43  100.23       183.99      5    1        6     2  \n",
      "64251  201.32   97.40       184.35      5    1        6     3  \n",
      "64252  195.00  101.77       184.54      5    1        6     4  \n",
      "64253  194.95   96.96       188.17      5    1        6     5  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "df['month'] = df['Datetime (UTC)'].apply(lambda row: row.month)\n",
    "df['day'] = df['Datetime (UTC)'].apply(lambda row: row.day)\n",
    "df['weekday'] = df['Datetime (UTC)'].apply(lambda row: row.weekday())\n",
    "df['hour'] = df['Datetime (UTC)'].apply(lambda row: row.hour)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80mxqDAh5Mwd",
   "metadata": {
    "id": "80mxqDAh5Mwd"
   },
   "outputs": [],
   "source": [
    "# separating the electricity prices and timestamp features\n",
    "electricity_prices_df = df[['Datetime (UTC)', 'Austria', 'Belgium', 'Czechia', 'Denmark', 'Estonia', 'Finland', 'France',\n",
    "              'Germany', 'Greece', 'Hungary', 'Italy', 'Latvia', 'Lithuania', 'Luxembourg',\n",
    "             'Netherlands', 'Norway', 'Poland', 'Portugal', 'Romania', 'Slovakia',\n",
    "             'Slovenia', 'Spain', 'Sweden', 'Switzerland']]\n",
    "timestamp_features_df = df[['Datetime (UTC)', 'month', 'day', 'weekday', 'hour']]\n",
    "\n",
    "# defining the split ratio\n",
    "train_size = 0.8\n",
    "train_size_electricity = int(len(electricity_prices_df) * train_size)\n",
    "train_size_timestamp = int(len(timestamp_features_df) * train_size)\n",
    "\n",
    "# spliting the data into train and test sets\n",
    "electricity_prices_train = electricity_prices_df[:train_size_electricity]\n",
    "electricity_prices_test = electricity_prices_df[train_size_electricity:]\n",
    "timestamp_features_train = timestamp_features_df[:train_size_timestamp]\n",
    "timestamp_features_test = timestamp_features_df[train_size_timestamp:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95180c89-5259-40f8-af8b-e90241aa8864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Datetime (UTC)  Austria  Belgium  Czechia  Denmark  Estonia  \\\n",
      "64249 2022-05-01 01:00:00   192.20   192.20   192.20   192.20   115.15   \n",
      "64250 2022-05-01 02:00:00   197.43   197.43   197.43   197.43   117.32   \n",
      "64251 2022-05-01 03:00:00   201.32   201.32   201.32   201.32   113.44   \n",
      "64252 2022-05-01 04:00:00   195.00   195.00   195.00   195.00   117.41   \n",
      "64253 2022-05-01 05:00:00   194.95   194.95   194.95   194.95   109.63   \n",
      "\n",
      "       Finland  France  Germany  Greece  ...  Netherlands  Norway  Poland  \\\n",
      "64249   115.15  192.20   192.20  215.85  ...       192.20  127.23  115.15   \n",
      "64250   117.32  197.43   197.43  215.46  ...       197.43  127.92  117.32   \n",
      "64251   113.44  201.32   201.32  215.46  ...       201.32  128.68  113.44   \n",
      "64252   117.41  195.00   195.00  199.52  ...       195.00  125.64  117.41   \n",
      "64253   109.63  194.95   194.95  202.37  ...       194.95  126.10  109.63   \n",
      "\n",
      "       Portugal  Romania  Slovakia  Slovenia   Spain  Sweden  Switzerland  \n",
      "64249    192.20   192.20    192.20    192.20  192.20   98.51       185.55  \n",
      "64250    197.43   197.43    197.43    197.43  197.43  100.23       183.99  \n",
      "64251    201.32   154.45    201.32    201.32  201.32   97.40       184.35  \n",
      "64252    195.00   195.00    195.00    195.00  195.00  101.77       184.54  \n",
      "64253    194.95   194.95    194.95    194.95  194.95   96.96       188.17  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "print(electricity_prices_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a2c3f05-460c-4d80-868e-48ff8f5cfd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#country_names = electricity_prices_train.drop(columns=['Datetime (UTC)']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4oRyT6un5WWm",
   "metadata": {
    "id": "4oRyT6un5WWm"
   },
   "outputs": [],
   "source": [
    "# rescaling the electricity prices\n",
    "scaler = StandardScaler()\n",
    "\n",
    "electricity_prices_train_scaled = scaler.fit_transform(electricity_prices_train.drop(columns=['Datetime (UTC)']))\n",
    "electricity_prices_test_scaled = scaler.transform(electricity_prices_test.drop(columns=['Datetime (UTC)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07d72a8e-4df2-4255-bdb3-3353426389cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06589643,  0.17649131,  0.12996246, ...,  1.55917589,\n",
       "         0.12128199, -0.0354501 ],\n",
       "       [ 0.10332711,  0.21675176,  0.16951748, ...,  1.65944201,\n",
       "         0.13893364, -0.0469631 ],\n",
       "       [ 0.13116752,  0.24669692,  0.19893795, ...,  1.73401854,\n",
       "         0.10989052, -0.04430625],\n",
       "       ...,\n",
       "       [-0.03523082,  0.06771879,  0.02309584, ...,  0.06572825,\n",
       "         0.93777311, -0.0127193 ],\n",
       "       [-0.12676781, -0.03073843, -0.07363623, ...,  0.19168398,\n",
       "         0.80651467, -0.06799647],\n",
       "       [-0.2366265 , -0.14890249, -0.18972984, ...,  0.28926612,\n",
       "         0.64898402, -0.2291785 ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electricity_prices_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "407a011b-3187-4e94-9c3a-e36c17253639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length, pred_length, label_length, curr_model):\n",
    "    seq_x = [] # storing for input seqiences\n",
    "    seq_y = [] # storing for output seqiences\n",
    "    for i in range(len(data) - seq_length - pred_length):\n",
    "        seq_x.append(data[i:i+seq_length])\n",
    "        if curr_model in [\"basis_former\", \"itransformer\", \"nonstat_tran\"]:\n",
    "          seq_y.append(data[i+seq_length-label_length:i+seq_length+pred_length])\n",
    "        else: ## only chronos\n",
    "          seq_y.append(data[i+seq_length:i+seq_length+pred_length])\n",
    "    return np.array(seq_x), np.array(seq_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c17fd64-77c4-42ab-9e63-bf919d801d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(seq_x, seq_y, seq_x_mark, seq_y_mark, batch_size, curr_model):\n",
    "    seq_x = torch.tensor(seq_x, dtype=torch.float32)\n",
    "    seq_y = torch.tensor(seq_y, dtype=torch.float32)\n",
    "    seq_x_mark = torch.tensor(seq_x_mark, dtype=torch.float32)\n",
    "    seq_y_mark = torch.tensor(seq_y_mark, dtype=torch.float32)\n",
    "    \n",
    "    # index for each sequence\n",
    "    if curr_model == \"basis_former\" :\n",
    "      indices = []\n",
    "      for i in range(len(seq_x)):\n",
    "          index_list = np.arange(i, i + len(seq_x[0]) + len(seq_y[0]), 1)\n",
    "          norm_index = index_list / len(seq_x) \n",
    "          indices.append(norm_index)\n",
    "      indices = torch.tensor(indices, dtype=torch.float32)\n",
    "      dataset = TensorDataset(seq_x, seq_y, seq_x_mark, seq_y_mark, indices) #### indices specific to Basisformer\n",
    "    else :\n",
    "      dataset = TensorDataset(seq_x, seq_y, seq_x_mark, seq_y_mark)\n",
    "    if curr_model == \"chronos\":\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
    "    else :\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=2, shuffle=True)\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ded9c3f-9b9c-48cc-8130-762d94b62f32",
   "metadata": {},
   "source": [
    "# Chronos\n",
    "\n",
    "zero shot evaluation with Chronos Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2617ec8b-f710-450b-81b1-1f8ce6f4fba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install git+https://github.com/amazon-science/chronos-forecasting.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da473f90-664c-449e-9396-dc9d8adf3ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "seq_length = 168 # one week\n",
    "pred_length = 48 # two days ahead\n",
    "label_length = 48\n",
    "curr_model = \"chronos\"\n",
    "\n",
    "train_seq_x, train_seq_y = create_sequences(electricity_prices_train_scaled, seq_length, pred_length, label_length, curr_model)\n",
    "train_seq_x_mark, train_seq_y_mark = create_sequences(timestamp_features_train.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "\n",
    "test_seq_x, test_seq_y = create_sequences(electricity_prices_test_scaled, seq_length, pred_length,label_length, curr_model)\n",
    "test_seq_x_mark, test_seq_y_mark = create_sequences(timestamp_features_test.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "\n",
    "# converting sequences to PyTorch DataLoader objects\n",
    "train_loader = create_dataloader(train_seq_x, train_seq_y, train_seq_x_mark, train_seq_y_mark, batch_size, curr_model)\n",
    "test_loader = create_dataloader(test_seq_x, test_seq_y, test_seq_x_mark, test_seq_y_mark, batch_size, curr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99270086-7efc-4968-9720-98413902bdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample testing sequence x: [[-0.37990801 -0.30301613 -0.34114313 ...  0.36499292  0.41119997\n",
      "  -0.40733483]\n",
      " [-0.48175095 -0.41255844 -0.44876606 ...  0.09218471  0.25592708\n",
      "  -0.51287069]\n",
      " [-0.54151122 -0.47683661 -0.51191796 ... -0.06789601  0.17885508\n",
      "  -0.55633965]\n",
      " ...\n",
      " [-0.47953231 -0.45720675 -0.45360644 ... -0.69000609  0.27696538\n",
      "  -0.59110006]\n",
      " [-0.50501094 -0.4921556  -0.48317817 ... -0.59184882  0.22513933\n",
      "  -0.59397831]\n",
      " [-0.52984544 -0.51809781 -0.50942213 ... -0.4403952   0.16130607\n",
      "  -0.63087896]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample testing sequence x:\", test_seq_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22e68564-a944-4a6f-b55d-9230a32c9a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch shape: torch.Size([16, 168, 24])\n",
      "Output batch shape: torch.Size([16, 48, 24])\n",
      "Input mark shape: torch.Size([16, 168, 4])\n",
      "Output mark shape: torch.Size([16, 48, 4])\n"
     ]
    }
   ],
   "source": [
    "# Check the dimensions\n",
    "for batch in test_loader:\n",
    "    batch_x, batch_y, batch_x_mark, batch_y_mark = batch\n",
    "    print(f'Input batch shape: {batch_x.shape}')\n",
    "    print(f'Output batch shape: {batch_y.shape}')\n",
    "    print(f'Input mark shape: {batch_x_mark.shape}')\n",
    "    print(f'Output mark shape: {batch_y_mark.shape}')\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0297963a-162b-417c-9d36-eff09e474633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Get forecasts for the given time series.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        context\n",
      "            Input series. This is either a 1D tensor, or a list\n",
      "            of 1D tensors, or a 2D tensor whose first dimension\n",
      "            is batch. In the latter case, use left-padding with\n",
      "            ``torch.nan`` to align series of different lengths.\n",
      "        prediction_length\n",
      "            Time steps to predict. Defaults to what specified\n",
      "            in ``self.model.config``.\n",
      "        num_samples\n",
      "            Number of sample paths to predict. Defaults to what\n",
      "            specified in ``self.model.config``.\n",
      "        temperature\n",
      "            Temperature to use for generating sample tokens.\n",
      "            Defaults to what specified in ``self.model.config``.\n",
      "        top_k\n",
      "            Top-k parameter to use for generating sample tokens.\n",
      "            Defaults to what specified in ``self.model.config``.\n",
      "        top_p\n",
      "            Top-p parameter to use for generating sample tokens.\n",
      "            Defaults to what specified in ``self.model.config``.\n",
      "        limit_prediction_length\n",
      "            Force prediction length smaller or equal than the\n",
      "            built-in prediction length from the model. True by\n",
      "            default. When true, fail loudly if longer predictions\n",
      "            are requested, otherwise longer predictions are allowed.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        samples\n",
      "            Tensor of sample forecasts, of shape\n",
      "            (batch_size, num_samples, prediction_length).\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(ChronosPipeline.predict.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d7a7e22-51e5-4c3c-b3f2-d51498587192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[-0.9287, -1.1369, -0.9066,  ..., -2.1256, -0.4122, -0.9932],\n",
      "         [-0.9440, -1.1247, -0.9323,  ..., -2.1256, -0.4039, -0.9895],\n",
      "         [-0.8577, -1.1384, -0.8715,  ..., -2.1256, -0.4044, -0.9365],\n",
      "         ...,\n",
      "         [-0.8039, -0.8729, -0.7576,  ..., -1.6699, -0.8470, -0.8752],\n",
      "         [-0.8430, -0.9175, -0.8005,  ..., -1.8309, -0.8471, -0.8960],\n",
      "         [-0.8710, -0.9417, -0.8292,  ..., -1.8859, -0.8448, -0.9079]],\n",
      "\n",
      "        [[-0.7364, -0.5648, -0.7773,  ..., -0.3054, -0.3476, -0.7666],\n",
      "         [-0.7675, -0.5431, -0.8590,  ...,  0.7580, -0.3769, -0.7782],\n",
      "         [-0.8305, -0.5681, -0.8749,  ...,  0.7917, -0.4568, -0.8296],\n",
      "         ...,\n",
      "         [-0.7219, -0.7701, -0.6564,  ..., -0.8804, -0.7223, -0.8148],\n",
      "         [-0.6875, -0.7470, -0.6430,  ..., -0.8553, -0.7157, -0.8079],\n",
      "         [-0.6006, -0.6798, -0.5870,  ..., -0.6494, -0.7186, -0.7851]],\n",
      "\n",
      "        [[-0.6733, -0.6095, -0.5492,  ..., -0.3486, -0.5502, -0.8015],\n",
      "         [-0.7210, -0.6360, -0.5595,  ..., -0.4642, -0.5524, -0.8152],\n",
      "         [-0.7446, -0.7311, -0.7039,  ..., -0.7629, -0.5645, -0.8106],\n",
      "         ...,\n",
      "         [-0.8798, -0.8407, -0.8694,  ..., -0.9741, -0.8908, -0.9063],\n",
      "         [-0.7161, -0.6846, -0.6773,  ..., -0.5792, -0.8290, -0.8214],\n",
      "         [-0.6318, -0.6063, -0.6052,  ..., -0.4251, -0.6930, -0.7718]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.8437, -0.9943, -0.6703,  ..., -2.1254, -0.3555, -0.9239],\n",
      "         [-0.8087, -1.0108, -0.6965,  ..., -2.0632, -0.3942, -0.9650],\n",
      "         [-0.8845, -1.0456, -0.8121,  ..., -1.9722, -0.4277, -1.0027],\n",
      "         ...,\n",
      "         [-1.4437, -1.4500, -1.4713,  ..., -2.1332, -0.9930, -1.5037],\n",
      "         [-1.3091, -1.3041, -1.3263,  ..., -2.1271, -0.8692, -1.3326],\n",
      "         [-1.0487, -1.1919, -1.0261,  ..., -2.1256, -0.6470, -0.9397]],\n",
      "\n",
      "        [[-0.7139, -0.6876, -0.6894,  ..., -1.7799, -0.0995, -0.7541],\n",
      "         [-0.7374, -0.7202, -0.7126,  ..., -2.0642, -0.2977, -0.8056],\n",
      "         [-0.7587, -0.7152, -0.7404,  ..., -2.0642, -0.2622, -0.8331],\n",
      "         ...,\n",
      "         [-0.8305, -0.5681, -0.8749,  ...,  0.7917, -0.4568, -0.8296],\n",
      "         [-0.9039, -0.6609, -0.9585,  ..., -0.1509, -0.4788, -0.8439],\n",
      "         [-0.9363, -0.6279, -0.9718,  ..., -0.4377, -0.4586, -0.8439]],\n",
      "\n",
      "        [[-0.7602, -0.7114, -0.7431,  ..., -0.6528, -0.2402, -0.8362],\n",
      "         [-0.8035, -0.7587, -0.7888,  ..., -0.7834, -0.2701, -0.8818],\n",
      "         [-0.8202, -0.7766, -0.8064,  ..., -1.0339, -0.3097, -0.8967],\n",
      "         ...,\n",
      "         [-0.8215, -0.8870, -0.7879,  ..., -1.3357, -0.4097, -0.8877],\n",
      "         [-0.8001, -0.8196, -0.7701,  ..., -1.1294, -0.4138, -0.8787],\n",
      "         [-0.8080, -0.7759, -0.7909,  ..., -0.9003, -0.4470, -0.8877]]]), tensor([[[-0.8697, -0.9522, -0.8261,  ..., -1.8967, -0.8391, -0.9149],\n",
      "         [-0.8536, -0.9951, -0.8140,  ..., -1.8861, -0.7300, -0.9160],\n",
      "         [-0.7976, -0.9853, -0.7482,  ..., -1.8010, -0.6074, -0.8693],\n",
      "         ...,\n",
      "         [-1.0844, -1.2845, -1.3016,  ..., -2.0146, -0.8853, -1.2225],\n",
      "         [-1.3090, -1.2904, -1.3082,  ..., -2.0730, -0.8812, -1.3211],\n",
      "         [-1.2714, -1.2937, -1.3140,  ..., -2.0932, -0.8803, -1.3211]],\n",
      "\n",
      "        [[-0.5861, -0.6159, -0.5674,  ..., -0.3810, -0.7832, -0.7533],\n",
      "         [-0.6875, -0.6792, -0.5009,  ...,  0.1648, -0.8541, -0.7717],\n",
      "         [-0.7160, -0.7429, -0.4917,  ...,  1.1019, -0.8897, -0.8068],\n",
      "         ...,\n",
      "         [-0.7436, -0.8429, -0.4871,  ..., -1.0537, -0.6537, -0.7947],\n",
      "         [-0.7085, -0.8053, -0.4917,  ..., -1.0615, -0.6739, -0.7620],\n",
      "         [-0.6748, -0.7538, -0.4917,  ..., -0.7653, -0.6767, -0.7701]],\n",
      "\n",
      "        [[-0.5958, -0.5393, -0.5714,  ..., -0.2226, -0.6787, -0.7081],\n",
      "         [-0.6771, -0.6226, -0.6552,  ..., -0.4310, -0.5768, -0.7712],\n",
      "         [-0.7450, -0.6957, -0.7269,  ..., -0.6129, -0.4429, -0.8208],\n",
      "         ...,\n",
      "         [-0.7777, -0.7341, -0.7672,  ..., -0.7067, -0.6907, -0.8524],\n",
      "         [-0.6948, -0.6520, -0.6810,  ..., -0.5067, -0.6354, -0.7974],\n",
      "         [-0.5586, -0.5393, -0.5127,  ..., -0.3371, -0.3821, -0.6729]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.9047, -1.0878, -0.7547,  ..., -2.0632, -0.5888, -0.8259],\n",
      "         [-0.8583, -1.0098, -0.7628,  ..., -1.6470, -0.6079, -0.8115],\n",
      "         [-0.9515, -1.0345, -0.9096,  ..., -1.4546, -0.6107, -0.9705],\n",
      "         ...,\n",
      "         [-0.9262, -1.2848, -0.6449,  ..., -2.1447, -0.5245, -0.9465],\n",
      "         [-0.8236, -1.0968, -0.5955,  ..., -2.1273, -0.4249, -0.9066],\n",
      "         [-0.7952, -0.9388, -0.6814,  ..., -2.1256, -0.3903, -0.9116]],\n",
      "\n",
      "        [[-0.9518, -0.5899, -0.9870,  ..., -0.6904, -0.4943, -0.8469],\n",
      "         [-0.9501, -0.7350, -0.9638,  ..., -0.8800, -0.4398, -0.8729],\n",
      "         [-0.9538, -0.7772, -0.9636,  ..., -0.9651, -0.4384, -0.8722],\n",
      "         ...,\n",
      "         [-0.7544, -0.5574, -0.7606,  ...,  0.0038, -0.6066, -0.7822],\n",
      "         [-0.8073, -0.7257, -0.8033,  ..., -0.3426, -0.6253, -0.8065],\n",
      "         [-0.8503, -0.6498, -0.8555,  ..., -0.6881, -0.6394, -0.8266]],\n",
      "\n",
      "        [[-0.8465, -0.8049, -0.8343,  ..., -0.8850, -0.4755, -0.9223],\n",
      "         [-0.8815, -0.8425, -0.8712,  ..., -0.9785, -0.4470, -0.9639],\n",
      "         [-0.8994, -0.8617, -0.8901,  ..., -1.0265, -0.4306, -0.9659],\n",
      "         ...,\n",
      "         [-0.7693, -0.7948, -0.7387,  ..., -1.3000, -0.2274, -0.8800],\n",
      "         [-0.7529, -0.7520, -0.7314,  ..., -0.7329, -0.2416, -0.8265],\n",
      "         [-0.7443, -0.7233, -0.7184,  ..., -0.6793, -0.3367, -0.8433]]]), tensor([[[ 4.,  5.,  4.,  1.],\n",
      "         [ 4.,  5.,  4.,  2.],\n",
      "         [ 4.,  5.,  4.,  3.],\n",
      "         ...,\n",
      "         [ 4., 11.,  3., 22.],\n",
      "         [ 4., 11.,  3., 23.],\n",
      "         [ 4., 12.,  4.,  0.]],\n",
      "\n",
      "        [[ 1., 24.,  2., 17.],\n",
      "         [ 1., 24.,  2., 18.],\n",
      "         [ 1., 24.,  2., 19.],\n",
      "         ...,\n",
      "         [ 1., 31.,  2., 14.],\n",
      "         [ 1., 31.,  2., 15.],\n",
      "         [ 1., 31.,  2., 16.]],\n",
      "\n",
      "        [[ 1., 22.,  0.,  7.],\n",
      "         [ 1., 22.,  0.,  8.],\n",
      "         [ 1., 22.,  0.,  9.],\n",
      "         ...,\n",
      "         [ 1., 29.,  0.,  4.],\n",
      "         [ 1., 29.,  0.,  5.],\n",
      "         [ 1., 29.,  0.,  6.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.,  6.,  5., 17.],\n",
      "         [ 4.,  6.,  5., 18.],\n",
      "         [ 4.,  6.,  5., 19.],\n",
      "         ...,\n",
      "         [ 4., 13.,  5., 14.],\n",
      "         [ 4., 13.,  5., 15.],\n",
      "         [ 4., 13.,  5., 16.]],\n",
      "\n",
      "        [[ 1., 17.,  2., 22.],\n",
      "         [ 1., 17.,  2., 23.],\n",
      "         [ 1., 18.,  3.,  0.],\n",
      "         ...,\n",
      "         [ 1., 24.,  2., 19.],\n",
      "         [ 1., 24.,  2., 20.],\n",
      "         [ 1., 24.,  2., 21.]],\n",
      "\n",
      "        [[ 2., 11.,  6., 19.],\n",
      "         [ 2., 11.,  6., 20.],\n",
      "         [ 2., 11.,  6., 21.],\n",
      "         ...,\n",
      "         [ 2., 18.,  6., 16.],\n",
      "         [ 2., 18.,  6., 17.],\n",
      "         [ 2., 18.,  6., 18.]]]), tensor([[[ 4., 12.,  4.,  1.],\n",
      "         [ 4., 12.,  4.,  2.],\n",
      "         [ 4., 12.,  4.,  3.],\n",
      "         ...,\n",
      "         [ 4., 13.,  5., 22.],\n",
      "         [ 4., 13.,  5., 23.],\n",
      "         [ 4., 14.,  6.,  0.]],\n",
      "\n",
      "        [[ 1., 31.,  2., 17.],\n",
      "         [ 1., 31.,  2., 18.],\n",
      "         [ 1., 31.,  2., 19.],\n",
      "         ...,\n",
      "         [ 2.,  2.,  4., 14.],\n",
      "         [ 2.,  2.,  4., 15.],\n",
      "         [ 2.,  2.,  4., 16.]],\n",
      "\n",
      "        [[ 1., 29.,  0.,  7.],\n",
      "         [ 1., 29.,  0.,  8.],\n",
      "         [ 1., 29.,  0.,  9.],\n",
      "         ...,\n",
      "         [ 1., 31.,  2.,  4.],\n",
      "         [ 1., 31.,  2.,  5.],\n",
      "         [ 1., 31.,  2.,  6.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4., 13.,  5., 17.],\n",
      "         [ 4., 13.,  5., 18.],\n",
      "         [ 4., 13.,  5., 19.],\n",
      "         ...,\n",
      "         [ 4., 15.,  0., 14.],\n",
      "         [ 4., 15.,  0., 15.],\n",
      "         [ 4., 15.,  0., 16.]],\n",
      "\n",
      "        [[ 1., 24.,  2., 22.],\n",
      "         [ 1., 24.,  2., 23.],\n",
      "         [ 1., 25.,  3.,  0.],\n",
      "         ...,\n",
      "         [ 1., 26.,  4., 19.],\n",
      "         [ 1., 26.,  4., 20.],\n",
      "         [ 1., 26.,  4., 21.]],\n",
      "\n",
      "        [[ 2., 18.,  6., 19.],\n",
      "         [ 2., 18.,  6., 20.],\n",
      "         [ 2., 18.,  6., 21.],\n",
      "         ...,\n",
      "         [ 2., 20.,  1., 16.],\n",
      "         [ 2., 20.,  1., 17.],\n",
      "         [ 2., 20.,  1., 18.]]])]\n"
     ]
    }
   ],
   "source": [
    "for batch in test_loader:\n",
    "    print(batch)\n",
    "    break  # Print only the first batch and break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bd82e9-d24f-4a39-9a5c-77821d6b2667",
   "metadata": {},
   "source": [
    "1. Pad Sequences to the Same Length: Ensure all sequences within a batch have the same length.\n",
    "2. Flatten the Padded Sequences: Convert the 3D tensor [batch_size, seq_length, num_features] to a 2D tensor [total_sequences, seq_length * num_features]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4fd1366b-cc21-4f51-8478-daa1b37c0ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ekaterinabasova/miniconda3/envs/basisformer_x86_env/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3280, 4032])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-small\",\n",
    "    device_map=\"cpu\",\n",
    "    torch_dtype=torch.bfloat16,  # Change to torch.float16 if necessary\n",
    ")\n",
    "\n",
    "\n",
    "# padding sequences within a batch\n",
    "def pad_sequence(sequences, batch_first=True, padding_value=torch.nan):\n",
    "    return torch.nn.utils.rnn.pad_sequence(sequences, batch_first=batch_first, padding_value=padding_value)\n",
    "\n",
    "def pad_batch(batch):\n",
    "    input_ids = batch[0]\n",
    "    sequences = [input_ids[i] for i in range(input_ids.size(0))]\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True)\n",
    "    return padded_sequences\n",
    "\n",
    "context = []\n",
    "\n",
    "# Iterate over the DataLoader to extract and pad input_ids\n",
    "for batch in test_loader:\n",
    "    input_ids_padded = pad_batch(batch)\n",
    "    context.append(input_ids_padded)\n",
    "\n",
    "# Concatenate the padded tensors to form a 3D tensor\n",
    "context_tensor_3d = torch.cat(context, dim=0)  # Concatenate along the batch dimension\n",
    "\n",
    "# Flatten the 3D tensor to 2D\n",
    "batch_size, seq_length, num_features = context_tensor_3d.shape\n",
    "context_tensor_2d = context_tensor_3d.view(batch_size, -1)\n",
    "\n",
    "# Now you can use the context tensor with your pipeline\n",
    "print(context_tensor_2d.shape)  # To verify the shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fb6121-1efc-4234-91af-39611924149f",
   "metadata": {},
   "source": [
    "This transformation suggests that each batch of size 24 (sequences) with 96 time steps and 24 features per time step has been flattened into a single 2D tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47829b56-b79b-4efe-9eba-2bfbbad6fea6",
   "metadata": {},
   "source": [
    "Original Shape:\n",
    "Batch size: 24\n",
    "Sequence length: 96\n",
    "Number of features: 24\n",
    "\n",
    "Flattened Shape Calculation:\n",
    "Flattened feature size: 96×24=2304\n",
    "Total number of sequences (batches) after concatenation: 16200\n",
    "\n",
    "\n",
    "The pipeline will process each of these 16,200 sequences, each with 2,304 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632d0df2-a154-46ec-9987-8bba8f396338",
   "metadata": {},
   "outputs": [],
   "source": [
    "del context\n",
    "del context_tensor_3d\n",
    "\n",
    "# predictions\n",
    "#forecast = pipeline.predict(\n",
    " #   context=context_tensor_2d,\n",
    "  #  prediction_length=48,\n",
    "   # num_samples=1,\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bdff46-6b95-4a9a-a10f-7bf9abb74261",
   "metadata": {},
   "source": [
    "# BasisFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ILk9LX4k5Yuu",
   "metadata": {
    "id": "ILk9LX4k5Yuu"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m label_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m48\u001b[39m\n\u001b[1;32m      4\u001b[0m curr_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbasis_former\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m train_seq_x, train_seq_y \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_sequences\u001b[49m(electricity_prices_train_scaled, seq_length, pred_length, label_length, curr_model)\n\u001b[1;32m      7\u001b[0m train_seq_x_mark, train_seq_y_mark \u001b[38;5;241m=\u001b[39m create_sequences(timestamp_features_train\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatetime (UTC)\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mvalues, seq_length, pred_length, label_length, curr_model)\n\u001b[1;32m     10\u001b[0m test_seq_x, test_seq_y \u001b[38;5;241m=\u001b[39m create_sequences(electricity_prices_test_scaled, seq_length, pred_length,label_length, curr_model)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_sequences' is not defined"
     ]
    }
   ],
   "source": [
    "seq_length = 96\n",
    "pred_length = 48\n",
    "label_length = 48\n",
    "curr_model = \"basis_former\"\n",
    "\n",
    "train_seq_x, train_seq_y = create_sequences(electricity_prices_train_scaled, seq_length, pred_length, label_length, curr_model)\n",
    "train_seq_x_mark, train_seq_y_mark = create_sequences(timestamp_features_train.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "\n",
    "test_seq_x, test_seq_y = create_sequences(electricity_prices_test_scaled, seq_length, pred_length,label_length, curr_model)\n",
    "test_seq_x_mark, test_seq_y_mark = create_sequences(timestamp_features_test.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IeE-jvzOEVw-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IeE-jvzOEVw-",
    "outputId": "d4778504-79d4-475b-c868-17b3994fd3fc"
   },
   "outputs": [],
   "source": [
    "print(\"Sample training sequence x:\", train_seq_x[0])\n",
    "print(\"Sample training sequence y:\", train_seq_y[0])\n",
    "print(\"Sample training sequence x mark:\", train_seq_x_mark[0])\n",
    "print(\"Sample training sequence y mark:\", train_seq_y_mark[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "OrL7qSyl5bqB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OrL7qSyl5bqB",
    "outputId": "01496ef4-4d84-4630-dc4b-5a1b9c36a404"
   },
   "outputs": [],
   "source": [
    "batch_size = 24\n",
    "\n",
    "# converting sequences to PyTorch DataLoader objects\n",
    "train_loader = create_dataloader(train_seq_x, train_seq_y, train_seq_x_mark, train_seq_y_mark, batch_size, curr_model)\n",
    "test_loader = create_dataloader(test_seq_x, test_seq_y, test_seq_x_mark, test_seq_y_mark, batch_size, curr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "912d3153-8549-47e5-856f-01fbd4258dd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Check the dimensions\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m----> 3\u001b[0m     batch_x, batch_y, batch_x_mark, batch_y_mark \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput batch shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_x\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput batch shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_y\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "# Check the dimensions\n",
    "for batch in test_loader:\n",
    "    batch_x, batch_y, batch_x_mark, batch_y_mark = batch\n",
    "    print(f'Input batch shape: {batch_x.shape}')\n",
    "    print(f'Output batch shape: {batch_y.shape}')\n",
    "    print(f'Input mark shape: {batch_x_mark.shape}')\n",
    "    print(f'Output mark shape: {batch_y_mark.shape}')\n",
    "    break  # Just check the first batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PB2mLPXVPBAU",
   "metadata": {
    "id": "PB2mLPXVPBAU"
   },
   "source": [
    "Model utils abd definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5463becb-cf31-487b-96c1-8f862a13d02a",
   "metadata": {
    "id": "5463becb-cf31-487b-96c1-8f862a13d02a"
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "# In PyTorch, all neural network models and layers are subclasses of torch.nn.Module.\n",
    "# The <Module> class is the base class for all neural network modules,\n",
    "# and it provides a blueprint for defining custom layers and models.\n",
    "\n",
    "# The <forward> method defines the forward pass of the network,\n",
    "# which is the process of passing input data through the layers of the network to compute the output.\n",
    "# This is where the actual computation (such as matrix multiplication, activation functions, etc.) is defined.\n",
    "####################################\n",
    "\n",
    "\n",
    "\n",
    "#This class defines a two-layer MLP with a skip connection and ReLU activations.\n",
    "#It reduces the input dimension, processes it, and then expands it back\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,input_len,output_len):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Sequential(\n",
    "            wn(nn.Linear(input_len, output_len)),\n",
    "            nn.ReLU(),\n",
    "            wn(nn.Linear(output_len,output_len))\n",
    "        )\n",
    "\n",
    "        self.linear2 = nn.Sequential(\n",
    "            wn(nn.Linear(output_len, output_len)),\n",
    "            nn.ReLU(),\n",
    "            wn(nn.Linear(output_len, output_len))\n",
    "        )\n",
    "\n",
    "        self.skip = wn(nn.Linear(input_len, output_len))\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.act(self.linear1(x)+self.skip(x))\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class MLP_bottle(nn.Module):\n",
    "    def __init__(self,input_len,output_len,bottleneck,bias=True):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Sequential(\n",
    "            wn(nn.Linear(input_len, bottleneck,bias=bias)),\n",
    "            nn.ReLU(),\n",
    "            wn(nn.Linear(bottleneck,bottleneck,bias=bias))\n",
    "        )\n",
    "\n",
    "        self.linear2 = nn.Sequential(\n",
    "            wn(nn.Linear(bottleneck, bottleneck)),\n",
    "            nn.ReLU(),\n",
    "            wn(nn.Linear(bottleneck, output_len))\n",
    "        )\n",
    "\n",
    "        self.skip = wn(nn.Linear(input_len, bottleneck,bias=bias))\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.act(self.linear1(x)+self.skip(x))\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "#This layer calculates the attention scores between queries, keys, and values using multi-head attention.\n",
    "#This class implements multi-head attention using linear projections and softmax to compute attention score\n",
    "#It is essential for capturing dependencies between different parts of the input sequence.\n",
    "\n",
    "class channel_AutoCorrelationLayer(nn.Module):\n",
    "    def __init__(self,d_model,n_heads, mask=False,d_keys=None,\n",
    "                 d_values=None,dropout=0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mask = mask\n",
    "\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "        d_values = d_values or (d_model // n_heads)\n",
    "\n",
    "        self.query_projection = wn(nn.Linear(d_model,d_keys * n_heads))\n",
    "        self.key_projection = wn(nn.Linear(d_model, d_keys * n_heads))\n",
    "        self.value_projection = wn(nn.Linear(d_model, d_values * n_heads))\n",
    "        self.out_projection = wn(nn.Linear(d_values * n_heads, d_model))\n",
    "        self.n_heads = n_heads\n",
    "        self.scale = d_keys ** -0.5\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        num = len(queries.shape)\n",
    "        if num == 2:\n",
    "            L, _ = queries.shape\n",
    "            S, _ = keys.shape\n",
    "            H = self.n_heads\n",
    "\n",
    "            queries = self.query_projection(queries).view(L, H, -1).permute(1,0,2)\n",
    "            keys = self.key_projection(keys).view(S, H, -1).permute(1,0,2)\n",
    "            values = self.value_projection(values).view(S, H, -1).permute(1,0,2)\n",
    "            # queries = queries.view(L, H, -1).permute(1,0,2)\n",
    "            # keys = keys.view(S, H, -1).permute(1,0,2)\n",
    "            # values = values.view(S, H, -1).permute(1,0,2)\n",
    "\n",
    "            dots = torch.matmul(queries, keys.transpose(-1, -2)) * self.scale\n",
    "\n",
    "            attn = self.attend(dots)\n",
    "            attn = self.dropout(attn)\n",
    "\n",
    "            out = torch.matmul(attn, values)    #(H,L,D)\n",
    "\n",
    "            out = out.permute(1,0,2).reshape(L,-1)\n",
    "        else:\n",
    "            B,L, _ = queries.shape\n",
    "            B,S, _ = keys.shape\n",
    "            H = self.n_heads\n",
    "\n",
    "            queries = self.query_projection(queries).view(B,L, H, -1).permute(0,2,1,3)\n",
    "            keys = self.key_projection(keys).view(B,S, H, -1).permute(0,2,1,3)\n",
    "            values = self.value_projection(values).view(B,S, H, -1).permute(0,2,1,3)\n",
    "\n",
    "            dots = torch.matmul(queries, keys.transpose(-1, -2)) * self.scale\n",
    "\n",
    "            attn = self.attend(dots)\n",
    "\n",
    "            attn = self.dropout(attn)\n",
    "\n",
    "            out = torch.matmul(attn, values)    #(H,L,D)\n",
    "\n",
    "            out = out.permute(0,2,1,3).reshape(B,L,-1)\n",
    "\n",
    "        return self.out_projection(out),attn\n",
    "\n",
    "\n",
    "\n",
    "# BCAB combines attention mechanisms and feed-forward networks to process both the basis functions and the input time series\n",
    "# BCAB applies cross-attention to both the basis functions and the time series,\n",
    "# followed by feed-forward networks and normalization.\n",
    "\n",
    "class BCAB(nn.Module):\n",
    "    def __init__(self, d_model,heads=8,index=0,d_ff=None,\n",
    "                     dropout=0.1, activation=\"relu\"):\n",
    "        super().__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.cross_attention_basis = channel_AutoCorrelationLayer(d_model,heads,dropout=dropout)\n",
    "        self.conv1_basis = wn(nn.Linear(d_model,d_ff))\n",
    "        self.conv2_basis = wn(nn.Linear(d_ff,d_model))\n",
    "\n",
    "        self.dropout_basis = nn.Dropout(dropout)\n",
    "        self.activation_basis = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "        self.cross_attention_ts = channel_AutoCorrelationLayer(d_model,heads,dropout=dropout)\n",
    "        self.conv1_ts = wn(nn.Linear(d_model,d_ff))\n",
    "        self.conv2_ts = wn(nn.Linear(d_ff,d_model))\n",
    "\n",
    "        self.dropout_ts = nn.Dropout(dropout)\n",
    "        self.activation_ts = F.relu if activation == \"relu\" else F.gelu\n",
    "        self.layer_norm11 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm12 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm21 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm22 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, basis,series):\n",
    "        basis_raw = basis\n",
    "        series_raw = series\n",
    "        basis_add, basis_attn = self.cross_attention_basis(\n",
    "            basis_raw, series_raw, series_raw,\n",
    "        )\n",
    "        basis_out = basis_raw + self.dropout_basis(basis_add)\n",
    "        basis_out = self.layer_norm11(basis_out)\n",
    "\n",
    "        y_basis = basis_out\n",
    "        y_basis = self.dropout_basis(self.activation_basis(self.conv1_basis(y_basis)))\n",
    "        y_basis = self.dropout_basis(self.conv2_basis(y_basis))\n",
    "        basis_out = basis_out + y_basis\n",
    "\n",
    "        basis_out = self.layer_norm12(basis_out)\n",
    "\n",
    "        series_add,series_attn = self.cross_attention_ts(\n",
    "            series_raw, basis_raw, basis_raw\n",
    "        )\n",
    "        series_out = series_raw + self.dropout_ts(series_add)\n",
    "\n",
    "        series_out = self.layer_norm21(series_out)\n",
    "\n",
    "        y_ts = series_out\n",
    "        y_ts = self.dropout_ts(self.activation_ts(self.conv1_ts(y_ts)))\n",
    "        y_ts = self.dropout_ts(self.conv2_ts(y_ts))\n",
    "        series_out = series_out + y_ts\n",
    "        # series_out = series_raw\n",
    "\n",
    "        series_out = self.layer_norm22(series_out)\n",
    "\n",
    "        return basis_out, series_out, basis_attn, series_attn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#The Coefnet applies multiple BCABs to process the input and extract coefficients\n",
    "#that represent the importance of different basis functions.\n",
    "#This class defines a network of BCABs and a final layer to compute the coefficients\n",
    "#representing the contribution of each basis function.\n",
    "\n",
    "\n",
    "class Coefnet(nn.Module):\n",
    "    def __init__(self, blocks,d_model,heads,norm_layer=None, projection=None):\n",
    "        super().__init__()\n",
    "        layers = [BCAB(d_model,heads) for i in range(blocks)]\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.norm = norm_layer\n",
    "        self.projection = projection\n",
    "        # heads = heads if blocks > 0 else 1\n",
    "        self.last_layer = last_layer(d_model,heads)\n",
    "\n",
    "    def forward(self, basis, series):\n",
    "        attns1 = []\n",
    "        attns2 = []\n",
    "        for layer in self.layers:\n",
    "            basis,series,basis_attn,series_attn = layer(basis,series)   #basis(B,N,d)  series(B,C,d)\n",
    "            attns1.append(basis_attn)\n",
    "            attns2.append(series_attn)\n",
    "\n",
    "        coef = self.last_layer(series,basis)  #(B,k,C,N)\n",
    "\n",
    "        return coef,attns1,attns2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The LastLayer computes the final attention scores between the processed series and the basis functions.\n",
    "\n",
    "class last_layer(nn.Module):\n",
    "    def __init__(self,d_model,n_heads, mask=False,d_keys=None,\n",
    "                 d_values=None,dropout=0):\n",
    "        super().__init__()\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "        d_values = d_values or (d_model // n_heads)\n",
    "\n",
    "        self.query_projection = wn(nn.Linear(d_model,d_keys * n_heads))\n",
    "        self.key_projection = wn(nn.Linear(d_model, d_keys * n_heads))\n",
    "        self.n_heads = n_heads\n",
    "        self.scale = d_keys ** -0.5\n",
    "\n",
    "    def forward(self, queries, keys):\n",
    "        B,L, _ = queries.shape\n",
    "        B,S, _ = keys.shape\n",
    "        H = self.n_heads\n",
    "\n",
    "        queries = self.query_projection(queries).view(B,L, H, -1).permute(0,2,1,3)\n",
    "        keys = self.key_projection(keys).view(B,S, H, -1).permute(0,2,1,3)\n",
    "\n",
    "        dots = torch.matmul(queries, keys.transpose(-1, -2)) * self.scale   #(B,H,L,S)\n",
    "\n",
    "        return dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xxvAM4KCqOvq",
   "metadata": {
    "id": "xxvAM4KCqOvq"
   },
   "outputs": [],
   "source": [
    "\n",
    "# The Basisformer model integrates all the components to perform time series forecasting.\n",
    "#  It normalizes the input, generates basis functions, processes them through the coefficient network,\n",
    "#  and combines the basis functions to produce the forecast output.\n",
    "#  It also includes mechanisms for loss calculation during training,\n",
    "#  using both smoothness and entropy losses to optimize the model.\n",
    "\n",
    "\n",
    "class Basisformer(nn.Module):\n",
    "    def __init__(self,seq_len,pred_len,d_model,heads,basis_nums,block_nums,bottleneck,map_bottleneck,device,tau):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model # the dimensionality of the model's hidden state\n",
    "        self.k = heads # number of attention heads\n",
    "        self.N = basis_nums # number of basis functions\n",
    "        self.coefnet = Coefnet(blocks=block_nums,d_model=d_model,heads=heads)\n",
    "\n",
    "        self.pred_len = pred_len # prediction length\n",
    "        self.seq_len = seq_len # sequence length\n",
    "\n",
    "        # Multi-Layer Perceptron\n",
    "        self.MLP_x = MLP_bottle(seq_len,heads * int(seq_len/heads),int(seq_len/bottleneck)) #processes the input sequence length to create a more compact representation\n",
    "        self.MLP_y = MLP_bottle(pred_len,heads * int(pred_len/heads),int(pred_len/bottleneck)) #same for prediction\n",
    "        self.MLP_sx = MLP_bottle(heads * int(seq_len/heads),seq_len,int(seq_len/bottleneck)) # re-expands the sequence length helping to restore some structure\n",
    "        self.MLP_sy = MLP_bottle(heads * int(pred_len/heads),pred_len,int(pred_len/bottleneck)) # same for prediction\n",
    "\n",
    "\n",
    "        # linear layers with weight normalization for projecting sequences into the model dimension\n",
    "        # nn.Linear(seq_len, d_model) - fully connected linear layer that transforms the input from seq_len or pred_len dimensions to d_model dimensions\n",
    "        # wn function applies weight normalization to the linear layer\n",
    "        self.project1 = wn(nn.Linear(seq_len,d_model))\n",
    "        self.project2 = wn(nn.Linear(seq_len,d_model))\n",
    "        self.project3 = wn(nn.Linear(pred_len,d_model))\n",
    "        self.project4 = wn(nn.Linear(pred_len,d_model))\n",
    "        self.criterion1 = nn.MSELoss()\n",
    "        self.criterion2 = nn.L1Loss(reduction='none')\n",
    "\n",
    "        self.device = device # setting the device (CPU or GPU)\n",
    "\n",
    "        # smooth array\n",
    "        arr = torch.zeros((seq_len+pred_len-2,seq_len+pred_len))\n",
    "        for i in range(seq_len+pred_len-2):\n",
    "            arr[i,i]=-1\n",
    "            arr[i,i+1] = 2\n",
    "            arr[i,i+2] = -1\n",
    "        self.smooth_arr = arr.to(device)\n",
    "\n",
    "        # initializing basis function\n",
    "        # MLP maps input to a higher dim space\n",
    "        self.map_MLP = MLP_bottle(4, # input dim\n",
    "                                  self.N*(self.seq_len+self.pred_len), #output dim\n",
    "                                  map_bottleneck, # hidden layer size for the MLP\n",
    "                                  bias=True)\n",
    "        self.tau = tau # temperature parameter\n",
    "        self.epsilon = 1E-5 # to avoid deletion by zero\n",
    "\n",
    "    def forward(self,x,mark,y=None,train=True,y_mark=None):\n",
    "        # normalization\n",
    "        mean_x = x.mean(dim=1,keepdim=True)\n",
    "        std_x = x.std(dim=1,keepdim=True)\n",
    "        feature = (x - mean_x) / (std_x + self.epsilon)\n",
    "        # reshaping\n",
    "        B,L,C = feature.shape               # batch size, seq length, number of features\n",
    "        feature = feature.permute(0,2,1)    # changing order of dimentions\n",
    "        feature = self.project1(feature)    # (B,C,d)\n",
    "                                            # linear transforrmation defined as wn(nn.Linear(seq_len, d_model))\n",
    "\n",
    "        # creating basis function\n",
    "        m = self.map_MLP(           # maps the input marker to a higher-dimensional space\n",
    "           mark[:, 0].unsqueeze(1)  # selects the first marker and reshapes it for the MLP;\n",
    "                                    # unsqueeze adds new dim at position in ()\n",
    "                        ).reshape(B,self.seq_len + self.pred_len,self.N) #reshapes the output to have other dimensions\n",
    "\n",
    "\n",
    "        # normalization\n",
    "        m = m / torch.sqrt(torch.sum(m**2,dim=1,keepdim=True)+self.epsilon)\n",
    "\n",
    "        # using basis functions in the model by splitting and projecting basis functions\n",
    "        raw_m1 = m[:,:self.seq_len].permute(0,2,1)  #(B,L,N) # corresponding to the input sequence\n",
    "        raw_m2 = m[:,self.seq_len:].permute(0,2,1)   #(B,L',N) #corresponding to the prediction sequence\n",
    "        # permute(0,2,1) changes the order of dimensions for compatibility with other operations\n",
    "\n",
    "        m1 = self.project2(raw_m1)    #(B,N,d) projects the input sequence basis functions into the model dimension\n",
    "\n",
    "        # attention mechanism with basis functions\n",
    "        score,attn_x1,attn_x2 = self.coefnet(m1,feature)    #(B,k,C,N)\n",
    "        # applies the coefficient network to the projected basis functions and the features extracted from the input sequence\n",
    "        # scores represent how much each basis function contributes to the final representation\n",
    "\n",
    "\n",
    "        # combining basis functions\n",
    "        base = self.MLP_y(raw_m2).reshape(B,self.N,self.k,-1).permute(0,2,1,3)   #(B,k,N,L/k)\n",
    "        out = torch.matmul(score,base).permute(0,2,1,3).reshape(B,C,-1)  #(B,C,k * (L/k))\n",
    "        out = self.MLP_sy(out).reshape(B,C,-1).permute(0,2,1)   #（BC,L）\n",
    "\n",
    "\n",
    "\n",
    "        # reverse normalization\n",
    "        output = out * (std_x + self.epsilon) + mean_x\n",
    "\n",
    "        #loss calculation\n",
    "        if train:\n",
    "            l_smooth = torch.einsum('xl,bln->xbn',self.smooth_arr,m)\n",
    "            l_smooth = abs(l_smooth).mean()\n",
    "            # l_smooth = self.criterion1(l_smooth,torch.zeros_like(l_smooth))\n",
    "\n",
    "            # #back\n",
    "            mean_y = y.mean(dim=1,keepdim=True)\n",
    "            std_y = y.std(dim=1,keepdim=True)\n",
    "            feature_y_raw = (y - mean_y) / (std_y + self.epsilon)\n",
    "\n",
    "            feature_y = feature_y_raw.permute(0,2,1)\n",
    "            feature_y = self.project3(feature_y)   #(BC,d)\n",
    "            m2 = self.project4(raw_m2)    #(N,d)\n",
    "\n",
    "            score_y,attn_y1,attn_y2 = self.coefnet(m2,feature_y)    #(B,k,C,N)\n",
    "            logit_q = score.permute(0,2,3,1) #(B,C,N,k)\n",
    "            logit_k = score_y.permute(0,2,3,1) #(B,C,N,k)\n",
    "\n",
    "            # l_pos = torch.bmm(logit_q.view(-1,1,self.k), logit_k.view(-1,self.k,1)).reshape(-1,1)  #(B*C*N,1,1)\n",
    "            l_neg = torch.bmm(logit_q.reshape(-1,self.N,self.k), logit_k.reshape(-1,self.N,self.k).permute(0,2,1)).reshape(-1,self.N) # (B,C*N,N)\n",
    "\n",
    "            labels = torch.arange(0,self.N,1,dtype=torch.long).unsqueeze(0).repeat(B*C,1).reshape(-1)\n",
    "\n",
    "            labels = labels.to(self.device)\n",
    "\n",
    "            cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "            l_entropy = cross_entropy_loss(l_neg/self.tau, labels)\n",
    "\n",
    "            return output,l_entropy,l_smooth,attn_x1,attn_x2,attn_y1,attn_y2\n",
    "        else:\n",
    "            # #back\n",
    "            mean_y = y.mean(dim=1,keepdim=True)\n",
    "            std_y = y.std(dim=1,keepdim=True)\n",
    "            feature_y_raw = (y - mean_y) / (std_y + self.epsilon)\n",
    "\n",
    "            feature_y = feature_y_raw.permute(0,2,1)\n",
    "            feature_y = self.project3(feature_y)   #(BC,d)\n",
    "            m2 = self.project4(raw_m2)    #(N,d)\n",
    "\n",
    "            score_y,attn_y1,attn_y2 = self.coefnet(m2,feature_y)    #(B,k,C,N)\n",
    "            return output,m,attn_x1,attn_x2,attn_y1,attn_y2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d3b15e-cdb7-432a-a22a-c030302f829a",
   "metadata": {
    "id": "a2d3b15e-cdb7-432a-a22a-c030302f829a"
   },
   "outputs": [],
   "source": [
    "def MSE(pred, true):\n",
    "    return np.mean((pred - true) ** 2)\n",
    "\n",
    "def RMSE(pred, true):\n",
    "    return np.sqrt(MSE(pred, true))\n",
    "\n",
    "def MAPE(pred, true):\n",
    "    return np.mean(np.abs((pred - true) / true))\n",
    "\n",
    "def metric(pred, true):\n",
    "    mse = MSE(pred,true)\n",
    "    rmse = RMSE(pred, true)\n",
    "    mape = MAPE(pred, true)\n",
    "\n",
    "    return mse, rmse, mape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-AgTZGZOHkJ-",
   "metadata": {
    "cellView": "form",
    "id": "-AgTZGZOHkJ-"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "def plot_seq_feature(pred_, true_, history_,label = \"train\",error = False,input='',wv=''):\n",
    "    assert(pred_.shape == true_.shape)\n",
    "\n",
    "    index = -1\n",
    "    if pred_.shape[2]>800:\n",
    "        index = 840\n",
    "    pred = pred_.detach().clone()[..., index].unsqueeze(2)\n",
    "    true = true_.detach().clone()[..., index].unsqueeze(2)\n",
    "    history = history_.detach().clone()[..., index].unsqueeze(2)\n",
    "\n",
    "    if len(pred.shape) == 3:  #BLD\n",
    "        if error == False:\n",
    "            pred = pred[0]\n",
    "            true = true[0]\n",
    "            history = history[0]\n",
    "        else:\n",
    "            largest_loss = 0\n",
    "            largest_index = 0\n",
    "            criterion = nn.MSELoss()\n",
    "            for i in range(pred.shape[0]):\n",
    "                loss = criterion(pred[i],true[i])\n",
    "                if  loss > largest_loss:\n",
    "                    largest_loss = loss\n",
    "                    largest_index = i\n",
    "            pred = pred[largest_index]\n",
    "            true = true[largest_index]\n",
    "            history = history[largest_index]\n",
    "            input_error = input[largest_index]\n",
    "            # wv_error = wv[largest_index]\n",
    "            # print('input mean',input_error.mean())\n",
    "            # print('input std',input_error.std())\n",
    "            # print('out mean',true.mean())\n",
    "            # print('out std',true.std())\n",
    "            # print('wv mean',wv_error.mean())\n",
    "            # print('wv std',wv_error.std())\n",
    "            # print('end')\n",
    "\n",
    "    pred = pred.cpu().numpy()\n",
    "    true = true.cpu().numpy()\n",
    "    history = history.cpu().numpy()\n",
    "\n",
    "    L, D = pred.shape\n",
    "    L_h,D_h = history.shape\n",
    "    # if D == 1:\n",
    "    #     pic_row, pic_col = 1, 1\n",
    "    # else:\n",
    "    #     pic_col = 2\n",
    "    #     pic_row = math.ceil(D/pic_col)\n",
    "    pic_row, pic_col = D, 1\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(8*pic_row,8*pic_col))\n",
    "    for i in range(1):\n",
    "        ax = plt.subplot(pic_row,pic_col,i+1)\n",
    "        ax.plot(np.arange(L_h), history[:, i], label = \"history\")\n",
    "        ax.plot(np.arange(L_h,L_h+L), pred[:, i], label = \"pred\")\n",
    "        ax.plot(np.arange(L_h,L_h+L), true[:, i], label = \"true\")\n",
    "        ax.set_title(\"dimension = {},  \".format(i) + label)\n",
    "        ax.legend()\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Des1ClFuevfI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Des1ClFuevfI",
    "outputId": "538a4886-5959-4a8c-a4e8-3239df3ed5ec"
   },
   "outputs": [],
   "source": [
    "pip install adabelief_pytorch==0.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BaRTzsYBRfyN",
   "metadata": {
    "cellView": "form",
    "id": "BaRTzsYBRfyN"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "from adabelief_pytorch import AdaBelief\n",
    "\n",
    "def train(model, train_loader, test_loader, args, device, record_dir):\n",
    "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    log_and_print('[Info] Number of parameters: {}'.format(num_params))\n",
    "\n",
    "    para1 = [param for name, param in model.named_parameters() if 'map_MLP' in name]\n",
    "    para2 = [param for name, param in model.named_parameters() if 'map_MLP' not in name]\n",
    "\n",
    "    # optimizer updates the model parameters during training\n",
    "    optimizer = AdaBelief(\n",
    "        [{'params': para1, 'lr': 5e-3}, {'params': para2, 'lr': args.learning_rate}],\n",
    "        eps=1e-16, betas=(0.9, 0.999), weight_decouple=True, rectify=True\n",
    "    )\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # number of batches in the training set\n",
    "    train_steps = len(train_loader)\n",
    "    # initializing the TensorBoard writer for logging training process\n",
    "    log_dir = os.path.join(record_dir, 'logs/fit')\n",
    "    writer = SummaryWriter(log_dir)\n",
    "\n",
    "    # defining for early stopping\n",
    "    best_loss = float('inf')\n",
    "    count = 0\n",
    "\n",
    "    # training loop\n",
    "    for epoch in range(args.train_epochs):\n",
    "        # lists to store loss values\n",
    "        train_loss = []\n",
    "        loss_pred = []\n",
    "        loss_of_ce = []\n",
    "        l_s = []\n",
    "        # setting model to training mode\n",
    "        model.train()\n",
    "        epoch_time = time.time()\n",
    "\n",
    "        for i, (batch_x, batch_y, batch_x_mark, batch_y_mark, index) in enumerate(train_loader):\n",
    "            # clears the gradients of all optimized tensors\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # loading data to the specified device (originally to cuda)\n",
    "            batch_x = batch_x.float().to(device)\n",
    "            batch_y = batch_y.float().to(device)\n",
    "            batch_x_mark = batch_x_mark.float().to(device)\n",
    "            batch_y_mark = batch_y_mark.float().to(device)\n",
    "\n",
    "            # feature dimension\n",
    "            f_dim = -1 if args.features == 'MS' else 0\n",
    "            # matching the target sequence length required by the model\n",
    "            batch_y = batch_y[:, -args.pred_len:, f_dim:].to(device)\n",
    "\n",
    "            # forward pass through the model to get outputs and losses\n",
    "            outputs, loss_infonce, loss_smooth, attn_x1, attn_x2, attn_y1, attn_y2 = model(batch_x, batch_x_mark, batch_y, True, batch_y_mark)\n",
    "\n",
    "            # calculating loss\n",
    "            loss_p = criterion(outputs, batch_y)\n",
    "            lam1 = args.loss_weight_prediction\n",
    "            lam2 = args.loss_weight_infonce\n",
    "            lam3 = args.loss_weight_smooth\n",
    "\n",
    "            # total loss\n",
    "            loss = lam1 * loss_p + lam2 * loss_infonce + lam3 * loss_smooth\n",
    "            train_loss.append(loss.item())\n",
    "            loss_pred.append(loss_p.item())\n",
    "            loss_of_ce.append(loss_infonce.item())\n",
    "            l_s.append(loss_smooth.item())\n",
    "\n",
    "            # gradient of the loss\n",
    "            loss.backward()\n",
    "\n",
    "            # updating model parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # logging every fifth step of the training process\n",
    "            if (i + 1) % (train_steps // 5) == 0:\n",
    "                log_and_print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
    "\n",
    "        # every epoch logging\n",
    "        log_and_print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
    "        # losses of every epoch\n",
    "        train_loss = np.average(train_loss)\n",
    "        loss1 = np.average(loss_pred)\n",
    "        log_and_print('loss_pred:{0}'.format(loss1))\n",
    "        loss2 = np.average(loss_of_ce)\n",
    "        log_and_print('loss entropy:{0}'.format(loss2))\n",
    "        loss3 = np.average(l_s)\n",
    "        log_and_print('loss smooth:{0}'.format(loss3))\n",
    "\n",
    "        # figures to TensorBoard\n",
    "        fig = plot_seq_feature(outputs, batch_y, batch_x)\n",
    "        writer.add_figure(\"figure_train\", fig, global_step=epoch)\n",
    "        writer.add_scalar('train_loss', train_loss, global_step=epoch)\n",
    "\n",
    "        # saving model checkpoints\n",
    "        ckpt_path = os.path.join(record_dir, args.check_point)\n",
    "        if not os.path.exists(ckpt_path):\n",
    "            os.makedirs(ckpt_path)\n",
    "        # saving in new folder if it is first epoch\n",
    "        if best_loss == float('inf'):\n",
    "            best_loss = train_loss\n",
    "            torch.save(model.state_dict(), os.path.join(ckpt_path, 'valid_best_checkpoint.pth'))\n",
    "        else:\n",
    "            if train_loss < best_loss:  # updates the results if training loss improves\n",
    "                torch.save(model.state_dict(), os.path.join(ckpt_path, 'valid_best_checkpoint.pth'))\n",
    "                best_loss = train_loss\n",
    "                count = 0\n",
    "            else:\n",
    "                count += 1\n",
    "        # final save at the end of each epoch\n",
    "        torch.save(model.state_dict(), os.path.join(ckpt_path, 'final_checkpoint.pth'))\n",
    "        # stopping training if loss doesn't improve for a number of epochs\n",
    "        if count >= args.patience:\n",
    "            break\n",
    "    writer.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EWJq-ZGFI7YH",
   "metadata": {
    "id": "EWJq-ZGFI7YH"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, args, device, record_dir):\n",
    "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    log_and_print('[Info] Number of parameters: {}'.format(num_params))\n",
    "\n",
    "    para1 = [param for name, param in model.named_parameters() if 'map_MLP' in name]\n",
    "    para2 = [param for name, param in model.named_parameters() if 'map_MLP' not in name]\n",
    "\n",
    "    optimizer = AdaBelief([{'params': para1, 'lr': 5e-3}, {'params': para2, 'lr': args.learning_rate}], eps=1e-16, betas=(0.9, 0.999), weight_decouple=True, rectify=True)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    train_steps = len(train_loader)\n",
    "    log_dir = os.path.join(record_dir, 'logs/fit')\n",
    "    writer = SummaryWriter(log_dir)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    count = 0\n",
    "\n",
    "    for epoch in range(args.train_epochs):\n",
    "        train_loss = []\n",
    "        loss_pred = []\n",
    "        loss_of_ce = []\n",
    "        l_s = []\n",
    "        model.train()\n",
    "        epoch_time = time.time()\n",
    "\n",
    "        for i, (batch_x, batch_y, batch_x_mark, batch_y_mark, index) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            batch_x = batch_x.float().to(device)\n",
    "            batch_y = batch_y.float().to(device)\n",
    "            batch_x_mark = batch_x_mark.float().to(device)\n",
    "            batch_y_mark = batch_y_mark.float().to(device)\n",
    "\n",
    "            f_dim = -1 if args.features == 'MS' else 0\n",
    "            batch_y = batch_y[:, -args.pred_len:, f_dim:].to(device)\n",
    "\n",
    "            try:\n",
    "                outputs, loss_infonce, loss_smooth, attn_x1, attn_x2, attn_y1, attn_y2 = model(batch_x, batch_x_mark, batch_y, True, batch_y_mark)\n",
    "            except Exception as e:\n",
    "                print(f\"Error in model forward pass: {e}\")\n",
    "                print(f\"batch_x shape: {batch_x.shape}\")\n",
    "                print(f\"batch_x_mark shape: {batch_x_mark.shape}\")\n",
    "                print(f\"batch_y shape: {batch_y.shape}\")\n",
    "                print(f\"batch_y_mark shape: {batch_y_mark.shape}\")\n",
    "                raise\n",
    "\n",
    "            loss_p = criterion(outputs, batch_y)\n",
    "            lam1 = args.loss_weight_prediction\n",
    "            lam2 = args.loss_weight_infonce\n",
    "            lam3 = args.loss_weight_smooth\n",
    "\n",
    "            loss = lam1 * loss_p + lam2 * loss_infonce + lam3 * loss_smooth\n",
    "            train_loss.append(loss.item())\n",
    "            loss_pred.append(loss_p.item())\n",
    "            loss_of_ce.append(loss_infonce.item())\n",
    "            l_s.append(loss_smooth.item())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i + 1) % (train_steps // 5) == 0:\n",
    "                log_and_print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
    "\n",
    "        log_and_print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
    "        train_loss = np.average(train_loss)\n",
    "        loss1 = np.average(loss_pred)\n",
    "        log_and_print('loss_pred:{0}'.format(loss1))\n",
    "        loss2 = np.average(loss_of_ce)\n",
    "        log_and_print('loss entropy:{0}'.format(loss2))\n",
    "        loss3 = np.average(l_s)\n",
    "        log_and_print('loss smooth:{0}'.format(loss3))\n",
    "\n",
    "        fig = plot_seq_feature(outputs, batch_y, batch_x)\n",
    "        writer.add_figure(\"figure_train\", fig, global_step=epoch)\n",
    "        writer.add_scalar('train_loss', train_loss, global_step=epoch)\n",
    "\n",
    "        ckpt_path = os.path.join(record_dir, args.check_point)\n",
    "        if not os.path.exists(ckpt_path):\n",
    "            os.makedirs(ckpt_path)\n",
    "        if best_loss == float('inf'):\n",
    "            best_loss = train_loss\n",
    "            torch.save(model.state_dict(), os.path.join(ckpt_path, 'valid_best_checkpoint.pth'))\n",
    "        else:\n",
    "            if train_loss < best_loss:\n",
    "                torch.save(model.state_dict(), os.path.join(ckpt_path, 'valid_best_checkpoint.pth'))\n",
    "                best_loss = train_loss\n",
    "                count = 0\n",
    "            else:\n",
    "                count += 1\n",
    "        torch.save(model.state_dict(), os.path.join(ckpt_path, 'final_checkpoint.pth'))\n",
    "        if count >= args.patience:\n",
    "            break\n",
    "    writer.close()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad1ab79-d58d-4f47-bd20-912a81f03ed4",
   "metadata": {
    "id": "aad1ab79-d58d-4f47-bd20-912a81f03ed4"
   },
   "outputs": [],
   "source": [
    "def log_and_print(text):\n",
    "    logging.info(text)\n",
    "    print(text)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9cbd1d-dcae-40c6-92ed-ae8e8d3090eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c9cbd1d-dcae-40c6-92ed-ae8e8d3090eb",
    "outputId": "13765488-7cfd-4221-cc76-806ff09d9a86"
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Time series prediction - Basisformer')\n",
    "    parser.add_argument('--is_training', type=bool, default=True, help='train or test')\n",
    "    parser.add_argument('--device', type=int, default=0, help='gpu device')\n",
    "\n",
    "    # data loader parameters\n",
    "    parser.add_argument('--num_workers', type=int, default=0, help='data loader num workers')\n",
    "    parser.add_argument('--root_path', type=str, default='data', help='root path of the data file')\n",
    "    parser.add_argument('--data_path', type=str, default='all_countries.csv', help='data file')\n",
    "    parser.add_argument('--features', type=str, default='M', help='forecasting task')\n",
    "    parser.add_argument('--freq', type=str, default='h', help='freq for time features encoding')\n",
    "\n",
    "    # forecasting task parameters\n",
    "    parser.add_argument('--seq_len', type=int, default=96, help='input sequence length')\n",
    "    parser.add_argument('--pred_len', type=int, default=48, help='prediction sequence length')\n",
    "\n",
    "    # model parameters\n",
    "    parser.add_argument('--heads', type=int, default=16, help='head in attention')\n",
    "    parser.add_argument('--d_model', type=int, default=100, help='dimension of model')\n",
    "    parser.add_argument('--N', type=int, default=10, help='number of learnable basis')\n",
    "    parser.add_argument('--block_nums', type=int, default=2, help='number of blocks')\n",
    "    parser.add_argument('--bottleneck', type=int, default=2, help='reduction of bottleneck')\n",
    "    parser.add_argument('--map_bottleneck', type=int, default=20, help='reduction of mapping bottleneck')\n",
    "\n",
    "    # optimization parameters\n",
    "    parser.add_argument('--train_epochs', type=int, default=1, help='train epochs')\n",
    "    parser.add_argument('--batch_size', type=int, default=24 , help='batch size of train input data')\n",
    "    parser.add_argument('--learning_rate', type=float, default=5e-4, help='optimizer learning rate')\n",
    "    parser.add_argument('--tau', type=float, default=0.07, help='temperature of infonce loss')\n",
    "    parser.add_argument('--loss_weight_prediction', type=float, default=1.0, help='weight of prediction loss')\n",
    "    parser.add_argument('--loss_weight_infonce', type=float, default=1.0, help='weight of infonce loss')\n",
    "    parser.add_argument('--loss_weight_smooth', type=float, default=1.0, help='weight of smooth loss')\n",
    "\n",
    "    # checkpoint path\n",
    "    parser.add_argument('--check_point', type=str, default='checkpoint', help='check point path, relative path')\n",
    "\n",
    "    # add patience parameter\n",
    "    parser.add_argument('--patience', type=int, default=5, help='early stopping patience')\n",
    "\n",
    "    args, unknown = parser.parse_known_args()\n",
    "\n",
    "    record_dir = os.path.join('records', args.data_path.split('.')[0], 'features_' + args.features,\n",
    "                              'seq_len' + str(args.seq_len) + ',' + 'pred_len' + str(args.pred_len))\n",
    "    if not os.path.exists(record_dir):\n",
    "       os.makedirs(record_dir)\n",
    "\n",
    "    if args.is_training:\n",
    "        logger_file = os.path.join(record_dir, 'train.log')\n",
    "    else:\n",
    "        logger_file = os.path.join(record_dir, 'test.log')\n",
    "\n",
    "    if os.path.exists(logger_file):\n",
    "        with open(logger_file, \"w\") as file:\n",
    "            file.truncate(0)\n",
    "    logging.basicConfig(filename=logger_file, level=logging.INFO)\n",
    "\n",
    "    log_and_print('Args in experiment:')\n",
    "    log_and_print(args)\n",
    "\n",
    "    device = torch.device(f'cuda:{args.device}' if torch.cuda.is_available() else 'cpu')\n",
    "    model = Basisformer(args.seq_len, args.pred_len, args.d_model, args.heads, args.N, args.block_nums, args.bottleneck, args.map_bottleneck, device, args.tau)\n",
    "\n",
    "    log_and_print(model)\n",
    "    model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d34df7-21cb-4303-87f9-d5ec8c03ec8e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33d34df7-21cb-4303-87f9-d5ec8c03ec8e",
    "outputId": "3c5fe222-fb0a-4abc-d84a-489ef41b44b1"
   },
   "outputs": [],
   "source": [
    "args.train_epochs = 1\n",
    "train(model, train_loader, test_loader, args, device, record_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6u_fgQaknOvh",
   "metadata": {
    "id": "6u_fgQaknOvh"
   },
   "outputs": [],
   "source": [
    "#!tensorboard --logdir=event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j59FnuQFNHcV",
   "metadata": {
    "id": "j59FnuQFNHcV"
   },
   "outputs": [],
   "source": [
    "def metric(pred, true):\n",
    "    mae = np.mean(np.abs(pred - true))\n",
    "    mse = np.mean((pred - true) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((pred - true) / true)) * 100\n",
    "    mspe = np.mean(((pred - true) / true) ** 2) * 100\n",
    "    return mae, mse, rmse, mape, mspe\n",
    "\n",
    "def test(model, test_loader, record_dir, args, device, scaler, country_names, test=True):\n",
    "    if test:\n",
    "        log_and_print('loading model')\n",
    "        model.load_state_dict(torch.load(os.path.join(record_dir, args.check_point, 'valid_best_checkpoint.pth')))\n",
    "\n",
    "    preds = []\n",
    "    trues = []\n",
    "\n",
    "    model.eval()\n",
    "    t1 = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (batch_x, batch_y, batch_x_mark, batch_y_mark, index) in enumerate(test_loader):\n",
    "            batch_x = batch_x.float().to(device)\n",
    "            batch_y = batch_y.float().to(device)\n",
    "            batch_x_mark = batch_x_mark.float().to(device)\n",
    "            batch_y_mark = batch_y_mark.float().to(device)\n",
    "\n",
    "            f_dim = -1 if args.features == 'MS' else 0\n",
    "            batch_y = batch_y[:, -args.pred_len:, f_dim:].to(device)\n",
    "\n",
    "            outputs, m, attn_x1, attn_x2, attn_y1, attn_y2 = model(batch_x, batch_x_mark, batch_y, train=False, y_mark=batch_y_mark)\n",
    "\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            batch_y = batch_y.detach().cpu().numpy()\n",
    "\n",
    "            outputs_rescaled = scaler.inverse_transform(outputs.reshape(-1, outputs.shape[-1])).reshape(outputs.shape)\n",
    "            batch_y_rescaled = scaler.inverse_transform(batch_y.reshape(-1, batch_y.shape[-1])).reshape(batch_y.shape)\n",
    "\n",
    "            preds.append(outputs_rescaled)\n",
    "            trues.append(batch_y_rescaled)\n",
    "\n",
    "    t2 = time.time()\n",
    "    log_and_print('total_time:{0}'.format(t2 - t1))\n",
    "    log_and_print('avg_time:{0}'.format((t2 - t1) / len(test_loader.dataset)))\n",
    "\n",
    "    # Flatten lists\n",
    "    preds = [item for sublist in preds for item in sublist]\n",
    "    trues = [item for sublist in trues for item in sublist]\n",
    "\n",
    "    preds = np.array(preds)\n",
    "    trues = np.array(trues)\n",
    "    preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "    trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n",
    "\n",
    "    # Save the results to a file\n",
    "    np.savez(os.path.join(record_dir, 'test_results.npz'), preds=preds, trues=trues, country_names=country_names)\n",
    "\n",
    "    mae, mse, rmse, mape, mspe = metric(preds, trues)\n",
    "    log_and_print('mse:{}, mae:{}'.format(mse, mae))\n",
    "    return mae, mse, rmse, mape, mspe\n",
    "\n",
    "\n",
    "# Run the test function\n",
    "test(model, test_loader, record_dir, args, device, scaler, country_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7LcX1snOPxcG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7LcX1snOPxcG",
    "outputId": "79041c68-11f5-41ec-b14b-afcd616877c1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def plot_predictions(true, pred, country_names, num_samples=24, samples_per_figure=6):\n",
    "    num_figures = num_samples // samples_per_figure\n",
    "    if num_samples % samples_per_figure:\n",
    "        num_figures += 1\n",
    "    \n",
    "    for fig_num in range(num_figures):\n",
    "        plt.figure(figsize=(20, 12))\n",
    "        start_idx = fig_num * samples_per_figure\n",
    "        end_idx = min((fig_num + 1) * samples_per_figure, num_samples)\n",
    "        \n",
    "        for i in range(start_idx, end_idx):\n",
    "            plt.subplot(samples_per_figure // 2, 2, (i % samples_per_figure) + 1)\n",
    "            plt.plot(true[i], label='True')\n",
    "            plt.plot(pred[i], label='Pred')\n",
    "            plt.legend()\n",
    "            plt.title(f'{country_names[i]}')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Load the results from the file\n",
    "def load_and_plot_results(record_dir, num_samples=24, samples_per_figure=6):\n",
    "    data = np.load(os.path.join(record_dir, 'test_results.npz'))\n",
    "    preds = data['preds']\n",
    "    trues = data['trues']\n",
    "    country_names = data['country_names']\n",
    "    plot_predictions(trues, preds, country_names, num_samples, samples_per_figure)\n",
    "\n",
    "# Adjust plot parameters as needed and plot the results\n",
    "load_and_plot_results(record_dir, num_samples=24, samples_per_figure=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859cd6c1-1569-4378-a015-2e74dcdc430b",
   "metadata": {
    "id": "YCYAEORVlIkJ"
   },
   "source": [
    "# Sythetic Data Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf52e8fc-db3d-4278-9d48-1191b949e600",
   "metadata": {},
   "source": [
    "## Chronos Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab4b902-ca90-486a-9061-e9895762829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install \"chronos[training] @ git+https://github.com/amazon-science/chronos-forecasting.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dec950b-f4b5-4876-b8fc-a9814e41dff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python kernel-synth.py --num-series 500 --max-kernels 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4027a0-2777-4b7d-a2aa-82dd576e5366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.ipc as ipc\n",
    "\n",
    "file_path = 'kernelsynth-data.arrow'\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    reader = ipc.RecordBatchFileReader(f)\n",
    "    table = reader.read_all()\n",
    "\n",
    "df = table.to_pandas()\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f0e4bd-22c7-4141-a928-67f7766349b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(df['target'].iloc[i])\n",
    "    plt.title(f'Time Series {i}')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Value')\n",
    "    plt.show()\n",
    "\n",
    "first_series = df['target'].iloc[0]\n",
    "print('Mean:', np.mean(first_series))\n",
    "print('Standard Deviation:', np.std(first_series))\n",
    "print('Min:', np.min(first_series))\n",
    "print('Max:', np.max(first_series))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a672fb3-0c03-4181-b993-8fa51bf590f8",
   "metadata": {},
   "source": [
    "## DYNOTEARS Causal Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b50b30-9b3a-4807-8cd1-e730aee0912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install causalnex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3308f3f-5444-4c7b-81c7-0cea10a543f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2019-2020 QuantumBlack Visual Analytics Limited\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n",
    "# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\n",
    "# OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, AND\n",
    "# NONINFRINGEMENT. IN NO EVENT WILL THE LICENSOR OR OTHER CONTRIBUTORS\n",
    "# BE LIABLE FOR ANY CLAIM, DAMAGES, OR OTHER LIABILITY, WHETHER IN AN\n",
    "# ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF, OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "#\n",
    "# The QuantumBlack Visual Analytics Limited (\"QuantumBlack\") name and logo\n",
    "# (either separately or in combination, \"QuantumBlack Trademarks\") are\n",
    "# trademarks of QuantumBlack. The License does not grant you any right or\n",
    "# license to the QuantumBlack Trademarks. You may not use the QuantumBlack\n",
    "# Trademarks or any confusingly similar mark as a trademark for your product,\n",
    "#     or use the QuantumBlack Trademarks in any other manner that might cause\n",
    "# confusion in the marketplace, including but not limited to in advertising,\n",
    "# on websites, or on software.\n",
    "#\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\"\"\"\n",
    "Tools to learn a Dynamic Bayesian Network which describe the conditional dependencies between variables in a time-series\n",
    "dataset.\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "from typing import Dict, List, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.linalg as slin\n",
    "import scipy.optimize as sopt\n",
    "\n",
    "from causalnex.structure import StructureModel\n",
    "from causalnex.structure.transformers import DynamicDataTransformer\n",
    "\n",
    "\n",
    "def from_pandas_dynamic(  # pylint: disable=too-many-arguments\n",
    "    time_series: Union[pd.DataFrame, List[pd.DataFrame]],\n",
    "    p: int,\n",
    "    lambda_w: float = 0.1,\n",
    "    lambda_a: float = 0.1,\n",
    "    max_iter: int = 100,\n",
    "    h_tol: float = 1e-8,\n",
    "    w_threshold: float = 0.0,\n",
    "    tabu_edges: List[Tuple[int, int, int]] = None,\n",
    "    tabu_parent_nodes: List[int] = None,\n",
    "    tabu_child_nodes: List[int] = None,\n",
    ") -> StructureModel:\n",
    "    \"\"\"\n",
    "    Learn the graph structure of a Dynamic Bayesian Network describing conditional dependencies between variables in\n",
    "    data. The input data is a time series or a list of realisations of a same time series.\n",
    "    The optimisation is to minimise a score function F(W, A) over the graph's contemporaneous (intra-slice) weighted\n",
    "    adjacency matrix, W, and lagged (inter-slice) weighted adjacency matrix, A, subject to the a constraint function\n",
    "    h(W), where h_value(W) == 0 characterises an acyclic graph. h(W) > 0 is a continuous, differentiable function that\n",
    "    encapsulated how acyclic the graph is (less = more acyclic).\n",
    "\n",
    "    Based on \"DYNOTEARS: Structure Learning from Time-Series Data\".\n",
    "    https://arxiv.org/abs/2002.00498\n",
    "    @inproceedings{pamfil2020dynotears,\n",
    "        title={DYNOTEARS: Structure Learning from Time-Series Data},\n",
    "        author={Pamfil, Roxana and Sriwattanaworachai, Nisara and Desai, Shaan and Pilgerstorfer,\n",
    "        Philip and Georgatzis, Konstantinos and Beaumont, Paul and Aragam, Bryon},\n",
    "        booktitle={International Conference on Artificial Intelligence and Statistics},\n",
    "        pages={1595--1605},\n",
    "        year={2020}year={2020},\n",
    "    }\n",
    "    Args:\n",
    "        time_series: pd.DataFrame or List of pd.DataFrame instances.\n",
    "        If a list is provided each element of the list being an realisation of a time series (i.e. time series governed\n",
    "        by the same processes)\n",
    "        The columns of the data frame represent the variables in the model, and the *index represents the time index*.\n",
    "        Successive events, therefore, must be indexed with one integer of difference between them too.\n",
    "        p: Number of past interactions we allow the model to create. The state of a variable at time `t` is affected by\n",
    "        past variables up to a `t-p`, as well as by other variables at `t`.\n",
    "        lambda_w: parameter for l1 regularisation of intra-slice edges\n",
    "        lambda_a: parameter for l1 regularisation of inter-slice edges\n",
    "        max_iter: max number of dual ascent steps during optimisation.\n",
    "        h_tol: exit if h(W) < h_tol (as opposed to strict definition of 0).\n",
    "        w_threshold: fixed threshold for absolute edge weights.\n",
    "        tabu_edges: list of edges(lag, from, to) not to be included in the graph. `lag == 0` implies that the edge is\n",
    "        forbidden in the INTRA graph (W), while lag > 0 implies an INTER-slice weight equal zero.\n",
    "        tabu_parent_nodes: list of nodes banned from being a parent of any other nodes.\n",
    "        tabu_child_nodes: list of nodes banned from being a child of any other nodes.\n",
    "\n",
    "    Returns:\n",
    "        StructureModel representing the model learnt. The node names are noted as `{var}_lag{l}`, where `var` is the\n",
    "        original variable name as in the give in the input data frames and `l`, in 0,1,2..p is the correspondent\n",
    "        time lag.\n",
    "    \"\"\"\n",
    "    time_series = [time_series] if not isinstance(time_series, list) else time_series\n",
    "\n",
    "    X, Xlags = DynamicDataTransformer(p=p).fit_transform(time_series, return_df=False)\n",
    "\n",
    "    col_idx = {c: i for i, c in enumerate(time_series[0].columns)}\n",
    "    idx_col = {i: c for c, i in col_idx.items()}\n",
    "\n",
    "    if tabu_edges:\n",
    "        tabu_edges = [(lag, col_idx[u], col_idx[v]) for lag, u, v in tabu_edges]\n",
    "    if tabu_parent_nodes:\n",
    "        tabu_parent_nodes = [col_idx[n] for n in tabu_parent_nodes]\n",
    "    if tabu_child_nodes:\n",
    "        tabu_child_nodes = [col_idx[n] for n in tabu_child_nodes]\n",
    "\n",
    "    g = from_numpy_dynamic(\n",
    "        X,\n",
    "        Xlags,\n",
    "        lambda_w,\n",
    "        lambda_a,\n",
    "        max_iter,\n",
    "        h_tol,\n",
    "        w_threshold,\n",
    "        tabu_edges,\n",
    "        tabu_parent_nodes,\n",
    "        tabu_child_nodes,\n",
    "    )\n",
    "\n",
    "    sm = StructureModel()\n",
    "    sm.add_nodes_from(\n",
    "        [f\"{var}_lag{l_val}\" for var in col_idx.keys() for l_val in range(p + 1)]\n",
    "    )\n",
    "    sm.add_weighted_edges_from(\n",
    "        [\n",
    "            (\n",
    "                _format_name_from_pandas(idx_col, u),\n",
    "                _format_name_from_pandas(idx_col, v),\n",
    "                w,\n",
    "            )\n",
    "            for u, v, w in g.edges.data(\"weight\")\n",
    "        ],\n",
    "        origin=\"learned\",\n",
    "    )\n",
    "\n",
    "    return sm\n",
    "\n",
    "\n",
    "def _format_name_from_pandas(idx_col: Dict[int, str], from_numpy_node: str) -> str:\n",
    "    \"\"\"\n",
    "    Helper function for `from_pandas_dynamic`. converts a node from the `from_numpy_dynamic` format to the `from_pandas`\n",
    "    format\n",
    "    Args:\n",
    "        idx_col: map from variable to intdex\n",
    "        from_numpy_node: nodes in the structure model output by `from_numpy_dynamic`.\n",
    "    Returns:\n",
    "        nodes in from_pandas_dynamic format\n",
    "    \"\"\"\n",
    "    idx, lag_val = from_numpy_node.split(\"_lag\")\n",
    "    return f\"{idx_col[int(idx)]}_lag{lag_val}\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (basisformer_x86_env)",
   "language": "python",
   "name": "basisformer_x86_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
