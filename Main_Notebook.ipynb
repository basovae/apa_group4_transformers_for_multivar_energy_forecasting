{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c73133af-7360-4762-9048-3aa0b3bb71b4",
   "metadata": {},
   "source": [
    "### Agenda:\n",
    "1. Data Loading & Preprocessing\n",
    "   - Pivoting\n",
    "   - Missing values handling\n",
    "   - Date features creation\n",
    "   - Train/Test split\n",
    "   - Scaling\n",
    "   - Sequences\n",
    "   - Data Loader (incl. indexing for Basisformer)\n",
    "2. Benchmark Models\n",
    "   - Linear Regression\n",
    "   - LSTM\n",
    "3. Transformers\n",
    "   - Non-Stationary Autoformer\n",
    "   - BasisFormer\n",
    "   - iTransformer\n",
    "   - Chronos\n",
    "4. Experimental Design\n",
    "   - Device Setup (probably can be eliminated)\n",
    "   - Data Preparation\n",
    "   - Unification\n",
    "5. Results\n",
    "6. Outlook\n",
    "   - Chronos Simulation Framework\n",
    "   - DYNOTEARS Causal Structure\n",
    "   - Non linear causal structure\n",
    "   - Data Augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "veljByFX557b",
   "metadata": {
    "id": "veljByFX557b"
   },
   "outputs": [],
   "source": [
    "#!pip install torch==2.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370ef93a-0cd3-471b-a6d1-1b3ed3da369c",
   "metadata": {},
   "source": [
    "# 1. Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1c78b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cad7a09c-a0e5-4eff-b76b-752fcb66665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f4de819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.weight_norm as wn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98a448b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import argparse\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c0948b2-e0b7-4862-9a96-8f186c1d4244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "iGtogtkxzGiT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "iGtogtkxzGiT",
    "outputId": "d63b1548-a355-4ac8-89ed-fc0029c44b31"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>ISO3 Code</th>\n",
       "      <th>Datetime (UTC)</th>\n",
       "      <th>Datetime (Local)</th>\n",
       "      <th>Price (EUR/MWhe)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>2015-01-01 01:00:00</td>\n",
       "      <td>17.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>2015-01-01 01:00:00</td>\n",
       "      <td>2015-01-01 02:00:00</td>\n",
       "      <td>15.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>2015-01-01 02:00:00</td>\n",
       "      <td>2015-01-01 03:00:00</td>\n",
       "      <td>16.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>2015-01-01 03:00:00</td>\n",
       "      <td>2015-01-01 04:00:00</td>\n",
       "      <td>17.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>2015-01-01 04:00:00</td>\n",
       "      <td>2015-01-01 05:00:00</td>\n",
       "      <td>16.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country ISO3 Code       Datetime (UTC)     Datetime (Local)  \\\n",
       "0  Austria       AUT  2015-01-01 00:00:00  2015-01-01 01:00:00   \n",
       "1  Austria       AUT  2015-01-01 01:00:00  2015-01-01 02:00:00   \n",
       "2  Austria       AUT  2015-01-01 02:00:00  2015-01-01 03:00:00   \n",
       "3  Austria       AUT  2015-01-01 03:00:00  2015-01-01 04:00:00   \n",
       "4  Austria       AUT  2015-01-01 04:00:00  2015-01-01 05:00:00   \n",
       "\n",
       "   Price (EUR/MWhe)  \n",
       "0             17.93  \n",
       "1             15.17  \n",
       "2             16.38  \n",
       "3             17.38  \n",
       "4             16.38  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##file_path = '/content/all_countries.csv' ## colab path\n",
    "file_path = 'data/all_countries.csv' ## jupyter path\n",
    "df = pd.read_csv(file_path)\n",
    "df = pd.DataFrame(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "vQW9jbwq4lFG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "vQW9jbwq4lFG",
    "outputId": "e9aa57ef-18a2-4243-cd79-51b284512116"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Country</th>\n",
       "      <th>Austria</th>\n",
       "      <th>Belgium</th>\n",
       "      <th>Bulgaria</th>\n",
       "      <th>Croatia</th>\n",
       "      <th>Czechia</th>\n",
       "      <th>Denmark</th>\n",
       "      <th>Estonia</th>\n",
       "      <th>Finland</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>...</th>\n",
       "      <th>Norway</th>\n",
       "      <th>Poland</th>\n",
       "      <th>Portugal</th>\n",
       "      <th>Romania</th>\n",
       "      <th>Serbia</th>\n",
       "      <th>Slovakia</th>\n",
       "      <th>Slovenia</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Sweden</th>\n",
       "      <th>Switzerland</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime (UTC)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00</th>\n",
       "      <td>17.93</td>\n",
       "      <td>34.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.20</td>\n",
       "      <td>18.29</td>\n",
       "      <td>23.37</td>\n",
       "      <td>23.37</td>\n",
       "      <td>34.94</td>\n",
       "      <td>17.93</td>\n",
       "      <td>...</td>\n",
       "      <td>27.36</td>\n",
       "      <td>17.18</td>\n",
       "      <td>48.10</td>\n",
       "      <td>44.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.20</td>\n",
       "      <td>23.25</td>\n",
       "      <td>48.10</td>\n",
       "      <td>23.37</td>\n",
       "      <td>43.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 01:00:00</th>\n",
       "      <td>15.17</td>\n",
       "      <td>32.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.06</td>\n",
       "      <td>16.04</td>\n",
       "      <td>19.33</td>\n",
       "      <td>19.33</td>\n",
       "      <td>32.19</td>\n",
       "      <td>15.17</td>\n",
       "      <td>...</td>\n",
       "      <td>27.24</td>\n",
       "      <td>17.38</td>\n",
       "      <td>47.33</td>\n",
       "      <td>39.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.06</td>\n",
       "      <td>22.20</td>\n",
       "      <td>47.33</td>\n",
       "      <td>19.33</td>\n",
       "      <td>38.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 02:00:00</th>\n",
       "      <td>16.38</td>\n",
       "      <td>28.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.27</td>\n",
       "      <td>14.60</td>\n",
       "      <td>17.66</td>\n",
       "      <td>17.66</td>\n",
       "      <td>23.53</td>\n",
       "      <td>16.38</td>\n",
       "      <td>...</td>\n",
       "      <td>27.16</td>\n",
       "      <td>17.40</td>\n",
       "      <td>42.27</td>\n",
       "      <td>26.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.27</td>\n",
       "      <td>19.56</td>\n",
       "      <td>42.27</td>\n",
       "      <td>17.66</td>\n",
       "      <td>35.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 03:00:00</th>\n",
       "      <td>17.38</td>\n",
       "      <td>28.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.17</td>\n",
       "      <td>14.95</td>\n",
       "      <td>17.53</td>\n",
       "      <td>17.53</td>\n",
       "      <td>22.92</td>\n",
       "      <td>17.38</td>\n",
       "      <td>...</td>\n",
       "      <td>27.15</td>\n",
       "      <td>18.60</td>\n",
       "      <td>38.41</td>\n",
       "      <td>20.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.17</td>\n",
       "      <td>18.88</td>\n",
       "      <td>38.41</td>\n",
       "      <td>17.53</td>\n",
       "      <td>30.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 04:00:00</th>\n",
       "      <td>16.38</td>\n",
       "      <td>34.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.90</td>\n",
       "      <td>14.50</td>\n",
       "      <td>18.07</td>\n",
       "      <td>18.07</td>\n",
       "      <td>34.26</td>\n",
       "      <td>16.38</td>\n",
       "      <td>...</td>\n",
       "      <td>27.30</td>\n",
       "      <td>19.30</td>\n",
       "      <td>35.72</td>\n",
       "      <td>18.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.90</td>\n",
       "      <td>18.39</td>\n",
       "      <td>35.72</td>\n",
       "      <td>18.07</td>\n",
       "      <td>28.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Country              Austria  Belgium  Bulgaria  Croatia  Czechia  Denmark  \\\n",
       "Datetime (UTC)                                                               \n",
       "2015-01-01 00:00:00    17.93    34.94       NaN      NaN    24.20    18.29   \n",
       "2015-01-01 01:00:00    15.17    32.19       NaN      NaN    22.06    16.04   \n",
       "2015-01-01 02:00:00    16.38    28.05       NaN      NaN    20.27    14.60   \n",
       "2015-01-01 03:00:00    17.38    28.04       NaN      NaN    19.17    14.95   \n",
       "2015-01-01 04:00:00    16.38    34.26       NaN      NaN    17.90    14.50   \n",
       "\n",
       "Country              Estonia  Finland  France  Germany  ...  Norway  Poland  \\\n",
       "Datetime (UTC)                                          ...                   \n",
       "2015-01-01 00:00:00    23.37    23.37   34.94    17.93  ...   27.36   17.18   \n",
       "2015-01-01 01:00:00    19.33    19.33   32.19    15.17  ...   27.24   17.38   \n",
       "2015-01-01 02:00:00    17.66    17.66   23.53    16.38  ...   27.16   17.40   \n",
       "2015-01-01 03:00:00    17.53    17.53   22.92    17.38  ...   27.15   18.60   \n",
       "2015-01-01 04:00:00    18.07    18.07   34.26    16.38  ...   27.30   19.30   \n",
       "\n",
       "Country              Portugal  Romania  Serbia  Slovakia  Slovenia  Spain  \\\n",
       "Datetime (UTC)                                                              \n",
       "2015-01-01 00:00:00     48.10    44.17     NaN     24.20     23.25  48.10   \n",
       "2015-01-01 01:00:00     47.33    39.17     NaN     22.06     22.20  47.33   \n",
       "2015-01-01 02:00:00     42.27    26.93     NaN     20.27     19.56  42.27   \n",
       "2015-01-01 03:00:00     38.41    20.94     NaN     19.17     18.88  38.41   \n",
       "2015-01-01 04:00:00     35.72    18.52     NaN     17.90     18.39  35.72   \n",
       "\n",
       "Country              Sweden  Switzerland  \n",
       "Datetime (UTC)                            \n",
       "2015-01-01 00:00:00   23.37        43.43  \n",
       "2015-01-01 01:00:00   19.33        38.08  \n",
       "2015-01-01 02:00:00   17.66        35.47  \n",
       "2015-01-01 03:00:00   17.53        30.83  \n",
       "2015-01-01 04:00:00   18.07        28.26  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df [['Country','Datetime (UTC)',  'Price (EUR/MWhe)']]\n",
    "df = df.pivot(index='Datetime (UTC)', columns='Country', values='Price (EUR/MWhe)')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "mfQvgSnM3_1v",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mfQvgSnM3_1v",
    "outputId": "9cd1c2f9-c7f7-46d1-df8b-df5c13df26d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country\n",
      "Austria                0\n",
      "Belgium                0\n",
      "Bulgaria           15336\n",
      "Croatia            24096\n",
      "Czechia                0\n",
      "Denmark                0\n",
      "Estonia                0\n",
      "Finland                0\n",
      "France                 0\n",
      "Germany                0\n",
      "Greece                 0\n",
      "Hungary                0\n",
      "Ireland            12480\n",
      "Italy                  0\n",
      "Latvia                 0\n",
      "Lithuania              0\n",
      "Luxembourg             0\n",
      "Netherlands            0\n",
      "North Macedonia    73008\n",
      "Norway                 0\n",
      "Poland                 0\n",
      "Portugal               0\n",
      "Romania                0\n",
      "Serbia             16800\n",
      "Slovakia               0\n",
      "Slovenia               0\n",
      "Spain                  0\n",
      "Sweden                 0\n",
      "Switzerland            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "WObloVqL4aH3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WObloVqL4aH3",
    "outputId": "c1a5702e-1761-4cca-d65c-14966b09d8dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country\n",
      "Austria        0\n",
      "Belgium        0\n",
      "Czechia        0\n",
      "Denmark        0\n",
      "Estonia        0\n",
      "Finland        0\n",
      "France         0\n",
      "Germany        0\n",
      "Greece         0\n",
      "Hungary        0\n",
      "Italy          0\n",
      "Latvia         0\n",
      "Lithuania      0\n",
      "Luxembourg     0\n",
      "Netherlands    0\n",
      "Norway         0\n",
      "Poland         0\n",
      "Portugal       0\n",
      "Romania        0\n",
      "Slovakia       0\n",
      "Slovenia       0\n",
      "Spain          0\n",
      "Sweden         0\n",
      "Switzerland    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(axis=1)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "AB6vyJX-C6h3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AB6vyJX-C6h3",
    "outputId": "aa9990f8-cb44-4367-b4ff-e2a1bf1732d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datetime (UTC)  Austria  Belgium  Czechia  Denmark  Estonia  Finland  \\\n",
      "0  2015-01-01 00:00:00    17.93    34.94    24.20    18.29    23.37    23.37   \n",
      "1  2015-01-01 01:00:00    15.17    32.19    22.06    16.04    19.33    19.33   \n",
      "2  2015-01-01 02:00:00    16.38    28.05    20.27    14.60    17.66    17.66   \n",
      "3  2015-01-01 03:00:00    17.38    28.04    19.17    14.95    17.53    17.53   \n",
      "4  2015-01-01 04:00:00    16.38    34.26    17.90    14.50    18.07    18.07   \n",
      "\n",
      "   France  Germany  Greece  ...  Netherlands  Norway  Poland  Portugal  \\\n",
      "0   34.94    17.93   48.78  ...        34.94   27.36   17.18     48.10   \n",
      "1   32.19    15.17   31.10  ...        32.19   27.24   17.38     47.33   \n",
      "2   23.53    16.38   20.78  ...        28.05   27.16   17.40     42.27   \n",
      "3   22.92    17.38   25.40  ...        28.04   27.15   18.60     38.41   \n",
      "4   34.26    16.38   26.00  ...        34.26   27.30   19.30     35.72   \n",
      "\n",
      "   Romania  Slovakia  Slovenia  Spain  Sweden  Switzerland  \n",
      "0    44.17     24.20     23.25  48.10   23.37        43.43  \n",
      "1    39.17     22.06     22.20  47.33   19.33        38.08  \n",
      "2    26.93     20.27     19.56  42.27   17.66        35.47  \n",
      "3    20.94     19.17     18.88  38.41   17.53        30.83  \n",
      "4    18.52     17.90     18.39  35.72   18.07        28.26  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.columns.name = None\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99211c4c-9b8f-4d60-9bb6-add80102ca5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last time point available: 2024-04-30 23:00:00\n"
     ]
    }
   ],
   "source": [
    "df['Datetime (UTC)'] = pd.to_datetime(df['Datetime (UTC)'])\n",
    "last_time_point = df['Datetime (UTC)'].max()\n",
    "print(\"Last time point available:\", last_time_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9365312-6296-4b97-ace6-9dd9191fccea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Datetime (UTC)  Austria  Belgium  Czechia  Denmark  Estonia  \\\n",
      "79633 2024-02-01 01:00:00    66.59    44.47    80.01    30.49    26.71   \n",
      "79634 2024-02-01 02:00:00    64.13    45.15    80.01    31.12    38.22   \n",
      "79635 2024-02-01 03:00:00    69.80    49.02    80.01    31.95    27.71   \n",
      "79636 2024-02-01 04:00:00    80.78    57.56    87.10    35.01    20.10   \n",
      "79637 2024-02-01 05:00:00    86.95    70.56    95.00    39.04    72.59   \n",
      "...                   ...      ...      ...      ...      ...      ...   \n",
      "81787 2024-04-30 19:00:00    87.82    87.02    88.29    66.05    88.36   \n",
      "81788 2024-04-30 20:00:00    77.50    75.39    77.99    54.09    78.02   \n",
      "81789 2024-04-30 21:00:00    76.10    77.51    75.93    50.98    54.93   \n",
      "81790 2024-04-30 22:00:00    64.22    58.00    67.16    44.71    38.00   \n",
      "81791 2024-04-30 23:00:00    54.89    54.28    56.35    44.18    36.61   \n",
      "\n",
      "       Finland  France  Germany  Greece  ...  Netherlands  Norway  Poland  \\\n",
      "79633    -2.49   46.66    42.16   80.00  ...        43.04   34.35   42.38   \n",
      "79634    -2.50   47.04    43.05   73.06  ...        43.94   34.62   40.93   \n",
      "79635    -2.07   51.06    46.91   83.80  ...        47.63   37.25   40.89   \n",
      "79636    -1.84   59.82    55.34   99.57  ...        56.06   39.16   51.65   \n",
      "79637    -0.10   72.42    69.01  107.36  ...        69.20   40.32   72.59   \n",
      "...        ...     ...      ...     ...  ...          ...     ...     ...   \n",
      "81787    88.36   83.91    88.37   80.01  ...        88.15   53.42   88.36   \n",
      "81788    78.02   70.98    77.97   77.53  ...        80.00   52.52   83.29   \n",
      "81789    54.93   75.79    75.69   75.97  ...        81.80   50.05   80.97   \n",
      "81790    38.00   35.01    66.81   36.99  ...        76.77   43.80   67.43   \n",
      "81791    36.61   34.99    55.09   34.86  ...        79.89   43.30   74.02   \n",
      "\n",
      "       Portugal  Romania  Slovakia  Slovenia  Spain  Sweden  Switzerland  \n",
      "79633     55.10    80.00     91.00     71.73  55.10   -2.49        70.80  \n",
      "79634     54.60    73.06     80.19     67.66  54.60   -2.50        73.85  \n",
      "79635     53.47    83.80     96.02     75.10  53.47   -2.07        74.06  \n",
      "79636     59.82    99.57    116.13     87.74  59.82   -1.84        74.09  \n",
      "79637     72.42   107.36    108.87     95.63  72.42   -0.10        86.00  \n",
      "...         ...      ...       ...       ...    ...     ...          ...  \n",
      "81787     83.91    88.08     88.15     88.09  83.91   55.47        88.81  \n",
      "81788     70.98    77.53     77.74     77.19  70.98   52.77        78.03  \n",
      "81789     65.00    75.97     75.94     76.02  65.00   50.05        71.07  \n",
      "81790     35.01    64.74     65.81     62.97  35.01   38.00        57.37  \n",
      "81791     34.99    54.86     55.49     53.86  34.99   36.61        53.04  \n",
      "\n",
      "[2159 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "start_date = '2024-02-01 01:00:00' ## FILTERING ONLY FOR 3 MONTHS\n",
    "df = df[df['Datetime (UTC)'] >= pd.to_datetime(start_date)]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "_Jtyfje24Pdq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Jtyfje24Pdq",
    "outputId": "507d28c6-0347-4446-9078-c6fda9ffa9a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Datetime (UTC)  Austria  Belgium  Czechia  Denmark  Estonia  \\\n",
      "79633 2024-02-01 01:00:00    66.59    44.47    80.01    30.49    26.71   \n",
      "79634 2024-02-01 02:00:00    64.13    45.15    80.01    31.12    38.22   \n",
      "79635 2024-02-01 03:00:00    69.80    49.02    80.01    31.95    27.71   \n",
      "79636 2024-02-01 04:00:00    80.78    57.56    87.10    35.01    20.10   \n",
      "79637 2024-02-01 05:00:00    86.95    70.56    95.00    39.04    72.59   \n",
      "\n",
      "       Finland  France  Germany  Greece  ...  Romania  Slovakia  Slovenia  \\\n",
      "79633    -2.49   46.66    42.16   80.00  ...    80.00     91.00     71.73   \n",
      "79634    -2.50   47.04    43.05   73.06  ...    73.06     80.19     67.66   \n",
      "79635    -2.07   51.06    46.91   83.80  ...    83.80     96.02     75.10   \n",
      "79636    -1.84   59.82    55.34   99.57  ...    99.57    116.13     87.74   \n",
      "79637    -0.10   72.42    69.01  107.36  ...   107.36    108.87     95.63   \n",
      "\n",
      "       Spain  Sweden  Switzerland  month  day  weekday  hour  \n",
      "79633  55.10   -2.49        70.80      2    1        3     1  \n",
      "79634  54.60   -2.50        73.85      2    1        3     2  \n",
      "79635  53.47   -2.07        74.06      2    1        3     3  \n",
      "79636  59.82   -1.84        74.09      2    1        3     4  \n",
      "79637  72.42   -0.10        86.00      2    1        3     5  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "df['month'] = df['Datetime (UTC)'].apply(lambda row: row.month)\n",
    "df['day'] = df['Datetime (UTC)'].apply(lambda row: row.day)\n",
    "df['weekday'] = df['Datetime (UTC)'].apply(lambda row: row.weekday())\n",
    "df['hour'] = df['Datetime (UTC)'].apply(lambda row: row.hour)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80mxqDAh5Mwd",
   "metadata": {
    "id": "80mxqDAh5Mwd"
   },
   "outputs": [],
   "source": [
    "# separating the electricity prices and timestamp features\n",
    "electricity_prices_df = df[['Datetime (UTC)', 'Austria', 'Belgium', 'Czechia', 'Denmark', 'Estonia', 'Finland', 'France',\n",
    "              'Germany', 'Greece', 'Hungary', 'Italy', 'Latvia', 'Lithuania', 'Luxembourg',\n",
    "             'Netherlands', 'Norway', 'Poland', 'Portugal', 'Romania', 'Slovakia',\n",
    "             'Slovenia', 'Spain', 'Sweden', 'Switzerland']]\n",
    "timestamp_features_df = df[['Datetime (UTC)', 'month', 'day', 'weekday', 'hour']]\n",
    "\n",
    "# defining the split ratio\n",
    "train_size = 0.8\n",
    "train_size_electricity = int(len(electricity_prices_df) * train_size)\n",
    "train_size_timestamp = int(len(timestamp_features_df) * train_size)\n",
    "\n",
    "# spliting the data into train and test sets\n",
    "electricity_prices_train = electricity_prices_df[:train_size_electricity]\n",
    "electricity_prices_test = electricity_prices_df[train_size_electricity:]\n",
    "timestamp_features_train = timestamp_features_df[:train_size_timestamp]\n",
    "timestamp_features_test = timestamp_features_df[train_size_timestamp:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95180c89-5259-40f8-af8b-e90241aa8864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(electricity_prices_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a2c3f05-460c-4d80-868e-48ff8f5cfd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#country_names = electricity_prices_train.drop(columns=['Datetime (UTC)']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4oRyT6un5WWm",
   "metadata": {
    "id": "4oRyT6un5WWm"
   },
   "outputs": [],
   "source": [
    "# rescaling the electricity prices\n",
    "scaler = StandardScaler()\n",
    "\n",
    "electricity_prices_train_scaled = scaler.fit_transform(electricity_prices_train.drop(columns=['Datetime (UTC)']))\n",
    "electricity_prices_test_scaled = scaler.transform(electricity_prices_test.drop(columns=['Datetime (UTC)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07d72a8e-4df2-4255-bdb3-3353426389cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#electricity_prices_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "407a011b-3187-4e94-9c3a-e36c17253639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length, pred_length, label_length, curr_model):\n",
    "    seq_x = [] # storing for input seqiences\n",
    "    seq_y = [] # storing for output seqiences\n",
    "    for i in range(len(data) - seq_length - pred_length):\n",
    "        seq_x.append(data[i:i+seq_length])\n",
    "        if curr_model in [\"basis_former\", \"itransformer\", \"ns_autoformer\"]:\n",
    "          seq_y.append(data[i+seq_length-label_length:i+seq_length+pred_length])\n",
    "        else: ## only chronos\n",
    "          seq_y.append(data[i+seq_length:i+seq_length+pred_length])\n",
    "    return np.array(seq_x), np.array(seq_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c17fd64-77c4-42ab-9e63-bf919d801d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(seq_x, seq_y, seq_x_mark, seq_y_mark, batch_size, curr_model):\n",
    "    seq_x = torch.tensor(seq_x, dtype=torch.float32)\n",
    "    seq_y = torch.tensor(seq_y, dtype=torch.float32)\n",
    "    seq_x_mark = torch.tensor(seq_x_mark, dtype=torch.float32)\n",
    "    seq_y_mark = torch.tensor(seq_y_mark, dtype=torch.float32)\n",
    "    \n",
    "    if curr_model == \"basis_former\":\n",
    "        indices = []\n",
    "        total_len = len(seq_x)\n",
    "        for i in range(total_len):\n",
    "            index_list = np.arange(i, i + len(seq_x[0]) + len(seq_y[0]), 1)\n",
    "            norm_index = index_list / total_len\n",
    "            indices.append(norm_index)\n",
    "        indices = torch.tensor(indices, dtype=torch.float32)\n",
    "        dataset = TensorDataset(seq_x, seq_y, seq_x_mark, seq_y_mark, indices)\n",
    "    else:\n",
    "        dataset = TensorDataset(seq_x, seq_y, seq_x_mark, seq_y_mark)\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=2, shuffle=True, drop_last=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9598752-60c2-45e0-a3da-535bb910219e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2. Benchmark Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1627bd8d-ab8f-4f35-81c8-25b91760b230",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2.1. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb17613-c608-4a1b-b8dd-7773464d72b1",
   "metadata": {},
   "source": [
    "## 2.2. LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5a7ac4-ef50-4568-aeb2-ed1cec9d015f",
   "metadata": {},
   "source": [
    "# 3. Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cca768-c6f9-4d30-ad48-32c86e9ae2c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Chronos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f123e551-7804-404c-9565-bbc4afd4c007",
   "metadata": {},
   "source": [
    "zero shot evaluation with Chronos Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ef7efd7-9214-4d25-bca0-afe8d19cad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length, pred_length, label_length, curr_model):\n",
    "    seq_x = []  # storing for input sequences\n",
    "    seq_y = []  # storing for output sequences\n",
    "    for i in range(len(data) - seq_length - pred_length):\n",
    "        seq_x.append(data[i:i+seq_length])\n",
    "        if curr_model in [\"basis_former\", \"itransformer\", \"ns_autoformer\"]:\n",
    "            seq_y.append(data[i+seq_length-label_length:i+seq_length+pred_length])\n",
    "        elif curr_model == \"chronos\":\n",
    "            # For Chronos, we only need the input sequence\n",
    "            seq_y.append(data[i+seq_length])  # Single step forecast\n",
    "        else:\n",
    "            seq_y.append(data[i+seq_length:i+seq_length+pred_length])\n",
    "    return np.array(seq_x), np.array(seq_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8fa73ec-8a05-4565-b335-0886a508f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(seq_x, seq_y, seq_x_mark, seq_y_mark, batch_size, curr_model):\n",
    "    seq_x = torch.tensor(seq_x, dtype=torch.float32)\n",
    "    seq_y = torch.tensor(seq_y, dtype=torch.float32)\n",
    "    seq_x_mark = torch.tensor(seq_x_mark, dtype=torch.float32)\n",
    "    seq_y_mark = torch.tensor(seq_y_mark, dtype=torch.float32)\n",
    "    \n",
    "    if curr_model == \"basis_former\":\n",
    "        indices = []\n",
    "        total_len = len(seq_x)\n",
    "        for i in range(total_len):\n",
    "            index_list = np.arange(i, i + len(seq_x[0]) + len(seq_y[0]), 1)\n",
    "            norm_index = index_list / total_len\n",
    "            indices.append(norm_index)\n",
    "        indices = torch.tensor(indices, dtype=torch.float32)\n",
    "        dataset = TensorDataset(seq_x, seq_y, seq_x_mark, seq_y_mark, indices)\n",
    "    elif curr_model == \"chronos\":\n",
    "        # For Chronos, we only need the input sequence (seq_x)\n",
    "        dataset = TensorDataset(seq_x.reshape(seq_x.shape[0], -1))  # Flatten the input sequence\n",
    "    else:\n",
    "        dataset = TensorDataset(seq_x, seq_y, seq_x_mark, seq_y_mark)\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=2, shuffle=True, drop_last=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d4e2e76-e80a-45da-aba7-c82e5dae03b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ekaterinabasova/miniconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 8.33 GB, other allocations: 4.66 MB, max allowed: 9.07 GB). Tried to allocate 812.50 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 42\u001b[0m\n\u001b[1;32m     38\u001b[0m chronos_input \u001b[38;5;241m=\u001b[39m prepare_chronos_data(dataloader)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Now you can use chronos_input with your Chronos pipeline\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Assuming you have a Chronos pipeline already set up\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m forecast \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchronos_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Store the forecast results\u001b[39;00m\n\u001b[1;32m     49\u001b[0m results[country] \u001b[38;5;241m=\u001b[39m forecast\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/chronos/chronos.py:512\u001b[0m, in \u001b[0;36mChronosPipeline.predict\u001b[0;34m(self, context, prediction_length, num_samples, temperature, top_k, top_p, limit_prediction_length)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    509\u001b[0m     token_ids, attention_mask, scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mcontext_input_transform(\n\u001b[1;32m    510\u001b[0m         context_tensor\n\u001b[1;32m    511\u001b[0m     )\n\u001b[0;32m--> 512\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_length\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39moutput_transform(\n\u001b[1;32m    522\u001b[0m         samples\u001b[38;5;241m.\u001b[39mto(scale\u001b[38;5;241m.\u001b[39mdevice), scale\n\u001b[1;32m    523\u001b[0m     )\n\u001b[1;32m    525\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(prediction)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/chronos/chronos.py:336\u001b[0m, in \u001b[0;36mChronosModel.forward\u001b[0;34m(self, input_ids, attention_mask, prediction_length, num_samples, temperature, top_k, top_p)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m top_p \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    334\u001b[0m     top_p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtop_p\n\u001b[0;32m--> 336\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGenerationConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprediction_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprediction_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq2seq\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    353\u001b[0m     preds \u001b[38;5;241m=\u001b[39m preds[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# remove the decoder start token\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/generation/utils.py:1758\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1750\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1751\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1752\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1753\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1754\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1755\u001b[0m     )\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 1758\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1759\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1762\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1764\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1766\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1767\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1769\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   1770\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1771\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1772\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config) \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1773\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/generation/utils.py:2397\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2394\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2396\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2397\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2398\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2400\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2401\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2402\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2405\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:1740\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1737\u001b[0m         decoder_attention_mask \u001b[38;5;241m=\u001b[39m decoder_attention_mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mfirst_device)\n\u001b[1;32m   1739\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[0;32m-> 1740\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1749\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1753\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1755\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m decoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:1107\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1093\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[1;32m   1094\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         output_attentions,\n\u001b[1;32m   1105\u001b[0m     )\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1107\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:717\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    715\u001b[0m     query_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 717\u001b[0m cross_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    730\u001b[0m \u001b[38;5;66;03m# clamp inf values to enable fp16 training\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:628\u001b[0m, in \u001b[0;36mT5LayerCrossAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, query_length, output_attentions)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    617\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    625\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    626\u001b[0m ):\n\u001b[1;32m    627\u001b[0m     normed_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 628\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEncDecAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormed_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_value_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_output[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    640\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m attention_output[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:524\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    519\u001b[0m value_states \u001b[38;5;241m=\u001b[39m project(\n\u001b[1;32m    520\u001b[0m     hidden_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv, key_value_states, past_key_value[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    521\u001b[0m )\n\u001b[1;32m    523\u001b[0m \u001b[38;5;66;03m# compute scores\u001b[39;00m\n\u001b[0;32m--> 524\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# equivalent of torch.einsum(\"bnqd,bnkd->bnqk\", query_states, key_states), compatible with onnx op>9\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m position_bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_relative_attention_bias:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 8.33 GB, other allocations: 4.66 MB, max allowed: 9.07 GB). Tried to allocate 812.50 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "# Function to prepare data for Chronos\n",
    "def prepare_chronos_data(dataloader):\n",
    "    chronos_data = []\n",
    "    for batch in dataloader:\n",
    "        chronos_data.append(batch[0])  # Only take the first element (seq_x)\n",
    "    return torch.cat(chronos_data, dim=0)\n",
    "\n",
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-small\",\n",
    "    device_map=\"mps\",  # use \"cpu\" for CPU inference and \"mps\" for Apple Silicon\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "seq_length = 24\n",
    "pred_length = 12\n",
    "label_length = 12\n",
    "batch_size = 32\n",
    "countries = electricity_prices_train.columns.drop('Datetime (UTC)').tolist()\n",
    "seq_x_mark = timestamp_features_df.iloc[:len(electricity_prices_train)].drop(columns=['Datetime (UTC)']).values\n",
    "seq_y_mark = timestamp_features_df.iloc[len(electricity_prices_train):].drop(columns=['Datetime (UTC)']).values\n",
    "\n",
    "\n",
    "# Assume you have your data prepared as before\n",
    "# data, seq_x_mark, seq_y_mark = ...\n",
    "\n",
    "results = {}\n",
    "\n",
    "for country in countries:\n",
    "    # Extract data for the current country\n",
    "    country_data = electricity_prices_train_scaled[:, electricity_prices_train.columns.get_loc(country)]\n",
    "    \n",
    "    seq_x, seq_y = create_sequences(country_data, seq_length, pred_length, label_length, \"chronos\")\n",
    "    dataloader = create_dataloader(seq_x, seq_y, seq_x_mark, seq_y_mark, batch_size, \"chronos\")\n",
    "    \n",
    "    # Prepare data for Chronos\n",
    "    chronos_input = prepare_chronos_data(dataloader)\n",
    "    \n",
    "    # Now you can use chronos_input with your Chronos pipeline\n",
    "    # Assuming you have a Chronos pipeline already set up\n",
    "    forecast = pipeline.predict(\n",
    "        context=chronos_input,\n",
    "        prediction_length=pred_length,\n",
    "        num_samples=20,\n",
    "    )\n",
    "    \n",
    "    # Store the forecast results\n",
    "    results[country] = forecast\n",
    "    \n",
    "    print(f\"Completed forecast for {country}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c3f273-da3a-4f78-9b03-332f66114916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "def create_country_tensors(data: np.ndarray, timestamps: pd.DataFrame, sequence_length: int) -> Dict[str, List[torch.Tensor]]:\n",
    "    country_tensors = {}\n",
    "    \n",
    "    for i in range(data.shape[1]):  # Iterate through each country column\n",
    "        country_data = data[:, i]\n",
    "        \n",
    "        # Create sequences\n",
    "        X = []\n",
    "        for j in range(len(country_data) - sequence_length):\n",
    "            X.append(country_data[j:j+sequence_length])\n",
    "        \n",
    "        # Convert to tensor\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "        \n",
    "        # Create timestamp tensor\n",
    "        timestamp_tensor = torch.tensor(timestamps.iloc[sequence_length:].values, dtype=torch.float32)\n",
    "        \n",
    "        country_tensors[f\"Country_{i}\"] = [X_tensor, timestamp_tensor]\n",
    "    \n",
    "    return country_tensors\n",
    "\n",
    "# Define sequence length\n",
    "sequence_length = 24  # Adjust as needed\n",
    "\n",
    "# Create tensors for training data\n",
    "train_tensors = create_country_tensors(\n",
    "    electricity_prices_train_scaled, \n",
    "    timestamp_features_df.iloc[:train_size_timestamp], \n",
    "    sequence_length\n",
    ")\n",
    "\n",
    "# Create tensors for test data\n",
    "test_tensors = create_country_tensors(\n",
    "    electricity_prices_test_scaled, \n",
    "    timestamp_features_df.iloc[train_size_timestamp:], \n",
    "    sequence_length\n",
    ")\n",
    "\n",
    "# Function to predict using Chronos for a single country\n",
    "def predict_chronos(pipeline, country_data, prediction_length, num_samples):\n",
    "    forecast = pipeline.predict(\n",
    "        context=country_data[0],  # Use the price data tensor\n",
    "        prediction_length=prediction_length,\n",
    "        num_samples=num_samples,\n",
    "    )\n",
    "    return forecast\n",
    "\n",
    "# Loop through each country and make predictions\n",
    "results = {}\n",
    "for country, tensors in train_tensors.items():\n",
    "    # Assuming you have a Chronos pipeline already set up\n",
    "    forecast = predict_chronos(pipeline, tensors, prediction_length=12, num_samples=20)\n",
    "    results[country] = forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2617ec8b-f710-450b-81b1-1f8ce6f4fba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/amazon-science/chronos-forecasting.git\n",
    "import chronos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da473f90-664c-449e-9396-dc9d8adf3ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "seq_length = 48 # one week\n",
    "pred_length = 48 # two days ahead\n",
    "label_length = 48\n",
    "curr_model = \"chronos\"\n",
    "\n",
    "train_seq_x, train_seq_y = create_sequences(electricity_prices_train_scaled, seq_length, pred_length, label_length, curr_model)\n",
    "train_seq_x_mark, train_seq_y_mark = create_sequences(timestamp_features_train.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "\n",
    "test_seq_x, test_seq_y = create_sequences(electricity_prices_test_scaled, seq_length, pred_length,label_length, curr_model)\n",
    "test_seq_x_mark, test_seq_y_mark = create_sequences(timestamp_features_test.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "\n",
    "# converting sequences to PyTorch DataLoader objects\n",
    "train_loader = create_dataloader(train_seq_x, train_seq_y, train_seq_x_mark, train_seq_y_mark, batch_size, curr_model)\n",
    "test_loader = create_dataloader(test_seq_x, test_seq_y, test_seq_x_mark, test_seq_y_mark, batch_size, curr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99270086-7efc-4968-9720-98413902bdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample testing sequence x: [[-1.47514259 -1.49006706 -1.56686779 ... -0.29106655 -1.84177497\n",
      "  -0.90996892]\n",
      " [-1.67138901 -1.71409752 -1.76082611 ... -0.49449098 -1.76060728\n",
      "  -1.31408237]\n",
      " [-1.66016387 -1.79509619 -1.74650184 ... -0.60904395 -1.71469425\n",
      "  -1.39936291]\n",
      " ...\n",
      " [ 0.65492464 -0.15813289  0.81173485 ... -0.29613526 -1.88891783\n",
      "   0.61635889]\n",
      " [ 0.53802835 -0.37781708  0.56860945 ... -0.62391218 -1.953688\n",
      "   0.39492022]\n",
      " [ 0.5388025  -0.51887329  0.50318239 ... -0.76076749 -1.95204825\n",
      "   0.20836905]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample testing sequence x:\", test_seq_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22e68564-a944-4a6f-b55d-9230a32c9a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch shape: torch.Size([8, 48, 24])\n",
      "Output batch shape: torch.Size([8, 48, 24])\n",
      "Input mark shape: torch.Size([8, 48, 4])\n",
      "Output mark shape: torch.Size([8, 48, 4])\n"
     ]
    }
   ],
   "source": [
    "# Check the dimensions\n",
    "for batch in test_loader:\n",
    "    batch_x, batch_y, batch_x_mark, batch_y_mark = batch\n",
    "    print(f'Input batch shape: {batch_x.shape}')\n",
    "    print(f'Output batch shape: {batch_y.shape}')\n",
    "    print(f'Input mark shape: {batch_x_mark.shape}')\n",
    "    print(f'Output mark shape: {batch_y_mark.shape}')\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0297963a-162b-417c-9d36-eff09e474633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Get forecasts for the given time series.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        context\n",
      "            Input series. This is either a 1D tensor, or a list\n",
      "            of 1D tensors, or a 2D tensor whose first dimension\n",
      "            is batch. In the latter case, use left-padding with\n",
      "            ``torch.nan`` to align series of different lengths.\n",
      "        prediction_length\n",
      "            Time steps to predict. Defaults to what specified\n",
      "            in ``self.model.config``.\n",
      "        num_samples\n",
      "            Number of sample paths to predict. Defaults to what\n",
      "            specified in ``self.model.config``.\n",
      "        temperature\n",
      "            Temperature to use for generating sample tokens.\n",
      "            Defaults to what specified in ``self.model.config``.\n",
      "        top_k\n",
      "            Top-k parameter to use for generating sample tokens.\n",
      "            Defaults to what specified in ``self.model.config``.\n",
      "        top_p\n",
      "            Top-p parameter to use for generating sample tokens.\n",
      "            Defaults to what specified in ``self.model.config``.\n",
      "        limit_prediction_length\n",
      "            Force prediction length smaller or equal than the\n",
      "            built-in prediction length from the model. True by\n",
      "            default. When true, fail loudly if longer predictions\n",
      "            are requested, otherwise longer predictions are allowed.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        samples\n",
      "            Tensor of sample forecasts, of shape\n",
      "            (batch_size, num_samples, prediction_length).\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "from chronos import ChronosPipeline\n",
    "print(ChronosPipeline.predict.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7a7e22-51e5-4c3c-b3f2-d51498587192",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_loader:\n",
    "    print(batch)\n",
    "    break  # Print only the first batch and break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bd82e9-d24f-4a39-9a5c-77821d6b2667",
   "metadata": {},
   "source": [
    "1. Pad Sequences to the Same Length: Ensure all sequences within a batch have the same length.\n",
    "2. Flatten the Padded Sequences: Convert the 3D tensor [batch_size, seq_length, num_features] to a 2D tensor [total_sequences, seq_length * num_features]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4fd1366b-cc21-4f51-8478-daa1b37c0ebc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ChronosPipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m----> 4\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mChronosPipeline\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mamazon/chronos-t5-small\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16,  \u001b[38;5;66;03m# Change to torch.float16 if necessary\u001b[39;00m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# padding sequences within a batch\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpad_sequence\u001b[39m(sequences, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding_value\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mnan):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ChronosPipeline' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-small\",\n",
    "    device_map=\"cpu\",\n",
    "    torch_dtype=torch.bfloat16,  # Change to torch.float16 if necessary\n",
    ")\n",
    "\n",
    "\n",
    "# padding sequences within a batch\n",
    "def pad_sequence(sequences, batch_first=True, padding_value=torch.nan):\n",
    "    return torch.nn.utils.rnn.pad_sequence(sequences, batch_first=batch_first, padding_value=padding_value)\n",
    "\n",
    "def pad_batch(batch):\n",
    "    input_ids = batch[0]\n",
    "    sequences = [input_ids[i] for i in range(input_ids.size(0))]\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True)\n",
    "    return padded_sequences\n",
    "\n",
    "context = []\n",
    "\n",
    "# Iterate over the DataLoader to extract and pad input_ids\n",
    "for batch in test_loader:\n",
    "    input_ids_padded = pad_batch(batch)\n",
    "    context.append(input_ids_padded)\n",
    "\n",
    "# Concatenate the padded tensors to form a 3D tensor\n",
    "context_tensor_3d = torch.cat(context, dim=0)  # Concatenate along the batch dimension\n",
    "\n",
    "# Flatten the 3D tensor to 2D\n",
    "batch_size, seq_length, num_features = context_tensor_3d.shape\n",
    "context_tensor_2d = context_tensor_3d.view(batch_size, -1)\n",
    "\n",
    "# Now you can use the context tensor with your pipeline\n",
    "print(context_tensor_2d.shape)  # To verify the shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fb6121-1efc-4234-91af-39611924149f",
   "metadata": {},
   "source": [
    "This transformation suggests that each batch of size 24 (sequences) with 96 time steps and 24 features per time step has been flattened into a single 2D tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47829b56-b79b-4efe-9eba-2bfbbad6fea6",
   "metadata": {},
   "source": [
    "Original Shape:\n",
    "Batch size: 24\n",
    "Sequence length: 96\n",
    "Number of features: 24\n",
    "\n",
    "Flattened Shape Calculation:\n",
    "Flattened feature size: 96Ã—24=2304\n",
    "Total number of sequences (batches) after concatenation: 16200\n",
    "\n",
    "\n",
    "The pipeline will process each of these 16,200 sequences, each with 2,304 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632d0df2-a154-46ec-9987-8bba8f396338",
   "metadata": {},
   "outputs": [],
   "source": [
    "del context\n",
    "del context_tensor_3d\n",
    "\n",
    "# predictions\n",
    "# 1 hour of running for 2 months\n",
    "forecast = pipeline.predict(\n",
    "    context=context_tensor_2d,\n",
    "    prediction_length=48,\n",
    "    num_samples=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bba3dd-02a1-4d90-a50b-e11362b3d12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f90544-308f-40b0-a176-45d74c0ba5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the forecast to a numpy array\n",
    "forecast_np = forecast[0].numpy()\n",
    "\n",
    "# Check the shape of forecast_np\n",
    "print(forecast_np.shape)  # This should print (num_samples, prediction_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6c5993-5e40-485a-888d-331dd33b7e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_reshaped = forecast_np.flatten()  # Flatten to (48,)\n",
    "forecast_reshaped = forecast_reshaped.reshape(-1, 1)  # Reshape to (48, 1)\n",
    "print(forecast_reshaped.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ecf9cb-e4f4-4468-9818-c8c6fbf950c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_forecast = (forecast_reshaped * scaler.scale_[0]) + scaler.mean_[0]\n",
    "rescaled_forecast = rescaled_forecast.reshape(forecast_np.shape)\n",
    "print(rescaled_forecast.shape)  # Should print (1, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63fa5d6-0f1e-4c29-924c-aa327b8351e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_index = range(len(electricity_prices_test_scaled), len(electricity_prices_test_scaled) + 48)\n",
    "\n",
    "# Compute quantiles for the forecast\n",
    "low, median, high = np.quantile(forecast, [0.1, 0.5, 0.9], axis=0)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(range(len(electricity_prices_test_scaled)), electricity_prices_test_scaled, color=\"royalblue\", label=\"historical data\")\n",
    "plt.plot(forecast_index, median, color=\"tomato\", label=\"median forecast\")\n",
    "plt.fill_between(forecast_index, low, high, color=\"tomato\", alpha=0.3, label=\"80% prediction interval\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Electricity Prices')\n",
    "plt.title('Electricity Prices Forecast')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ee0fbc-fd5f-4b8e-99f0-e0d05ff0826d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Basisformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df01bc9-9596-49f6-ace9-1acf18f1c23e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ILk9LX4k5Yuu",
   "metadata": {
    "id": "ILk9LX4k5Yuu"
   },
   "outputs": [],
   "source": [
    "seq_length = 96\n",
    "pred_length = 48\n",
    "label_length = 48\n",
    "curr_model = \"basis_former\"\n",
    "\n",
    "train_seq_x, train_seq_y = create_sequences(electricity_prices_train_scaled, seq_length, pred_length, label_length, curr_model)\n",
    "train_seq_x_mark, train_seq_y_mark = create_sequences(timestamp_features_train.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "\n",
    "test_seq_x, test_seq_y = create_sequences(electricity_prices_test_scaled, seq_length, pred_length,label_length, curr_model)\n",
    "test_seq_x_mark, test_seq_y_mark = create_sequences(timestamp_features_test.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IeE-jvzOEVw-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IeE-jvzOEVw-",
    "outputId": "d4778504-79d4-475b-c868-17b3994fd3fc"
   },
   "outputs": [],
   "source": [
    "print(\"Sample training sequence x:\", train_seq_x[0])\n",
    "print(\"Sample training sequence y:\", train_seq_y[0])\n",
    "print(\"Sample training sequence x mark:\", train_seq_x_mark[0])\n",
    "print(\"Sample training sequence y mark:\", train_seq_y_mark[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OrL7qSyl5bqB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OrL7qSyl5bqB",
    "outputId": "01496ef4-4d84-4630-dc4b-5a1b9c36a404"
   },
   "outputs": [],
   "source": [
    "batch_size = 24\n",
    "\n",
    "# converting sequences to PyTorch DataLoader objects\n",
    "train_loader = create_dataloader(train_seq_x, train_seq_y, train_seq_x_mark, train_seq_y_mark, batch_size, curr_model)\n",
    "test_loader = create_dataloader(test_seq_x, test_seq_y, test_seq_x_mark, test_seq_y_mark, batch_size, curr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca8679b-4ac1-42ab-8065-f6f2519e40cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    print(f\"Batch contains {len(batch)} items:\")\n",
    "    for i, item in enumerate(batch):\n",
    "        print(f\"Item {i}: Shape = {item.shape if torch.is_tensor(item) else 'Not a tensor'}\")\n",
    "    break  # Just print the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Des1ClFuevfI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Des1ClFuevfI",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "538a4886-5959-4a8c-a4e8-3239df3ed5ec"
   },
   "outputs": [],
   "source": [
    "##pip install adabelief_pytorch==0.2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c7af02-3c5d-4a35-a1e1-ed6266bed132",
   "metadata": {},
   "source": [
    "### Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f18f708-9681-4f6a-b70b-0ad9009722f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import Basisformer.model\n",
    "importlib.reload(Basisformer.model)\n",
    "from Basisformer.model import Basisformer\n",
    "\n",
    "import Basisformer.main\n",
    "importlib.reload(Basisformer.main)\n",
    "from Basisformer.main import parse_args, model_setup, log_and_print\n",
    "\n",
    "args = parse_args()\n",
    "\n",
    "# Set up device\n",
    "device = torch.device(f\"cuda:{args.device}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set up model\n",
    "model = model_setup(args, device)\n",
    "\n",
    "# Log arguments and model\n",
    "log_and_print('Args in experiment:')\n",
    "log_and_print(args)\n",
    "log_and_print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25388088-0a01-4a53-9327-36baeb5ec317",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d34df7-21cb-4303-87f9-d5ec8c03ec8e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33d34df7-21cb-4303-87f9-d5ec8c03ec8e",
    "outputId": "3c5fe222-fb0a-4abc-d84a-489ef41b44b1"
   },
   "outputs": [],
   "source": [
    "import Basisformer.model\n",
    "importlib.reload(Basisformer.model)\n",
    "from Basisformer.model import Basisformer\n",
    "\n",
    "import Basisformer.main\n",
    "importlib.reload(Basisformer.main)\n",
    "from Basisformer.main import train\n",
    "\n",
    "\n",
    "record_dir = os.path.join('records', args.data_path.split('.')[0], 'features_' + args.features,\n",
    "                          'seq_len' + str(args.seq_len) + ',' + 'pred_len' + str(args.pred_len))\n",
    "\n",
    "# Call the train function\n",
    "train(model, train_loader, args, device, record_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886eefd2-4847-4504-a105-5d4fa9396aef",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j59FnuQFNHcV",
   "metadata": {
    "id": "j59FnuQFNHcV"
   },
   "outputs": [],
   "source": [
    "import Basisformer.main\n",
    "importlib.reload(Basisformer.main)\n",
    "from Basisformer.main import test\n",
    "\n",
    "test(model, test_loader, args, device, record_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1803a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "basisformer_train = train\n",
    "basisformer_test = test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ffc309-339b-43e4-ab87-1e1ece074e45",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## iTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf6cf6e-e6dc-41fd-a14e-db5a55912360",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 96\n",
    "pred_length = 48\n",
    "label_length = 48\n",
    "curr_model = \"itransformer\"\n",
    "batch_size = 24\n",
    "\n",
    "train_seq_x, train_seq_y = create_sequences(electricity_prices_train_scaled, seq_length, pred_length, label_length, curr_model)\n",
    "train_seq_x_mark, train_seq_y_mark = create_sequences(timestamp_features_train.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "test_seq_x, test_seq_y = create_sequences(electricity_prices_test_scaled, seq_length, pred_length,label_length, curr_model)\n",
    "test_seq_x_mark, test_seq_y_mark = create_sequences(timestamp_features_test.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "batch_size = 24\n",
    "\n",
    "# converting sequences to PyTorch DataLoader objects\n",
    "train_loader = create_dataloader(train_seq_x, train_seq_y, train_seq_x_mark, train_seq_y_mark, batch_size, curr_model)\n",
    "test_loader = create_dataloader(test_seq_x, test_seq_y, test_seq_x_mark, test_seq_y_mark, batch_size, curr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eb6eb6-1970-4b57-8a82-2851c125fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Sample training sequence x:\", train_seq_x[0])\n",
    "# print(\"Sample training sequence y:\", train_seq_y[0])\n",
    "# print(\"Sample training sequence x mark:\", train_seq_x_mark[0])\n",
    "# print(\"Sample training sequence y mark:\", train_seq_y_mark[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a08286-785d-43a8-960d-bceca7822558",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    print(f\"Batch contains {len(batch)} items:\")\n",
    "    for i, item in enumerate(batch):\n",
    "        print(f\"Item {i}: Shape = {item.shape if torch.is_tensor(item) else 'Not a tensor'}\")\n",
    "    break  # Just print the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dac7e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "# Commented out because model is imported in experiment.py\n",
    "# import iTransformer.Model \n",
    "# importlib.reload(iTransformer.Model)\n",
    "# from iTransformer.Model import Model, Config\n",
    "\n",
    "# Commented because both the imported functions are throwing errors\n",
    "import iTransformer.main\n",
    "importlib.reload(iTransformer.main)\n",
    "from iTransformer.main import parse_args_itrans, long_term_forecast\n",
    "\n",
    "import iTransformer.experiment\n",
    "importlib.reload(iTransformer.experiment)\n",
    "from iTransformer.experiment import Exp_Long_Term_Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0503782-999a-4ec6-a856-82281b291341",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    is_training = 1\n",
    "    model_id = 'iTransformer_train'\n",
    "    model = 'iTransformer'\n",
    "    data = 'all_countries'\n",
    "    features = 'M'\n",
    "    target = 'OT'\n",
    "    freq = 'h'\n",
    "    checkpoints = './checkpoints/'\n",
    "    seq_len = 96\n",
    "    label_len = 48\n",
    "    pred_len = 48\n",
    "    enc_in = 24\n",
    "    dec_in = 24\n",
    "    c_out = 24\n",
    "    d_model = 512\n",
    "    n_heads = 8\n",
    "    e_layers = 2\n",
    "    d_layers = 1\n",
    "    d_ff = 2048\n",
    "    moving_avg = 25\n",
    "    factor = 1\n",
    "    distil = True\n",
    "    dropout = 0.05\n",
    "    embed = 'timeF'\n",
    "    activation = 'gelu'\n",
    "    output_attention = False\n",
    "    do_predict = True\n",
    "    num_workers = 10\n",
    "    itr = 2\n",
    "    train_epochs = 1\n",
    "    batch_size = 32\n",
    "    patience = 3\n",
    "    learning_rate = 0.0001\n",
    "    des = 'test'\n",
    "    loss = 'mse'\n",
    "    lradj = 'type1'\n",
    "    use_amp = False\n",
    "    use_gpu = True if torch.cuda.is_available() else False\n",
    "    gpu = 0\n",
    "    use_multi_gpu = False\n",
    "    devices = '0,1,2,3'\n",
    "    exp_name = 'MTSF'\n",
    "    channel_independence = False\n",
    "    inverse = False\n",
    "    class_strategy = 'projection'\n",
    "    target_root_path = './data'\n",
    "    target_data_path = 'all_countries'\n",
    "    efficient_training = False\n",
    "    use_norm = True\n",
    "    partial_start_index = 0\n",
    "    seed = 2021\n",
    "    p_hidden_dims = [128, 128]\n",
    "    p_hidden_layers = 2\n",
    "\n",
    "args = Args()\n",
    "\n",
    "if args.use_gpu:\n",
    "    if args.use_multi_gpu:\n",
    "        args.devices = args.devices.replace(' ', '')\n",
    "        device_ids = args.devices.split(',')\n",
    "        args.device_ids = [int(id_) for id_ in device_ids]\n",
    "        args.gpu = args.device_ids[0]\n",
    "    else:\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "\n",
    "# Initialize the experiment\n",
    "exp = Exp_Long_Term_Forecast(args) #long_term_forecast(args) #, train_loader, test_loader)\n",
    "\n",
    "# Define the settings\n",
    "setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}'.format(\n",
    "    args.model_id, args.model, args.data, args.features, args.seq_len, args.label_len,\n",
    "    args.pred_len, args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff,\n",
    "    args.factor, args.embed, args.distil, args.des, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca24c83-5c85-41d7-adfb-4b679d9bb9cf",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7177faa3-8546-4f9f-bfdb-5fa3c72fa657",
   "metadata": {},
   "outputs": [],
   "source": [
    "Exp_Long_Term_Forecast.train(self=exp, train_loader=train_loader, setting=setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b770d7dc-c343-4c42-84ee-ab3ab9c3cd1e",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ce0485-c648-48ee-b860-b7bd40e578e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Exp_Long_Term_Forecast.test(self=exp, test_loader=test_loader, setting=setting, test=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1866cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# itransformer_train = Exp_Long_Term_Forecast.train()\n",
    "# itransformer_test = Exp_Long_Term_Forecast.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa62ae11-381d-4aaf-9e32-ade675824eeb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Nonstationary Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a8451f-0280-4b1d-83f4-645080a0ebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 96\n",
    "pred_length = 48\n",
    "label_length = 48\n",
    "curr_model = \"ns_autoformer\"\n",
    "\n",
    "train_seq_x, train_seq_y = create_sequences(electricity_prices_train_scaled, seq_length, pred_length, label_length, curr_model)\n",
    "train_seq_x_mark, train_seq_y_mark = create_sequences(timestamp_features_train.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "\n",
    "test_seq_x, test_seq_y = create_sequences(electricity_prices_test_scaled, seq_length, pred_length,label_length, curr_model)\n",
    "test_seq_x_mark, test_seq_y_mark = create_sequences(timestamp_features_test.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "batch_size = 24\n",
    "\n",
    "# converting sequences to PyTorch DataLoader objects\n",
    "train_loader = create_dataloader(train_seq_x, train_seq_y, train_seq_x_mark, train_seq_y_mark, batch_size, curr_model)\n",
    "test_loader = create_dataloader(test_seq_x, test_seq_y, test_seq_x_mark, test_seq_y_mark, batch_size, curr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5613fe15-f1ce-403c-ab95-885a612b9a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    print(f\"Batch contains {len(batch)} items:\")\n",
    "    for i, item in enumerate(batch):\n",
    "        print(f\"Item {i}: Shape = {item.shape if torch.is_tensor(item) else 'Not a tensor'}\")\n",
    "    break  # Just print the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376fd372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import ns_Autoformer.ns_Autoformer\n",
    "importlib.reload(ns_Autoformer.ns_Autoformer)\n",
    "from ns_Autoformer.ns_Autoformer import Model\n",
    "\n",
    "import ns_Autoformer.main\n",
    "importlib.reload(ns_Autoformer.main)\n",
    "from ns_Autoformer.main import parse_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d461a9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ns_Autoformer.main import Exp_Main\n",
    "\n",
    "# setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}'.format(\n",
    "#     args.model_id, args.model, args.features, args.seq_len, args.label_len,\n",
    "#     args.pred_len, args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff,\n",
    "#     args.factor, args.embed, args.distil, args.des, 0)\n",
    "\n",
    "# exp = Exp_Main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eafce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ns_Autoformer.main import Exp_Main\n",
    "\n",
    "class Args:\n",
    "    is_training = 1\n",
    "    model_id = 'ns_autoformer_train'\n",
    "    model = 'ns_Autoformer'\n",
    "    features = 'M'\n",
    "    target = 'OT'\n",
    "    freq = 'h'\n",
    "    checkpoints = './checkpoints/'\n",
    "    seq_len = 96\n",
    "    label_len = 48\n",
    "    pred_len = 48\n",
    "    enc_in = 24\n",
    "    dec_in = 24\n",
    "    c_out = 24\n",
    "    d_model = 512\n",
    "    n_heads = 8\n",
    "    e_layers = 2\n",
    "    d_layers = 1\n",
    "    d_ff = 2048\n",
    "    moving_avg = 25\n",
    "    factor = 1\n",
    "    distil = True\n",
    "    dropout = 0.05\n",
    "    embed = 'timeF'\n",
    "    activation = 'gelu'\n",
    "    output_attention = False\n",
    "    do_predict = True\n",
    "    num_workers = 10\n",
    "    itr = 2\n",
    "    train_epochs = 1\n",
    "    batch_size = 32\n",
    "    patience = 3\n",
    "    learning_rate = 0.0001\n",
    "    des = 'test'\n",
    "    loss = 'mse'\n",
    "    lradj = 'type1'\n",
    "    use_amp = False\n",
    "    use_gpu = True if torch.cuda.is_available() else False\n",
    "    gpu = 0\n",
    "    use_multi_gpu = False\n",
    "    devices = '0,1,2,3'\n",
    "    seed = 2021\n",
    "    p_hidden_dims = [128, 128]\n",
    "    p_hidden_layers = 2\n",
    "\n",
    "args = Args()\n",
    "\n",
    "if args.use_gpu:\n",
    "    if args.use_multi_gpu:\n",
    "        args.devices = args.devices.replace(' ', '')\n",
    "        device_ids = args.devices.split(',')\n",
    "        args.device_ids = [int(id_) for id_ in device_ids]\n",
    "        args.gpu = args.device_ids[0]\n",
    "    else:\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "\n",
    "print('Args in experiment:')\n",
    "print(args)\n",
    "\n",
    "# Initialize the experiment\n",
    "exp = Exp_Main(args)\n",
    "\n",
    "# Define the setting string\n",
    "setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}'.format(\n",
    "    args.model_id, args.model, args.features, args.seq_len, args.label_len,\n",
    "    args.pred_len, args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff,\n",
    "    args.factor, args.embed, args.distil, args.des, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ba12b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ns_Autoformer.main import Exp_Main\n",
    "\n",
    "Exp_Main.train(self=exp, train_loader=train_loader, setting=setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ea5a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "Exp_Main.test(self=exp, test_loader=test_loader, setting=setting, test=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbdc742",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_autoformer_train = Exp_Main.train\n",
    "ns_autoformer_test = Exp_Main.test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b714a69-118b-466b-a1f7-a9de9b3d0427",
   "metadata": {},
   "source": [
    "# 4. Experimental Design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c49845",
   "metadata": {},
   "source": [
    "## Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fa8cd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(f\"cuda:{args.device}\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8548e1f7",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f6a0895",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 96\n",
    "pred_length = 48\n",
    "label_length = 48\n",
    "curr_model = \"basis_former\"\n",
    "\n",
    "train_seq_x, train_seq_y = create_sequences(electricity_prices_train_scaled, seq_length, pred_length, label_length, curr_model)\n",
    "train_seq_x_mark, train_seq_y_mark = create_sequences(timestamp_features_train.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n",
    "\n",
    "\n",
    "test_seq_x, test_seq_y = create_sequences(electricity_prices_test_scaled, seq_length, pred_length,label_length, curr_model)\n",
    "test_seq_x_mark, test_seq_y_mark = create_sequences(timestamp_features_test.drop(columns=['Datetime (UTC)']).values, seq_length, pred_length, label_length, curr_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ce08587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y8/hhkwp1r54qg4ztcfjzk9c2800000gn/T/ipykernel_34711/2035128206.py:14: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1712608635429/work/torch/csrc/utils/tensor_new.cpp:277.)\n",
      "  indices = torch.tensor(indices, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 24\n",
    "\n",
    "# converting sequences to PyTorch DataLoader objects\n",
    "train_loader = create_dataloader(train_seq_x, train_seq_y, train_seq_x_mark, train_seq_y_mark, batch_size, curr_model)\n",
    "test_loader = create_dataloader(test_seq_x, test_seq_y, test_seq_x_mark, test_seq_y_mark, batch_size, curr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652b7a2b",
   "metadata": {},
   "source": [
    "## Unification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10670e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit (model, train_flag, test_flag, train_loader=None, test_loader=None, pretrained_model=None):\n",
    "    '''Fits a transformer model to the train and/or test loaders\n",
    "    \n",
    "    model - \"basis_former\", \"itransformer\", \"ns_autoformer\"\n",
    "    \n",
    "    train_flag: typ(bool) - True: to train the model on train_loader, False: if pretrained_model is passed\n",
    "    \n",
    "    test_flag: typ(bool) - True: to test on test_loader, False: if only training\n",
    "    \n",
    "    pretrained_model - pass a pretrained model if available to be fitted on a test_loader. \n",
    "    eg. fit(basis_former, train_flag=False, test_flag=True, test_loader=test_loader, pretrained_model=model)\n",
    "    '''\n",
    "    \n",
    "    if curr_model == 'basis_former':\n",
    "        # Code for Basisforme\n",
    "\n",
    "        import Basisformer.model\n",
    "        importlib.reload(Basisformer.model)\n",
    "        from Basisformer.model import Basisformer\n",
    "\n",
    "        import Basisformer.main\n",
    "        importlib.reload(Basisformer.main)\n",
    "        from Basisformer.main import parse_args, model_setup, log_and_print\n",
    "\n",
    "        args = parse_args()\n",
    "        \n",
    "        if pretrained_model == None:\n",
    "            # Set up model\n",
    "            model = model_setup(args, device)\n",
    "\n",
    "        else:\n",
    "            model = pretrained_model\n",
    "\n",
    "        # Log arguments and model\n",
    "        log_and_print('Args in experiment:')\n",
    "        log_and_print(args)\n",
    "        log_and_print(model)\n",
    "        \n",
    "        if train_flag:\n",
    "            import Basisformer.model\n",
    "            importlib.reload(Basisformer.model)\n",
    "            from Basisformer.model import Basisformer\n",
    "\n",
    "            import Basisformer.main\n",
    "            importlib.reload(Basisformer.main)\n",
    "            from Basisformer.main import train\n",
    "\n",
    "\n",
    "            record_dir = os.path.join('records', args.data_path.split('.')[0], 'features_' + args.features,\n",
    "                                    'seq_len' + str(args.seq_len) + ',' + 'pred_len' + str(args.pred_len))\n",
    "            \n",
    "            if train_loader == None:\n",
    "                return 'train_loader not found'\n",
    "\n",
    "            # Call the train function\n",
    "            train(model, train_loader, args, device, record_dir)\n",
    "            \n",
    "        else:\n",
    "            if pretrained_model == None:\n",
    "                return 'model not found which is required for testing'\n",
    "            \n",
    "        if test_flag :\n",
    "            import Basisformer.main\n",
    "            importlib.reload(Basisformer.main)\n",
    "            from Basisformer.main import test\n",
    "            \n",
    "            if test_loader == None:\n",
    "                return 'test_loader not found'\n",
    "\n",
    "            test(model, test_loader, args, device, record_dir)\n",
    "        return model\n",
    "            \n",
    "    \n",
    "    elif curr_model == 'itransformer':\n",
    "        # code for itransformer\n",
    "        \n",
    "        import iTransformer.experiment\n",
    "        importlib.reload(iTransformer.experiment)\n",
    "        from iTransformer.experiment import Exp_Long_Term_Forecast\n",
    "        \n",
    "        from iTransformer import Model\n",
    "        \n",
    "        class Args:\n",
    "            is_training = 1\n",
    "            model_id = 'iTransformer_train'\n",
    "            model = 'iTransformer'\n",
    "            data = 'all_countries'\n",
    "            features = 'M'\n",
    "            target = 'OT'\n",
    "            freq = 'h'\n",
    "            checkpoints = './checkpoints/'\n",
    "            seq_len = 96\n",
    "            label_len = 48\n",
    "            pred_len = 48\n",
    "            enc_in = 24\n",
    "            dec_in = 24\n",
    "            c_out = 24\n",
    "            d_model = 512\n",
    "            n_heads = 8\n",
    "            e_layers = 2\n",
    "            d_layers = 1\n",
    "            d_ff = 2048\n",
    "            moving_avg = 25\n",
    "            factor = 1\n",
    "            distil = True\n",
    "            dropout = 0.05\n",
    "            embed = 'timeF'\n",
    "            activation = 'gelu'\n",
    "            output_attention = False\n",
    "            do_predict = True\n",
    "            num_workers = 10\n",
    "            itr = 2\n",
    "            train_epochs = 1\n",
    "            batch_size = 32\n",
    "            patience = 3\n",
    "            learning_rate = 0.0001\n",
    "            des = 'test'\n",
    "            loss = 'mse'\n",
    "            lradj = 'type1'\n",
    "            use_amp = False\n",
    "            use_gpu = True if torch.cuda.is_available() else False\n",
    "            gpu = 0\n",
    "            use_multi_gpu = False\n",
    "            devices = '0,1,2,3'\n",
    "            exp_name = 'MTSF'\n",
    "            channel_independence = False\n",
    "            inverse = False\n",
    "            class_strategy = 'projection'\n",
    "            target_root_path = './data'\n",
    "            target_data_path = 'all_countries'\n",
    "            efficient_training = False\n",
    "            use_norm = True\n",
    "            partial_start_index = 0\n",
    "            seed = 2021\n",
    "            p_hidden_dims = [128, 128]\n",
    "            p_hidden_layers = 2\n",
    "\n",
    "        args = Args()\n",
    "        \n",
    "        if pretrained_model == None:\n",
    "            # Initialize the experiment\n",
    "            exp = Exp_Long_Term_Forecast(args)\n",
    "\n",
    "        else:\n",
    "            return 'pretrained not valid for iTransformer and ns_autoformer'\n",
    "\n",
    "        # Define the settings\n",
    "        setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}'.format(\n",
    "            args.model_id, args.model, args.data, args.features, args.seq_len, args.label_len,\n",
    "            args.pred_len, args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff,\n",
    "            args.factor, args.embed, args.distil, args.des, 0)\n",
    "        \n",
    "        if train_flag:\n",
    "            Exp_Long_Term_Forecast.train(self=exp, train_loader=train_loader, setting=setting)\n",
    "        \n",
    "        if test_flag:\n",
    "            Exp_Long_Term_Forecast.test(self=exp, test_loader=test_loader, setting=setting, test=0)\n",
    "        return exp.model\n",
    "    \n",
    "    elif curr_model == 'ns_autoformer':\n",
    "        # code for itransformer\n",
    "        import ns_Autoformer.ns_Autoformer\n",
    "        importlib.reload(ns_Autoformer.ns_Autoformer)\n",
    "        from ns_Autoformer.ns_Autoformer import Model\n",
    "\n",
    "        # import ns_Autoformer.main\n",
    "        # importlib.reload(ns_Autoformer.main)\n",
    "        # from ns_Autoformer.main import parse_args\n",
    "        \n",
    "        from ns_Autoformer.main import Exp_Main\n",
    "\n",
    "        class Args:\n",
    "            is_training = 1\n",
    "            model_id = 'ns_autoformer_train'\n",
    "            model = 'ns_Autoformer'\n",
    "            features = 'M'\n",
    "            target = 'OT'\n",
    "            freq = 'h'\n",
    "            checkpoints = './checkpoints/'\n",
    "            seq_len = 96\n",
    "            label_len = 48\n",
    "            pred_len = 48\n",
    "            enc_in = 24\n",
    "            dec_in = 24\n",
    "            c_out = 24\n",
    "            d_model = 512\n",
    "            n_heads = 8\n",
    "            e_layers = 2\n",
    "            d_layers = 1\n",
    "            d_ff = 2048\n",
    "            moving_avg = 25\n",
    "            factor = 1\n",
    "            distil = True\n",
    "            dropout = 0.05\n",
    "            embed = 'timeF'\n",
    "            activation = 'gelu'\n",
    "            output_attention = False\n",
    "            do_predict = True\n",
    "            num_workers = 10\n",
    "            itr = 2\n",
    "            train_epochs = 1\n",
    "            batch_size = 32\n",
    "            patience = 3\n",
    "            learning_rate = 0.0001\n",
    "            des = 'test'\n",
    "            loss = 'mse'\n",
    "            lradj = 'type1'\n",
    "            use_amp = False\n",
    "            use_gpu = True if torch.cuda.is_available() else False\n",
    "            gpu = 0\n",
    "            use_multi_gpu = False\n",
    "            devices = '0,1,2,3'\n",
    "            seed = 2021\n",
    "            p_hidden_dims = [128, 128]\n",
    "            p_hidden_layers = 2\n",
    "\n",
    "        args = Args()\n",
    "\n",
    "        # if args.use_gpu:\n",
    "        #     if args.use_multi_gpu:\n",
    "        #         args.devices = args.devices.replace(' ', '')\n",
    "        #         device_ids = args.devices.split(',')\n",
    "        #         args.device_ids = [int(id_) for id_ in device_ids]\n",
    "        #         args.gpu = args.device_ids[0]\n",
    "        #     else:\n",
    "        #         torch.cuda.set_device(args.gpu)\n",
    "\n",
    "        # print('Args in experiment:')\n",
    "        # print(args)\n",
    "\n",
    "        # Initialize the experiment\n",
    "        exp = Exp_Main(args)\n",
    "\n",
    "        # Define the setting string\n",
    "        setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}'.format(\n",
    "            args.model_id, args.model, args.features, args.seq_len, args.label_len,\n",
    "            args.pred_len, args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff,\n",
    "            args.factor, args.embed, args.distil, args.des, 0)\n",
    "        \n",
    "        if train_flag:\n",
    "            Exp_Main.train(self=exp, train_loader=train_loader, setting=setting)\n",
    "        \n",
    "        if test_flag:\n",
    "            Exp_Main.test(self=exp, test_loader=test_loader, setting=setting, test=0)\n",
    "        return exp.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55134ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use CPU\n",
      "Epoch: 1 cost time: 48.523653984069824\n",
      "Epoch: 1, Steps: 65 | Train Loss: 0.7034816\n",
      "Validation loss decreased (inf --> 0.703482).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "test shape: (12, 24, 48, 24) (12, 24, 48, 24)\n",
      "test shape: (288, 48, 24) (288, 48, 24)\n",
      "mse:1.3615845441818237, mae:0.847229540348053\n"
     ]
    }
   ],
   "source": [
    "iTransformer_train_test = fit(model=curr_model, train_flag=True, test_flag=True, train_loader=train_loader, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18c7e457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ekaterinabasova/miniconda3/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=True, data_path='data', device=0, num_workers=0, features='M', freq='h', seq_len=96, pred_len=48, heads=16, d_model=100, N=10, block_nums=2, bottleneck=2, map_bottleneck=20, train_epochs=1, batch_size=24, learning_rate=0.0005, tau=0.07, loss_weight_prediction=1.0, loss_weight_infonce=1.0, loss_weight_smooth=1.0, check_point='checkpoint', patience=5)\n",
      "Basisformer(\n",
      "  (coefnet): Coefnet(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x BCAB(\n",
      "        (cross_attention_basis): channel_AutoCorrelationLayer(\n",
      "          (query_projection): Linear(in_features=100, out_features=96, bias=True)\n",
      "          (key_projection): Linear(in_features=100, out_features=96, bias=True)\n",
      "          (value_projection): Linear(in_features=100, out_features=96, bias=True)\n",
      "          (out_projection): Linear(in_features=96, out_features=100, bias=True)\n",
      "          (attend): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (conv1_basis): Linear(in_features=100, out_features=400, bias=True)\n",
      "        (conv2_basis): Linear(in_features=400, out_features=100, bias=True)\n",
      "        (dropout_basis): Dropout(p=0.1, inplace=False)\n",
      "        (cross_attention_ts): channel_AutoCorrelationLayer(\n",
      "          (query_projection): Linear(in_features=100, out_features=96, bias=True)\n",
      "          (key_projection): Linear(in_features=100, out_features=96, bias=True)\n",
      "          (value_projection): Linear(in_features=100, out_features=96, bias=True)\n",
      "          (out_projection): Linear(in_features=96, out_features=100, bias=True)\n",
      "          (attend): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (conv1_ts): Linear(in_features=100, out_features=400, bias=True)\n",
      "        (conv2_ts): Linear(in_features=400, out_features=100, bias=True)\n",
      "        (dropout_ts): Dropout(p=0.1, inplace=False)\n",
      "        (layer_norm11): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "        (layer_norm12): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "        (layer_norm21): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "        (layer_norm22): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (last_layer): last_layer(\n",
      "      (query_projection): Linear(in_features=100, out_features=96, bias=True)\n",
      "      (key_projection): Linear(in_features=100, out_features=96, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (MLP_x): MLP_bottle(\n",
      "    (linear1): Sequential(\n",
      "      (0): Linear(in_features=96, out_features=48, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=48, out_features=48, bias=True)\n",
      "    )\n",
      "    (linear2): Sequential(\n",
      "      (0): Linear(in_features=48, out_features=48, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=48, out_features=96, bias=True)\n",
      "    )\n",
      "    (skip): Linear(in_features=96, out_features=48, bias=True)\n",
      "    (act): ReLU()\n",
      "  )\n",
      "  (MLP_y): MLP_bottle(\n",
      "    (linear1): Sequential(\n",
      "      (0): Linear(in_features=48, out_features=24, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=24, out_features=24, bias=True)\n",
      "    )\n",
      "    (linear2): Sequential(\n",
      "      (0): Linear(in_features=24, out_features=24, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=24, out_features=48, bias=True)\n",
      "    )\n",
      "    (skip): Linear(in_features=48, out_features=24, bias=True)\n",
      "    (act): ReLU()\n",
      "  )\n",
      "  (MLP_sx): MLP_bottle(\n",
      "    (linear1): Sequential(\n",
      "      (0): Linear(in_features=96, out_features=48, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=48, out_features=48, bias=True)\n",
      "    )\n",
      "    (linear2): Sequential(\n",
      "      (0): Linear(in_features=48, out_features=48, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=48, out_features=96, bias=True)\n",
      "    )\n",
      "    (skip): Linear(in_features=96, out_features=48, bias=True)\n",
      "    (act): ReLU()\n",
      "  )\n",
      "  (MLP_sy): MLP_bottle(\n",
      "    (linear1): Sequential(\n",
      "      (0): Linear(in_features=48, out_features=24, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=24, out_features=24, bias=True)\n",
      "    )\n",
      "    (linear2): Sequential(\n",
      "      (0): Linear(in_features=24, out_features=24, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=24, out_features=48, bias=True)\n",
      "    )\n",
      "    (skip): Linear(in_features=48, out_features=24, bias=True)\n",
      "    (act): ReLU()\n",
      "  )\n",
      "  (project1): Linear(in_features=96, out_features=100, bias=True)\n",
      "  (project2): Linear(in_features=96, out_features=100, bias=True)\n",
      "  (project3): Linear(in_features=48, out_features=100, bias=True)\n",
      "  (project4): Linear(in_features=48, out_features=100, bias=True)\n",
      "  (criterion1): MSELoss()\n",
      "  (criterion2): L1Loss()\n",
      "  (map_MLP): MLP_bottle(\n",
      "    (linear1): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=20, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (linear2): Sequential(\n",
      "      (0): Linear(in_features=20, out_features=20, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=20, out_features=1440, bias=True)\n",
      "    )\n",
      "    (skip): Linear(in_features=1, out_features=20, bias=True)\n",
      "    (act): ReLU()\n",
      "  )\n",
      ")\n",
      "[Info] Number of parameters: 611976\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "\titers: 13, epoch: 1 | loss: 3.5904522\n",
      "\titers: 26, epoch: 1 | loss: 3.3287392\n",
      "\titers: 39, epoch: 1 | loss: 1.9276766\n",
      "\titers: 52, epoch: 1 | loss: 1.0573691\n",
      "\titers: 65, epoch: 1 | loss: 1.0257976\n",
      "Epoch: 1 cost time: 7.510359048843384\n",
      "loss_pred:1.025433797102708\n",
      "loss entropy:1.4030354900240827\n",
      "loss smooth:0.12736542912629933\n",
      "Epoch: 1 | Train Loss: 2.5558348\n",
      "loading model\n",
      "total_time:1.9078679084777832\n",
      "avg_time:0.1589889923731486\n",
      "mse:1.9724358320236206, mae:1.0011928081512451\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Basisformer_train_test = fit(model=\"basis_former\", train_flag=True, test_flag=True, train_loader=train_loader, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2803d193-eb4d-4ba8-b719-e2fa360e4167",
   "metadata": {},
   "source": [
    "# 5. Results - Models Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "315f19d0-063a-4932-8af4-7689bcb289f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(model_name, train_loader, test_loader,  self, setting, args=None, device=None, record_dir=None):\n",
    "    if model_name == \"basisformer\":\n",
    "        basisformer_train(model_name, train_loader, args, device, record_dir)\n",
    "        results = basisformer_test(model_name, test_loader, args, device, record_dir)\n",
    "    elif model_name == \"itransformer\":\n",
    "        itransformer_train(self, train_loader, setting)\n",
    "        results = itransformer_test(self, test_loader, setting)\n",
    "    elif model_name == \"ns_autoformer\":\n",
    "        ns_autoformer_train(self, train_loader, setting)\n",
    "        results = ns_autoformer_test(self, train_loader, setting)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {model_name}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def compare_models(train_loader, test_loader, args, self, setting, device, record_dir):\n",
    "    models = [\"basisformer\", \"itransformer\", \"ns_autoformer\"]\n",
    "    results = {}\n",
    "    \n",
    "    for model_name in models:\n",
    "        if model_name == \"basisformer\":\n",
    "            results[model_name] = run_models(model_name, train_loader, test_loader, args, self, setting, device, record_dir)\n",
    "        else:\n",
    "            results[model_name] = run_models(model_name, train_loader, test_loader, self, setting)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f782f44-f11a-4da5-84f7-e2f866782482",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m compare_models(train_loader\u001b[38;5;241m=\u001b[39mtrain_loader, test_loader\u001b[38;5;241m=\u001b[39mtest_loader, args\u001b[38;5;241m=\u001b[39m\u001b[43margs\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m=\u001b[39mexp, setting\u001b[38;5;241m=\u001b[39msetting, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, record_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "results = compare_models(train_loader=train_loader, test_loader=test_loader, args=args, self=exp, setting=setting, device=None, record_dir=None, index=None)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0bbe9e-2ecc-49c0-bf7b-356fb6f80758",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 6. Outlook "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0876475-7871-4b24-b71c-4d70f4d5adea",
   "metadata": {},
   "source": [
    "## Chronos Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56344b93-c9be-4c74-a0af-028dfdd20cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"chronos[training] @ git+https://github.com/amazon-science/chronos-forecasting.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb5bb54-ba52-4564-9775-05648c81013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python supporting_files_chronos/kernel-synth.py --num-series 500 --max-kernels 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c174fb6-a8cb-4ffb-b5fd-09a6d7908d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.ipc as ipc\n",
    "\n",
    "file_path = 'supporting_files_chronos/kernelsynth-data.arrow'\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    reader = ipc.RecordBatchFileReader(f)\n",
    "    table = reader.read_all()\n",
    "\n",
    "df_ch = table.to_pandas()\n",
    "\n",
    "print(df_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961121e6-2507-475c-8a80-7d6eb4489466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Number of time series\n",
    "num_series = 15\n",
    "# Number of plots per row\n",
    "plots_per_row = 5\n",
    "# Number of rows\n",
    "num_rows = (num_series + plots_per_row - 1) // plots_per_row\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, plots_per_row, figsize=(15, num_rows * 3))\n",
    "\n",
    "for i in range(num_series):\n",
    "    row = i // plots_per_row\n",
    "    col = i % plots_per_row\n",
    "    ax = axes[row, col]\n",
    "    ax.plot(df_ch['target'].iloc[i])\n",
    "    ax.set_title(f'Time Series {i}')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Value')\n",
    "\n",
    "# Remove any empty subplots\n",
    "for j in range(i + 1, num_rows * plots_per_row):\n",
    "    fig.delaxes(axes.flatten()[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9102227-5e5b-43ca-886e-362609622ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python supporting_files_chronos/kernel-synth-mult.py --num-series 500 --max-kernels 2 --dimensions 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c8baf1-c81a-4d00-a358-68f3697deda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.ipc as ipc\n",
    "\n",
    "file_path = 'supporting_files_chronos/kernelsynth-data.arrow'\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    reader = ipc.RecordBatchFileReader(f)\n",
    "    table = reader.read_all()\n",
    "\n",
    "df_ch_mult = table.to_pandas()\n",
    "\n",
    "print(df_ch_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2f68c5-3899-42e3-a491-fae38480a6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_ch_mult.head())\n",
    "print(df_ch_mult['target'].head().apply(lambda x: np.array(x).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fb2bce-e5b5-4f44-b2f7-76815d8a78d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot multivariate time series\n",
    "def plot_multivariate_time_series(data, num_rows=3, num_cols=5):\n",
    "    num_series = num_rows * num_cols\n",
    "    time_points = np.arange(len(data[0]) // 3)  # 1024 time points for reshaped data\n",
    "    \n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(20, num_rows * 4))\n",
    "    axs = axs.flatten()  # Flatten to easily iterate over subplots\n",
    "    \n",
    "    for i in range(num_series):\n",
    "        series = np.array(data[i]).reshape(-1, 3)  # Reshape to [1024, 3]\n",
    "        for j in range(series.shape[1]):\n",
    "            axs[i].plot(time_points, series[:, j], label=f'Dimension {j+1}')\n",
    "        axs[i].set_title(f'Time Series {i+1}')\n",
    "        axs[i].set_xlabel('Time')\n",
    "        axs[i].set_ylabel('Value')\n",
    "        axs[i].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Extract the 'target' column as a list and plot the first 15 multivariate time series\n",
    "plot_multivariate_time_series(df_ch_mult['target'].head(15).tolist(), num_rows=3, num_cols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8868e96d-c11f-44da-8284-5e3bdd7aa438",
   "metadata": {},
   "source": [
    "## DYNOTEARS Causal Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a06305-e94e-4e3e-8c8a-5a5036bf69e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalnex.structure.notears import from_pandas\n",
    "df_str = df.drop(columns=['Datetime (UTC)'])\n",
    "sm = from_pandas(df_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b7a18a-5c45-4440-b616-9c6f949c4db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalnex.plots import plot_structure, NODE_STYLE, EDGE_STYLE\n",
    "\n",
    "viz = plot_structure(\n",
    "    sm,\n",
    "    all_node_attributes=NODE_STYLE.WEAK,\n",
    "    all_edge_attributes=EDGE_STYLE.WEAK,\n",
    ")\n",
    "\n",
    "viz.toggle_physics(False)\n",
    "viz.show(\"supporting_files_dynotears/01_fully_connected.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297ebd63-03d7-45ab-8815-f4417d6ffeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.remove_edges_below_threshold(0.8)\n",
    "viz = plot_structure(\n",
    "    sm,\n",
    "    all_node_attributes=NODE_STYLE.WEAK,\n",
    "    all_edge_attributes=EDGE_STYLE.WEAK,\n",
    ")\n",
    "viz.show(\"supporting_files_dynotears/01_thresholded.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed52dbcf-3b38-457a-b105-b536abcccf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalnex.structure.notears import from_pandas\n",
    "df_str = df.drop(columns=['Datetime (UTC)'])\n",
    "sm = from_pandas(df_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad28f5e0-39c1-4129-a872-fa77fc837671",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.remove_edges_below_threshold(0.8)\n",
    "viz = plot_structure(\n",
    "    sm,\n",
    "    all_node_attributes=NODE_STYLE.WEAK,\n",
    "    all_edge_attributes=EDGE_STYLE.WEAK,\n",
    ")\n",
    "viz.show(\"supporting_files_dynotears/01_thresholded.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27208a4-9616-40ff-b2f3-d4455498b979",
   "metadata": {},
   "source": [
    "## Granger causality test with nonlinear forecasting methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71002567-98ca-49d4-a3d1-eb9dc74bf455",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nonlincausality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a85194-ab4f-4f57-b164-abe8bce5091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Feb  7 23:29:32 2022\n",
    "\n",
    "@author: Maciej RosoÅ‚\n",
    "\n",
    "contact: mrosol5@gmail.com, maciej.rosol.dokt@pw.edu.pl\n",
    "\"\"\"\n",
    "#%%\n",
    "import os\n",
    "\n",
    "# os.chdir(os.path.dirname(__file__))\n",
    "import numpy as np\n",
    "##import tensorflow\n",
    "import nonlincausality as nlc\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from nonlincausality.utils import prepare_data_for_prediction, calculate_pred_and_errors\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae4f41d-d94a-4877-987a-206fe905892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Data generation Y->X\n",
    "np.random.seed(10)\n",
    "y = (\n",
    "    np.cos(np.linspace(0, 20, 10_100))\n",
    "    + np.sin(np.linspace(0, 3, 10_100))\n",
    "    - 0.2 * np.random.random(10_100)\n",
    ")\n",
    "np.random.seed(20)\n",
    "x = 2 * y ** 3 - 5 * y ** 2 + 0.3 * y + 2 - 0.05 * np.random.random(10_100)\n",
    "data = np.vstack([x[:-100], y[100:]]).T\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(data[:, 0], label=\"X\")\n",
    "plt.plot(data[:, 1], label=\"Y\")\n",
    "plt.xlabel(\"Number of sample\")\n",
    "plt.ylabel(\"Signals [AU]\")\n",
    "plt.legend()\n",
    "\n",
    "#%% Test in case of presence of the causality\n",
    "lags = [50, 150]\n",
    "data_train = data[:6000, :]\n",
    "data_val = data[6000:8000, :]\n",
    "data_test = data[8000:, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8f4823-6810-4a83-941e-b759cddef251",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = nlc.nonlincausalityNN(\n",
    "    x=data_train,\n",
    "    maxlag=lags,\n",
    "    NN_config=['d','dr','d','dr'],\n",
    "    NN_neurons=[100,0.05,100,0.05],\n",
    "    x_test=data_test,\n",
    "    run=3,\n",
    "    epochs_num=[50, 50],\n",
    "    learning_rate=[0.0001, 0.00001],\n",
    "    batch_size_num=32,\n",
    "    x_val=data_val,\n",
    "    reg_alpha=None,\n",
    "    callbacks=None,\n",
    "    verbose=True,\n",
    "    plot=True,\n",
    ")\n",
    "\n",
    "#%% Example of obtaining the results\n",
    "for lag in lags:\n",
    "    best_model_X = results[lag].best_model_X\n",
    "    best_model_XY = results[lag].best_model_XY\n",
    "\n",
    "    p_value = results[lag].p_value\n",
    "    test_statistic = results[lag]._test_statistic\n",
    "\n",
    "    best_history_X = results[lag].best_history_X\n",
    "    best_history_XY = results[lag].best_history_XY\n",
    "\n",
    "    nlc.plot_history_loss(best_history_X, best_history_XY)\n",
    "    plt.title(\"Lag = %d\" % lag)\n",
    "    best_errors_X = results[lag].best_errors_X\n",
    "    best_errors_XY = results[lag].best_errors_XY\n",
    "\n",
    "    cohens_d = np.abs(\n",
    "        (np.mean(np.abs(best_errors_X)) - np.mean(np.abs(best_errors_XY)))\n",
    "        / np.std([best_errors_X, best_errors_XY])\n",
    "    )\n",
    "    print(\"For lag = %d Cohen's d = %0.3f\" % (lag, cohens_d))\n",
    "    print(f\"Test statistic = {test_statistic} p-value = {p_value}\")\n",
    "\n",
    "    # Using models for prediction\n",
    "    data_X, data_XY = prepare_data_for_prediction(data_test, lag)\n",
    "    X_pred_X = best_model_X.predict(data_X)\n",
    "    X_pred_XY = best_model_XY.predict(data_XY)\n",
    "\n",
    "    # Plot of true X vs X predicted\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].plot(data_test[lag:, 0], X_pred_X, \"o\")\n",
    "    ax[0].set_xlabel(\"X test values\")\n",
    "    ax[0].set_ylabel(\"Predicted X values\")\n",
    "    ax[0].set_title(\"Model based on X\")\n",
    "    ax[1].plot(data_test[lag:, 0], X_pred_XY, \"o\")\n",
    "    ax[1].set_xlabel(\"X test values\")\n",
    "    ax[1].set_ylabel(\"Predicted X values\")\n",
    "    ax[1].set_title(\"Model based on X and Y\")\n",
    "    plt.suptitle(\"Lag = %d\" % lag)\n",
    "\n",
    "    # Another way of obtaining predicted values (and errors)\n",
    "    X_pred_X, X_pred_XY, error_X, error_XY = calculate_pred_and_errors(\n",
    "        data_test[lag:, 0], \n",
    "        data_X, \n",
    "        data_XY, \n",
    "        best_model_X, \n",
    "        best_model_XY\n",
    "    )\n",
    "    # Plot of X predicted vs prediction error\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].plot(X_pred_X, error_X, \"o\")\n",
    "    ax[0].set_xlabel(\"Predicted X values\")\n",
    "    ax[0].set_ylabel(\"Prediction errors\")\n",
    "    ax[0].set_title(\"Model based on X\")\n",
    "    ax[1].plot(X_pred_XY, error_XY, \"o\")\n",
    "    ax[1].set_xlabel(\"Predicted X values\")\n",
    "    ax[1].set_ylabel(\"Prediction errors\")\n",
    "    ax[1].set_title(\"Model based on X and Y\")\n",
    "    plt.suptitle(\"Lag = %d\" % lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706cea49-2e4e-4b80-9dc4-be81936b1cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Test in case of absence of the causality\n",
    "np.random.seed(30)\n",
    "data_noise = np.vstack([x[:-100], np.random.random(10_000)]).T\n",
    "\n",
    "lags = [50, 150]\n",
    "data_noise_train = data_noise[:6000, :]\n",
    "data_noise_val = data_noise[6000:8000, :]\n",
    "data_noise_test = data_noise[8000:, :]\n",
    "\n",
    "results = nlc.nonlincausalityNN(\n",
    "    x=data_noise_train,\n",
    "    maxlag=lags,\n",
    "    NN_config=['d','dr','d','dr'],\n",
    "    NN_neurons=[100,0.05,100,0.05],\n",
    "    x_test=data_noise_test,\n",
    "    run=3,\n",
    "    epochs_num=[50, 50],\n",
    "    learning_rate=[0.001, 0.0001],\n",
    "    batch_size_num=32,\n",
    "    x_val=data_noise_val,\n",
    "    reg_alpha=None,\n",
    "    callbacks=None,\n",
    "    verbose=True,\n",
    "    plot=True,\n",
    ")\n",
    "\n",
    "#%% Example of obtaining the results\n",
    "for lag in lags:\n",
    "    best_model_X_lag50 = results[lag].best_model_X\n",
    "    best_model_XY_lag50 = results[lag].best_model_XY\n",
    "\n",
    "    p_value = results[lag].p_value\n",
    "    test_statistic = results[lag].test_statistic\n",
    "\n",
    "    best_history_X = results[lag].best_history_X\n",
    "    best_history_XY = results[lag].best_history_XY\n",
    "\n",
    "    nlc.plot_history_loss(best_history_X, best_history_XY)\n",
    "    plt.title(\"Lag = %d\" % lag)\n",
    "\n",
    "    best_errors_X = results[lag].best_errors_X\n",
    "    best_errors_XY = results[lag].best_errors_XY\n",
    "\n",
    "    cohens_d = np.abs(\n",
    "        (np.mean(np.abs(best_errors_X)) - np.mean(np.abs(best_errors_XY)))\n",
    "        / np.std([best_errors_X, best_errors_XY])\n",
    "    )\n",
    "    print(\"For lag = %d Cohen's d = %0.3f\" % (lag, cohens_d))\n",
    "    print(f\"test statistic = {test_statistic} p-value = {p_value}\")\n",
    "#%% Example of the measure of the causality change over time\n",
    "\n",
    "data_test_measure = copy.copy(data_test)\n",
    "np.random.seed(30)\n",
    "data_test_measure[:1000, 1] = np.random.random(1000)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(data_test_measure[:, 0], label=\"X\")\n",
    "plt.plot(data_test_measure[:, 1], label=\"Y\")\n",
    "plt.xlabel(\"Number of sample\")\n",
    "plt.ylabel(\"Signals [AU]\")\n",
    "plt.legend()\n",
    "\n",
    "results = nlc.nonlincausalitymeasureNN(\n",
    "    x=data_train,\n",
    "    maxlag=lags,\n",
    "    window=100,\n",
    "    step=1,\n",
    "    NN_config=['d','dr','d','dr'],\n",
    "    NN_neurons=[100,0.05,100,0.05],\n",
    "    x_test=data_test_measure,\n",
    "    run=3,\n",
    "    epochs_num=[50,50],\n",
    "    learning_rate=[0.0001, 0.00001],\n",
    "    batch_size_num=32,\n",
    "    x_val=data_val,\n",
    "    verbose=True,\n",
    "    plot=True,\n",
    ")\n",
    "\n",
    "\n",
    "#%% Example of usage for conditional analysis\n",
    "np.random.seed(30)\n",
    "z = np.random.random([10_000, 2])\n",
    "\n",
    "z_train = z[:6000, :]\n",
    "z_val = z[6000:8000, :]\n",
    "z_test = z[8000:, :]\n",
    "\n",
    "results_conditional = nlc.nonlincausalityNN(\n",
    "    x=data_train,\n",
    "    maxlag=lags,\n",
    "    NN_config=['d','dr','d','dr'],\n",
    "    NN_neurons=[100,0.05,100,0.05],\n",
    "    x_test=data_test,\n",
    "    run=1,\n",
    "    z=z_train,\n",
    "    z_test=z_test,\n",
    "    epochs_num=[50, 50],\n",
    "    learning_rate=[0.0001, 0.00001],\n",
    "    batch_size_num=32,\n",
    "    x_val=data_val,\n",
    "    z_val=z_val,\n",
    "    reg_alpha=None,\n",
    "    callbacks=None,\n",
    "    verbose=True,\n",
    "    plot=True,\n",
    ")\n",
    "# %% Exaple of the usage the package with Scikit-learn model\n",
    "\n",
    "parametres = {\n",
    "    'kernel':['poly', 'rbf'],\n",
    "    'C':[0.01,0.1,1], \n",
    "    'epsilon':[0.01,0.1,1.]\n",
    "}\n",
    "results_skl = nlc.nonlincausality_sklearn(    \n",
    "    x=data_train,\n",
    "    sklearn_model=SVR,\n",
    "    maxlag=lags,\n",
    "    params=parametres,\n",
    "    x_test=data_test,\n",
    "    x_val=data_val,\n",
    "    plot=True)\n",
    "\n",
    "#%% Example of usage other functions for causality analysis\n",
    "\n",
    "# ARIMA/ARIMAX models\n",
    "results_ARIMA = nlc.nonlincausalityARIMA(x=data_train[::10], maxlag=[5,15], x_test=data_test[::10])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
